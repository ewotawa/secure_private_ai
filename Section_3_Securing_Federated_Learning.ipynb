{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 3 - Securing Federated Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewotawa/secure_private_ai/blob/master/Section_3_Securing_Federated_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jzoKqLOaOl4",
        "colab_type": "text"
      },
      "source": [
        "# Section: Securing Federated Learning\n",
        "\n",
        "- Lesson 1: Trusted Aggregator\n",
        "- Lesson 2: Intro to Additive Secret Sharing\n",
        "- Lesson 3: Intro to Fixed Precision Encoding\n",
        "- Lesson 4: Secret Sharing + Fixed Precision in PySyft\n",
        "- Final Project: Federated Learning wtih Encrypted Gradient Aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ9l5evZaOl8",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Federated Learning with a Trusted Aggregator\n",
        "\n",
        "In the last section, we learned how to train a model on a distributed dataset using Federated Learning. In particular, the last project aggregated gradients directly from one data owner to another. \n",
        "\n",
        "However, while in some cases it could be ideal to do this, what would be even better is to be able to choose a neutral third party to perform the aggregation.\n",
        "\n",
        "As it turns out, we can use the same tools we used previously to accomplish this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RN0inkwGTAT",
        "colab_type": "text"
      },
      "source": [
        "### Install libraries and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "355SUSnNGVD6",
        "colab_type": "code",
        "outputId": "91f2630b-9aad-45ab-c0d9-6ce5c8d837f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "# PySyft\n",
        "\n",
        "!pip install syft\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "# PyTorch\n",
        "\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# time\n",
        "\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages (0.1.21a1)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.0.1)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: websocket-client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.56.0)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: tf-encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.7)\n",
            "Requirement already satisfied: flask-socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from syft) (4.1.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.1.0)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 00:21:09.489979 140468923750272 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0726 00:21:09.510081 140468923750272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq8Iba7FaOl_",
        "colab_type": "text"
      },
      "source": [
        "# Project: Federated Learning with a Trusted Aggregator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_aKplNKaOmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QxB76WICItF",
        "colab_type": "text"
      },
      "source": [
        "### Instructor's Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtRx8-evCILB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import syft as sy\n",
        "import torch\n",
        "hook = sy.TorchHook(torch)\n",
        "from torch import nn, optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDQnFg98aOmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a few workers\n",
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCUIKdajaOmV",
        "colab_type": "code",
        "outputId": "e6691db3-c23d-4333-d8a2-c2fd259e69f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# inform each worker that the other workers exist\n",
        "\n",
        "bob.add_workers([alice, secure_worker])\n",
        "alice.add_workers([bob, secure_worker])\n",
        "secure_worker.add_workers([bob, alice])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 00:21:16.155555 140468923750272 base.py:628] Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0726 00:21:16.158713 140468923750272 base.py:628] Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0726 00:21:16.160677 140468923750272 base.py:628] Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0726 00:21:16.162790 140468923750272 base.py:628] Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0726 00:21:16.164652 140468923750272 base.py:628] Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0726 00:21:16.166789 140468923750272 base.py:628] Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:secure_worker #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmxe8KRJaOmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same Toy Dataset and simple linear model\n",
        "\n",
        "data = torch.tensor([[0,0], [0,1], [1,0], [1,1.]], requires_grad=True)\n",
        "target = torch.tensor([[0], [0], [1], [1.]], requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-m2myhuaOmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get pointers to training data on each worker by sending some training data to bob and alice\n",
        "\n",
        "bobs_data = data[0:2].send(bob)\n",
        "bobs_target = target[0:2].send(bob)\n",
        "\n",
        "alices_data = data[2:].send(alice)\n",
        "alices_target = target[2:].send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFdfkcnnDQ_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize a Toy Model\n",
        "\n",
        "model = nn.Linear(2, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgdGhlWpDQ59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instead of having one model, have two different models that we send to the two different workers so that they can be averaged.\n",
        "\n",
        "bobs_model = model.copy().send(bob)\n",
        "alices_model = model.copy().send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KmK1pxgDQy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create two separate optimizers\n",
        "\n",
        "bobs_opt = optim.SGD(params=bobs_model.parameters(), lr=0.1)\n",
        "alices_opt = optim.SGD(params=alices_model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ZbPmjEaOmr",
        "colab_type": "code",
        "outputId": "1b98bee2-53e9-42ce-85a2-f79cdd00d6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the models\n",
        "\n",
        "for round_iter in range(10):\n",
        "  \n",
        "  bobs_model = model.copy().send(bob)\n",
        "  alices_model = model.copy().send(alice)\n",
        "  \n",
        "  bobs_opt = optim.SGD(params=bobs_model.parameters(), lr=0.1)\n",
        "  alices_opt = optim.SGD(params=alices_model.parameters(), lr=0.1)\n",
        "  \n",
        "  for i in range(10):\n",
        "    \n",
        "    bobs_opt.zero_grad()\n",
        "    bobs_pred = bobs_model(bobs_data)\n",
        "    bobs_loss = ((bobs_pred - bobs_target) **2).sum()\n",
        "    bobs_loss.backward()\n",
        "    \n",
        "    bobs_opt.step()\n",
        "    bobs_loss = bobs_loss.get().data\n",
        "    bobs_loss\n",
        "    \n",
        "    alices_opt.zero_grad()\n",
        "    alices_pred = alices_model(alices_data)\n",
        "    alices_loss = ((alices_pred - alices_target) **2).sum()\n",
        "    alices_loss.backward()\n",
        "    \n",
        "    alices_opt.step()\n",
        "    alices_loss = alices_loss.get().data\n",
        "    alices_loss\n",
        "  \n",
        "  bobs_model.move(secure_worker)\n",
        "  alices_model.move(secure_worker)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    weights = model.weight.set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
        "    bias = model.bias.set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())\n",
        "  \n",
        "  secure_worker.clear_objects()\n",
        "  \n",
        "  print(\"Iteration:\\t\", round_iter)\n",
        "  print(\"Bob:\\t\", str(bobs_loss), \"\\tAlice:\\t\", str(alices_loss))\n",
        "  print(\"Weights: \", str(weights), \"\\nBias: \", str(bias),\"\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:\t 0\n",
            "Bob:\t tensor(0.0728) \tAlice:\t tensor(0.0097)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[-0.3562, -0.2346]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.6973], requires_grad=True) \n",
            "\n",
            "Iteration:\t 1\n",
            "Bob:\t tensor(0.0293) \tAlice:\t tensor(0.0002)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[-0.1890, -0.1173]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.5831], requires_grad=True) \n",
            "\n",
            "Iteration:\t 2\n",
            "Bob:\t tensor(0.0151) \tAlice:\t tensor(0.0002)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[-0.0401, -0.0689]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.4888], requires_grad=True) \n",
            "\n",
            "Iteration:\t 3\n",
            "Bob:\t tensor(0.0091) \tAlice:\t tensor(0.0005)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.0935, -0.0457]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.4156], requires_grad=True) \n",
            "\n",
            "Iteration:\t 4\n",
            "Bob:\t tensor(0.0061) \tAlice:\t tensor(0.0006)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.2118, -0.0335]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.3567], requires_grad=True) \n",
            "\n",
            "Iteration:\t 5\n",
            "Bob:\t tensor(0.0043) \tAlice:\t tensor(0.0006)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.3154, -0.0263]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.3077], requires_grad=True) \n",
            "\n",
            "Iteration:\t 6\n",
            "Bob:\t tensor(0.0031) \tAlice:\t tensor(0.0005)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.4058, -0.0216]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.2662], requires_grad=True) \n",
            "\n",
            "Iteration:\t 7\n",
            "Bob:\t tensor(0.0023) \tAlice:\t tensor(0.0004)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.4844, -0.0182]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.2305], requires_grad=True) \n",
            "\n",
            "Iteration:\t 8\n",
            "Bob:\t tensor(0.0017) \tAlice:\t tensor(0.0003)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.5527, -0.0156]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.1998], requires_grad=True) \n",
            "\n",
            "Iteration:\t 9\n",
            "Bob:\t tensor(0.0013) \tAlice:\t tensor(0.0002)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.6119, -0.0134]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([0.1733], requires_grad=True) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX9uUUHWaOmy",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Intro to Additive Secret Sharing\n",
        "\n",
        "While being able to have a trusted third party to perform the aggregation is certainly nice, in an ideal setting we wouldn't have to trust anyone at all. This is where Cryptography can provide an interesting alterantive. \n",
        "\n",
        "Specifically, we're going to be looking at a simple protocol for Secure Multi-Party Computation called Additive Secret Sharing. This protocol will allow multiple parties (of size 3 or more) to aggregate their gradients without the use of a trusted 3rd party to perform the aggregation. In other words, we can add 3 numbers together from 3 different people without anyone ever learning the inputs of any other actors.\n",
        "\n",
        "Let's start by considering the number 5, which we'll put into a varible x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1lqIxO8aOm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdiQY-iDaOm7",
        "colab_type": "text"
      },
      "source": [
        "Let's say we wanted to SHARE the ownership of this number between two people, Alice and Bob. We could split this number into two shares, 2, and 3, and give one to Alice and one to Bob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg-ujOdkaOm-",
        "colab_type": "code",
        "outputId": "479db93e-4e66-4c99-9b36-1dc2641bbd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_x_share = 2\n",
        "alice_x_share = 3\n",
        "\n",
        "decrypted_x = bob_x_share + alice_x_share\n",
        "decrypted_x"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO4WO_lJaOnQ",
        "colab_type": "text"
      },
      "source": [
        "Note that neither Bob nor Alice know the value of x. They only know the value of their own SHARE of x. Thus, the true value of X is hidden (i.e., encrypted). \n",
        "\n",
        "The truly amazing thing, however, is that Alice and Bob can still compute using this value! They can perform arithmetic over the hidden value! Let's say Bob and Alice wanted to multiply this value by 2! If each of them multiplied their respective share by 2, then the hidden number between them is also multiplied! Check it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYHci918aOnS",
        "colab_type": "code",
        "outputId": "cb663eee-a31b-4c14-8341-116e9f18f414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_x_share = 2 * 2\n",
        "alice_x_share = 3 * 2\n",
        "\n",
        "decrypted_x = bob_x_share + alice_x_share\n",
        "decrypted_x"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CahOx-EeaOnd",
        "colab_type": "text"
      },
      "source": [
        "This even works for addition between two shared values!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UjdTG4YaOnf",
        "colab_type": "code",
        "outputId": "3891aa2b-90e6-41c0-c7d2-b4ecefc979bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# encrypted \"5\"\n",
        "bob_x_share = 2\n",
        "alice_x_share = 3\n",
        "\n",
        "# encrypted \"7\"\n",
        "bob_y_share = 5\n",
        "alice_y_share = 2\n",
        "\n",
        "# encrypted 5 + 7\n",
        "bob_z_share = bob_x_share + bob_y_share\n",
        "alice_z_share = alice_x_share + alice_y_share\n",
        "\n",
        "decrypted_z = bob_z_share + alice_z_share\n",
        "decrypted_z"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vBygY8IaOnp",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we just added two numbers together while they were still encrypted!!!\n",
        "\n",
        "One small tweak - notice that since all our numbers are positive, it's possible for each share to reveal a little bit of information about the hidden value, namely, it's always greater than the share. Thus, if Bob has a share \"3\" then he knows that the encrypted value is at least 3.\n",
        "\n",
        "This would be quite bad, but can be solved through a simple fix. Decryption happens by summing all the shares together MODULUS some constant. I.e."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXxARaataOnr",
        "colab_type": "code",
        "outputId": "8425ede2-0ec7-4744-cf7f-4c116bee9279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = 5\n",
        "\n",
        "Q = 23740629843760239486723\n",
        "\n",
        "bob_x_share = 23552870267 # <- a random number\n",
        "alice_x_share = Q - bob_x_share + x\n",
        "alice_x_share"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23740629843736686616461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r67WBxzTaOn1",
        "colab_type": "code",
        "outputId": "9f049389-e8d9-4bef-ccbf-2c4e337b7b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(bob_x_share + alice_x_share) % Q"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxzwV1iZaOoC",
        "colab_type": "text"
      },
      "source": [
        "So now, as you can see, both shares are wildly larger than the number being shared, meaning that individual shares no longer leak this inforation. However, all the properties we discussed earlier still hold! (addition, encryption, decryption, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzkTC1UUaOoE",
        "colab_type": "text"
      },
      "source": [
        "# Project: Build Methods for Encrypt, Decrypt, and Add \n",
        "\n",
        "In this project, you must take the lessons we learned in the last section and write general methods for encrypt, decrypt, and add. Store shares for a variable in a tuple like so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPyDd_n1aOoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_share = (2,5,7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UIPgJ_laOoO",
        "colab_type": "text"
      },
      "source": [
        "Even though normally those shares would be distributed amongst several workers, you can store them in ordered tuples like this for now :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9Yc4C5gaOoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3jpzoTONhRW",
        "colab_type": "text"
      },
      "source": [
        "### My work\n",
        "\n",
        "Create a method called <strong>encrypt()</strong>  \n",
        "<ul>\n",
        "  <li>Accepts two input parameters:\n",
        "    <ul>\n",
        "      <li>Number to be encrypted</li>\n",
        "      <li>Number of shares to be split into</li>\n",
        "    </ul>\n",
        "  </li>\n",
        "  <li>Returns a tuple of shares</li>\n",
        "</ul>\n",
        "\n",
        "Create a method called <strong>decrypt()</strong>  \n",
        "* Accepts as input a tuple of shares \n",
        "* Returns the decrypted value \n",
        "\n",
        "Create a method called <strong>add()</strong> \n",
        "* Accepts two tuples of shares \n",
        "* Returns a single tuple of shares which are added correctly according to the additive secret sharing protocol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAFXLroBNgNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encrypt(orig_number, num_shares, Q):\n",
        "  x = int(orig_number)\n",
        "  \n",
        "  # Q = 23740629843760239486723 #large prime number\n",
        "  \n",
        "  shares = []\n",
        "  share_sum = int()\n",
        "  \n",
        "  for i in range(num_shares - 1):\n",
        "    share = torch.randn(1) * 100000000000\n",
        "    shares.append(int(share.item()))\n",
        "  \n",
        "  last_share = Q - int(sum(shares)) + x\n",
        "  shares.append(last_share)\n",
        "  \n",
        "  sum_out = sum(shares)\n",
        "  \n",
        "  shares = tuple(shares)\n",
        "  \n",
        "  # validation:\n",
        "  # print(sum_out % Q)\n",
        "  \n",
        "  return(shares)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AvP5Qo1aOoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decrypt(encrypted_shares, Q):\n",
        "  sum_shares = sum(encrypted_shares)\n",
        "  decrypted = sum_shares % Q\n",
        "  return decrypted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDCuCTOIaOoX",
        "colab_type": "code",
        "outputId": "00058252-3d37-4136-e228-54047b77f32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "Q = 23740629843760239486723 #large prime number \n",
        "shares = encrypt(5, 200, Q)\n",
        "print(shares)\n",
        "decrypted = decrypt(shares, Q)\n",
        "print(decrypted)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48404017152, 37268344832, 45172924416, 214172139520, -171496161280, -36272275456, 1325095424, 13208155136, 45870018560, -195716169728, 20030484480, -21258268672, -54761136128, 35366637568, 92163555328, -88563277824, 194362376192, 836648576, -24129884160, 61459886080, 8927991808, -105625640960, 50138685440, 48976003072, 47181570048, -5782382592, -109374029824, 12370370560, -49431748608, 110995382272, 78522023936, -22257340416, -75291254784, 181980282880, 51208798208, -65850863616, 1362587776, 249025462272, 28094949376, 149882224640, -17737238528, 10544888832, -17314750464, -13725630464, 111559933952, 89403785216, 104940388352, -15262956544, 170423894016, -12734749696, 90204061696, 91082997760, -22575351808, 190532780032, 209165713408, 107776794624, 61423300608, 157157523456, -53264359424, 21686482944, 21910296576, -197568577536, -88690532352, -124373336064, -111401738240, 93403791360, 39465037824, 64173518848, -485526048, -177425350656, 155931852800, -25453158400, 72493432832, -31350591488, -120117796864, -86137520128, 147965149184, 14294042624, 17159818240, 110938652672, -89670729728, -178138103808, 7543629312, 107035385856, 30822813696, 109056385024, -100302159872, 76145508352, -218754482176, 115092750336, -28119603200, 181657731072, 106774888448, -31546099712, 39951527936, 76306292736, 69771124736, 13919165440, -217474678784, -24405270528, 34000750592, 132482310144, 47669694464, -93588627456, -2186950912, -170884661248, 24975032320, -251360657408, 112567205888, 59870969856, 80004702208, -81260388352, -18452404224, -151595843584, -69611700224, 46291214336, 73364684800, -129993531392, 12179328000, 37538746368, -178878709760, -72104951808, -52465942528, 54915022848, 78668161024, 181485535232, 90462625792, -176993681408, -45804167168, 55584878592, 13816505344, 112041885696, 38682660864, -8217088512, 18478073856, 35382038528, -79228788736, -209420025856, 3551494144, 64206868480, 92212346880, 113661059072, 10600121344, 180592361472, -75447394304, 6769990656, -160138395648, -230976667648, -3531170816, -121529352192, -133210382336, 162038185984, 66570227712, 204372885504, 52237664256, 41241202688, 60802957312, -6714701312, 39108255744, 10287316992, -9129405440, -99297320960, 47659905024, 3315645696, -61429063680, -63109267456, -65909874688, 45357060096, -102933667840, 102186631168, -62460301312, 166652084224, 108942376960, -47666905088, -62773010432, 190604460032, 238240006144, -58239094784, -40938872832, -97984380928, 49498537984, -35933396992, -59458854912, 60620873728, 4434681344, -35176665088, -3586753792, -189697441792, 134480592896, 62122369024, -124589129728, -39258021888, -108616851456, -25431259136, 199168720896, -61012594688, 52559814656, 40859254784, 28057006080, 23740629841868811590952)\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geTTom0HaOot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add(tuple1, tuple2):\n",
        "  sum_tuple = tuple1 + tuple2\n",
        "  return sum_tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTMHNSeKaOo2",
        "colab_type": "code",
        "outputId": "4ef0e4a1-0e42-4cf2-eed2-48aac33a8d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tuple1 = encrypt(5, 5, Q)\n",
        "tuple2 = encrypt(10, 5, Q)\n",
        "\n",
        "sum_tuple = add(tuple1, tuple2)\n",
        "print(sum_tuple)\n",
        "\n",
        "decrypt(sum_tuple, Q)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(244839448576, -101526904832, 54522036224, -5230072832, 23740629843567634979592, -38770032640, -178999951360, 177767972864, -71160422400, 23740629843871401920269)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEp4vocmcYJW",
        "colab_type": "text"
      },
      "source": [
        "### Instructor's work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezYgiNX-Yx6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKTlK7tLdEKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = 23740629843760239486723 #large prime number "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2pxfV6RdHTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encrypt(x, n_shares):\n",
        "  shares = list()\n",
        "  for i in range(n_shares - 1):\n",
        "    shares.append(random.randint(0, Q))\n",
        "  final_share = Q - (sum(shares) % Q) + x\n",
        "  shares.append(final_share)\n",
        "  return tuple(shares)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPGku6jHeSel",
        "colab_type": "code",
        "outputId": "24051130-8d52-4a58-b637-acbe3dcd9dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "encrypt(5, n_shares=10)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19719178205133768498514,\n",
              " 22437704552807729263033,\n",
              " 8743514729836978573972,\n",
              " 9994137450193379136389,\n",
              " 12921063178089361404680,\n",
              " 17681291228760577452375,\n",
              " 15818014619598394287843,\n",
              " 19596789109218081686548,\n",
              " 20361092631404725080654,\n",
              " 18911623201278681023058)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHdEvowdehIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decrypt(shares):\n",
        "  return sum(shares) % Q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5HRzaDgexdO",
        "colab_type": "code",
        "outputId": "63f1e415-7cbf-43ce-a021-e6b08ebf992f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decrypt(encrypt(5, 10))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-4bluRge1cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add(a, b):\n",
        "  c = list()\n",
        "  assert(len(a) == len(b))\n",
        "  for i in range(len(a)):\n",
        "    c.append((a[i] + b[i]) % Q)\n",
        "  return tuple(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4_oodXZfVk1",
        "colab_type": "code",
        "outputId": "6887278e-0345-417a-b21a-cfd4a9f2bf22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decrypt(add(encrypt(5, 10), encrypt(5, 10)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFZbgXdsaOpA",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Intro to Fixed Precision Encoding\n",
        "\n",
        "As you may remember, our goal is to aggregate gradients using this new Secret Sharing technique. However, the protocol we've just explored in the last section uses positive integers. However, our neural network weights are NOT integers. Instead, our weights are decimals (floating point numbers).\n",
        "\n",
        "Not a huge deal! We just need to use a fixed precision encoding, which lets us do computation over decimal numbers using integers!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5taeIZZqaOpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE=10\n",
        "PRECISION=4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rO-HlHFaOpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(x):\n",
        "    return int((x * (BASE ** PRECISION)) % Q)\n",
        "\n",
        "def decode(x):\n",
        "    return (x if x <= Q/2 else x - Q) / BASE**PRECISION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-RRpwNgaOpX",
        "colab_type": "code",
        "outputId": "aa1ff464-7d8b-4112-aced-b5ca716b6b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encode(3.5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRxTbzEXaOpi",
        "colab_type": "code",
        "outputId": "d5a7ede1-faf0-4926-b447-eb746ef59e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decode(35000)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8coAYwPaOpq",
        "colab_type": "code",
        "outputId": "b529a6f9-4c82-4b54-eeaf-9a8e6dcb742a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = encrypt(encode(5.5), 3)\n",
        "y = encrypt(encode(2.3), 3)\n",
        "z = add(x,y)\n",
        "decode(decrypt(z))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxndJNJqaOpz",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Secret Sharing + Fixed Precision in PySyft\n",
        "\n",
        "While writing things from scratch is certainly educational, PySyft makes a great deal of this much easier for us through its abstractions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrYybTrhaOp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = bob.clear_objects()\n",
        "alice = alice.clear_objects()\n",
        "secure_worker = secure_worker.clear_objects()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VMAhg6BaOp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([1,2,3,4,5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18fTR_nKaOqQ",
        "colab_type": "text"
      },
      "source": [
        "### Secret Sharing Using PySyft\n",
        "\n",
        "We can share using the simple .share() method!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1jCOLObaOqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.share(bob, alice, secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KePfhEpqaOqd",
        "colab_type": "code",
        "outputId": "ba66db7e-c93d-44b0-a01e-bfc8a0a633e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{51351644448: tensor([1542841711977177559,  826536590925762557,  278092298435898122,\n",
              "         3609678328164168715,  492195322488907427])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oLgGcRWaOqp",
        "colab_type": "text"
      },
      "source": [
        "and as you can see, Bob now has one of the shares of x! Furthermore, we can still call addition in this state, and PySyft will automatically perform the remote execution for us!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eurv7F0laOqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRm5jpW6aOqx",
        "colab_type": "code",
        "outputId": "8a5eabc0-1a9a-4670-df79-4a8f1cfe01fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:15186991494 -> bob:66313699950]\n",
              "\t-> (Wrapper)>[PointerTensor | me:36565099520 -> alice:77462307685]\n",
              "\t-> (Wrapper)>[PointerTensor | me:59613647163 -> secure_worker:69329711773]\n",
              "\t*crypto provider: me*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmASr4yVaOq7",
        "colab_type": "code",
        "outputId": "3bccfb53-d28f-4121-8667-85b03a07ba78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.get()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  4,  6,  8, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USsIL-fvaOrH",
        "colab_type": "text"
      },
      "source": [
        "### Fixed Precision using PySyft\n",
        "\n",
        "We can also convert a tensor to fixed precision using .fix_precision()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro6HYYKIaOrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([0.1,0.2,0.3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0F7XtYoaOrV",
        "colab_type": "code",
        "outputId": "6b707fa6-6156-4766-f1ca-f1b15856c176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1000, 0.2000, 0.3000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqFDgDQaOrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.fix_prec()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_TNTfnuaOr0",
        "colab_type": "code",
        "outputId": "4886fcaa-69a1-4236-8f7f-8ef1a7beb36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.child.child"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([100, 200, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rhPGuuXaOsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLfDmUedaOsO",
        "colab_type": "code",
        "outputId": "1d9ae0c4-9ef1-4053-f006-04e25b79b9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = y.float_prec()\n",
        "y"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2000, 0.4000, 0.6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHc4L2WbaOsc",
        "colab_type": "text"
      },
      "source": [
        "### Shared Fixed Precision\n",
        "\n",
        "And of course, we can combine the two!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQx0QmxbaOse",
        "colab_type": "code",
        "outputId": "f64b2b6a-2e08-4680-9235-805637826825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([0.1, 0.2, 0.3])\n",
        "print(x)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1000, 0.2000, 0.3000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWt3-aqlaOsn",
        "colab_type": "code",
        "outputId": "4cf5c8c3-e84d-45fc-e98b-5ad5aef60912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = x.fix_prec().share(bob, alice, secure_worker)\n",
        "print(x)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Wrapper)>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
            "\t-> (Wrapper)>[PointerTensor | me:10930538663 -> bob:67871063829]\n",
            "\t-> (Wrapper)>[PointerTensor | me:36219304287 -> alice:47764675786]\n",
            "\t-> (Wrapper)>[PointerTensor | me:67734829532 -> secure_worker:52285622123]\n",
            "\t*crypto provider: me*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXv8SQhHaOtM",
        "colab_type": "code",
        "outputId": "1ba53632-7bf6-4ea2-a2bb-35499ebb94b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y = x + x\n",
        "print(x)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Wrapper)>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
            "\t-> (Wrapper)>[PointerTensor | me:10930538663 -> bob:67871063829]\n",
            "\t-> (Wrapper)>[PointerTensor | me:36219304287 -> alice:47764675786]\n",
            "\t-> (Wrapper)>[PointerTensor | me:67734829532 -> secure_worker:52285622123]\n",
            "\t*crypto provider: me*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUnyMYkpaOtZ",
        "colab_type": "code",
        "outputId": "753e3af7-e2eb-4a71-9af4-f9f73af4e2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.get().float_prec()\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2000, 0.4000, 0.6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VedGpynTaOt7",
        "colab_type": "text"
      },
      "source": [
        "Make sure to make the point that people can see the model averages in the clear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elv6crAPaOt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZl3oCKcaOuI",
        "colab_type": "text"
      },
      "source": [
        "# Final Project: Federated Learning with Encrypted Gradient Aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg1uoz_-6Obg",
        "colab_type": "text"
      },
      "source": [
        "Build on the first project, where you perform federated learning with a trusted, secure aggregator.\n",
        "\n",
        "<ul>\n",
        "  <li>Take the same neural network you used in the first project. </li>\n",
        "  <li>Aggregate gradients using additive secret sharing and fixed-precision encoding.  </li>\n",
        "  <li>Use at least three data owners per aggregation.  \n",
        "    <ul>\n",
        "      <li>Ensures that no one will ever see anyone's gradients other than their own. Protects privacy without needing to trust a secure aggregator.  </li>\n",
        "    </ul>\n",
        "  </li>\n",
        "</ul>  \n",
        "\n",
        "My approach:\n",
        "<ul>\n",
        "<li>Work with the approach outlined in the <a href=\"https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2011%20-%20Secure%20Deep%20Learning%20Classification.ipynb\">OpenMined notebook</a> exercise.</li>\n",
        "  <li>Use the same dummy data approach as final project for Section 2.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0D6ArcbHvKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a few workers\n",
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ari5V-JbIehY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same Toy Dataset and simple linear model\n",
        "\n",
        "data = torch.tensor([[0,0], [0,1], [1,0], [1,1.]], requires_grad=True)\n",
        "target = torch.tensor([[0], [0], [1], [1.]], requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3znKbvZIkCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get pointers to training data on each worker by sending some training data to bob and alice\n",
        "\n",
        "bobs_data = data[0:2].send(bob)\n",
        "bobs_target = target[0:2].send(bob)\n",
        "\n",
        "alices_data = data[2:].send(alice)\n",
        "alices_target = target[2:].send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "traCKb_EIyRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize a Toy Model\n",
        "\n",
        "model = nn.Linear(2, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxrRlYISI8XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instead of having one model, have two different models that we send to the two different workers so that they can be averaged.\n",
        "\n",
        "bobs_model = model.copy().send(bob)\n",
        "alices_model = model.copy().send(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk9S8hujJJyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create two separate optimizers\n",
        "\n",
        "bobs_opt = optim.SGD(params=bobs_model.parameters(), lr=0.1)\n",
        "alices_opt = optim.SGD(params=alices_model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wSEIFbFJR0q",
        "colab_type": "code",
        "outputId": "09be1e9f-2a71-4698-dc03-7fee48e19523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the models\n",
        "\n",
        "for round_iter in range(10):\n",
        "  \n",
        "  bobs_model = model.copy().send(bob)\n",
        "  alices_model = model.copy().send(alice)\n",
        "  \n",
        "  bobs_opt = optim.SGD(params=bobs_model.parameters(), lr=0.1)\n",
        "  alices_opt = optim.SGD(params=alices_model.parameters(), lr=0.1)\n",
        "  \n",
        "  for i in range(10):\n",
        "    \n",
        "    bobs_opt.zero_grad()\n",
        "    bobs_pred = bobs_model(bobs_data)\n",
        "    bobs_loss = ((bobs_pred - bobs_target) **2).sum()\n",
        "    bobs_loss.backward()\n",
        "    \n",
        "    bobs_opt.step()\n",
        "    bobs_loss = bobs_loss.get().data\n",
        "    bobs_loss\n",
        "    \n",
        "    alices_opt.zero_grad()\n",
        "    alices_pred = alices_model(alices_data)\n",
        "    alices_loss = ((alices_pred - alices_target) **2).sum()\n",
        "    alices_loss.backward()\n",
        "    \n",
        "    alices_opt.step()\n",
        "    alices_loss = alices_loss.get().data\n",
        "    alices_loss\n",
        "  \n",
        "  bobs_model.move(secure_worker)\n",
        "  alices_model.move(secure_worker)\n",
        "  \n",
        "  # weights\n",
        "  bob_w = bobs_model.weight.data.child.clone().get()\n",
        "  alice_w = alices_model.weight.data.child.clone().get()\n",
        "  \n",
        "  bob_w_s = bob_w.fix_prec().share(bob, alice, secure_worker)\n",
        "  alice_w_s = alice_w.fix_prec().share(bob, alice, secure_worker)\n",
        "  \n",
        "  w_avg_get_fl= ((bob_w_s[0] + alice_w_s[0]) / 2).get().float_prec()\n",
        "  w_l = w_avg_get_fl.tolist()\n",
        "  w_ll = list()\n",
        "  w_ll.append(w_l)\n",
        "  \n",
        "  w = torch.tensor(w_ll, requires_grad=True)\n",
        "  \n",
        "  # bias\n",
        "  bob_b = bobs_model.bias.data.child.clone().get()\n",
        "  alice_b = alices_model.bias.data.child.clone().get()\n",
        "  \n",
        "  bob_b_s = bob_b.fix_prec().share(bob, alice, secure_worker)\n",
        "  alice_b_s = alice_b.fix_prec().share(bob, alice, secure_worker)\n",
        "  \n",
        "  b_avg_get_fl= ((bob_b_s[0] + alice_b_s[0]) / 2).get().float_prec()\n",
        "  b_l = b_avg_get_fl.tolist()\n",
        "  b_ll = list()\n",
        "  b_ll.append(b_l)\n",
        "  \n",
        "  b = torch.tensor(b_ll, requires_grad=True)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    weights = model.weight.set_(w)\n",
        "    bias = model.bias.set_(b)\n",
        "  \n",
        "  secure_worker.clear_objects()\n",
        "  \n",
        "  print(\"Iteration:\\t\", round_iter)\n",
        "  print(\"Bob:\\t\", str(bobs_loss), \"\\tAlice:\\t\", str(alices_loss))\n",
        "  print(\"Weights: \", str(weights), \"\\nBias: \", str(bias),\"\\n\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:\t 0\n",
            "Bob:\t tensor(0.0090) \tAlice:\t tensor(0.0316)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[0.3870, 0.1730]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.1740]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 1\n",
            "Bob:\t tensor(0.0003) \tAlice:\t tensor(0.0064)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[0.4820, 0.0610]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.1750]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 2\n",
            "Bob:\t tensor(0.0001) \tAlice:\t tensor(0.0018)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[0.5600, 0.0200]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.1700]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 3\n",
            "Bob:\t tensor(0.0005) \tAlice:\t tensor(0.0007)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[0.6230, 0.0030]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.1560]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 4\n",
            "Bob:\t tensor(0.0006) \tAlice:\t tensor(0.0003)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.6740, -0.0040]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.1390]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 5\n",
            "Bob:\t tensor(0.0005) \tAlice:\t tensor(0.0002)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.7180, -0.0060]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.1230]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 6\n",
            "Bob:\t tensor(0.0004) \tAlice:\t tensor(0.0001)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.7550, -0.0070]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.1070]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 7\n",
            "Bob:\t tensor(0.0004) \tAlice:\t tensor(7.3166e-05)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.7880, -0.0070]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.0930]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 8\n",
            "Bob:\t tensor(0.0003) \tAlice:\t tensor(5.0643e-05)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.8160, -0.0060]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.0820]], requires_grad=True) \n",
            "\n",
            "Iteration:\t 9\n",
            "Bob:\t tensor(0.0002) \tAlice:\t tensor(3.7207e-05)\n",
            "Weights:  Parameter containing:\n",
            "tensor([[ 0.8400, -0.0060]], requires_grad=True) \n",
            "Bias:  Parameter containing:\n",
            "tensor([[0.0710]], requires_grad=True) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}