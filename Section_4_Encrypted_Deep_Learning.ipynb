{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Section 4 - Encrypted Deep Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "whhNGQAm1Sdn",
        "qRHorDE61SiL",
        "oCOxJQhP1SiN",
        "IQj85l901Sid",
        "9MePG7vB1SjW",
        "EYikqlhJ1SjX",
        "EAoOm9jR1Sjx",
        "k2ZS6vEx1Sj5",
        "2IaVvtSL1SkE",
        "IJspZ4wn1SkK",
        "qfq4eCkW1Ska",
        "j6_FkZkv1Skb",
        "ll5-M5X41Skk",
        "45UXMU301Skm",
        "T2O9EBzD1Sk8"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewotawa/secure_private_ai/blob/master/Section_4_Encrypted_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcAlinv91SYb",
        "colab_type": "text"
      },
      "source": [
        "# Section: Encrypted Deep Learning\n",
        "\n",
        "- Lesson: Reviewing Additive Secret Sharing\n",
        "- Lesson: Encrypted Subtraction and Public/Scalar Multiplication\n",
        "- Lesson: Encrypted Computation in PySyft\n",
        "- Project: Build an Encrypted Database\n",
        "- Lesson: Encrypted Deep Learning in PyTorch\n",
        "- Lesson: Encrypted Deep Learning in Keras\n",
        "- Final Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeXcPikT3CHQ",
        "colab_type": "code",
        "outputId": "929db48c-579b-4d24-9625-427b4594e18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# PySyft\n",
        "\n",
        "!pip install syft\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "# PyTorch\n",
        "\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# time\n",
        "\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/49/1262a301e9db38f4822fa9e0e3b15831c86af9eaeb43b2b0aea3d0c6e1a1/syft-0.1.22a1-py3-none-any.whl (249kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 11.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 163kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 174kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 184kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 194kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 204kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 215kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 225kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 235kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 245kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.3)\n",
            "Collecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 12.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 21.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40kB 24.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51kB 27.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61kB 30.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 71kB 32.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81kB 32.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92kB 34.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102kB 36.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112kB 36.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 122kB 36.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 133kB 36.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 143kB 36.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 153kB 36.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 163kB 36.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 174kB 36.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 184kB 36.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 194kB 36.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Collecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/66/44/edc4715af85671b943c18ac8345d0207972284a0cd630126ff5251faa08b/Flask_SocketIO-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Collecting tf-encrypted!=0.5.7,>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 39kB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 39.7MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/4b/ad228451b1c071c5c52616b7d4298ebcfcac5ae8515ede959db19e4cd56d/websockets-8.0.2-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 14.4MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Collecting python-socketio>=4.3.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/b0/22c3f785f23fec5c7a815f47c55d7e7946a67ae2129ff604148e939d3bdb/python_socketio-4.3.1-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted!=0.5.7,>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Collecting python-engineio>=3.9.0 (from python-socketio>=4.3.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/20/8e3ba16102ae2e245d70d9cb9fa48b076253fdb036dc43eea142294c2897/python_engineio-3.9.3-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (3.1.1)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zstd: filename=zstd-1.4.1.0-cp36-cp36m-linux_x86_64.whl size=1067085 sha256=e068f9431787721b44563fbf9ff9cc1774ef77e1a45a53de5f71203122826bfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44105 sha256=34ad78578b768c914c5aea398579b873426d5a8b463a8fa374583baeee4150ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: websocket-client, python-engineio, python-socketio, flask-socketio, pyyaml, tf-encrypted, msgpack, websockets, zstd, lz4, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.2.1 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.9.3 python-socketio-4.3.1 pyyaml-5.1.2 syft-0.1.22a1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-8.0.2 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 02:07:18.436465 140370259122048 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0808 02:07:18.456842 140370259122048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD-MaOgw1SYg",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Reviewing Additive Secret Sharing\n",
        "\n",
        "_For more great information about SMPC protocols like this one, visit https://mortendahl.github.io. With permission, Morten's work directly inspired this first teaching segment._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN4X14wa1SYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "BASE = 10\n",
        "\n",
        "PRECISION_INTEGRAL = 8\n",
        "PRECISION_FRACTIONAL = 8\n",
        "Q = 293973345475167247070445277780365744413\n",
        "\n",
        "PRECISION = PRECISION_INTEGRAL + PRECISION_FRACTIONAL\n",
        "\n",
        "assert(Q > BASE**PRECISION)\n",
        "\n",
        "def encode(rational):\n",
        "    upscaled = int(rational * BASE**PRECISION_FRACTIONAL)\n",
        "    field_element = upscaled % Q\n",
        "    return field_element\n",
        "\n",
        "def decode(field_element):\n",
        "    upscaled = field_element if field_element <= Q/2 else field_element - Q\n",
        "    rational = upscaled / BASE**PRECISION_FRACTIONAL\n",
        "    return rational\n",
        "\n",
        "def encrypt(secret):\n",
        "    first  = random.randrange(Q)\n",
        "    second = random.randrange(Q)\n",
        "    third  = (secret - first - second) % Q\n",
        "    return [first, second, third]\n",
        "\n",
        "def decrypt(sharing):\n",
        "    return sum(sharing) % Q\n",
        "\n",
        "def add(a, b):\n",
        "    c = list()\n",
        "    for i in range(len(a)):\n",
        "        c.append((a[i] + b[i]) % Q)\n",
        "    return tuple(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIdT_BnX1SYw",
        "colab_type": "code",
        "outputId": "0115ecf6-2175-48ff-d528-b2463cc34912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = encrypt(encode(5.5))\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[191399845254032188583941495419710394154,\n",
              " 146112633277576147135582787737676387628,\n",
              " 250434212418726158421366272403894707044]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ymgxcnD1SZI",
        "colab_type": "code",
        "outputId": "d451081c-eeb0-4d8c-ce68-76471a6aef03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y = encrypt(encode(2.3))\n",
        "y"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[62675146043691001422013069077952476457,\n",
              " 200272344583655953542989332330522902702,\n",
              " 31025854847820292105442876372120365253]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsG0Tt951SZU",
        "colab_type": "code",
        "outputId": "a3b181c6-329e-4c13-a1e8-d2f6b3c59d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "z = add(x,y)\n",
        "z"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(254074991297723190005954564497662870611,\n",
              " 52411632386064853608126842287833545917,\n",
              " 281460067266546450526809148776015072297)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_nWYNLh1SZf",
        "colab_type": "code",
        "outputId": "a05f77a9-7392-4f4e-d940-300bcd0828e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decode(decrypt(z))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.79999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8ZdyTSS1SZs",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Subtraction and Public/Scalar Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJliD3ag1SZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8MvF3ne1SZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field = 23740629843760239486723"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVhOmLYE1SZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 5\n",
        "\n",
        "bob_x_share = 2372385723 # random number\n",
        "alices_x_share = field - bob_x_share + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw2LT1uH1SaM",
        "colab_type": "code",
        "outputId": "16adc85d-689f-4f7a-bb2c-caae36741613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(bob_x_share + alices_x_share) % field"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B82EzIEf1Sar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field = 10\n",
        "\n",
        "x = 5\n",
        "\n",
        "bob_x_share = 8\n",
        "alice_x_share = field - bob_x_share + x\n",
        "\n",
        "y = 1\n",
        "\n",
        "bob_y_share = 9\n",
        "alice_y_share = field - bob_y_share + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv4Ua_uP1Sa0",
        "colab_type": "code",
        "outputId": "74e1c2a4-588f-48cd-a63f-4bbc340af37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((bob_x_share + alice_x_share) - (bob_y_share + alice_y_share)) % field"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqA5PE951SbB",
        "colab_type": "code",
        "outputId": "7104aa9e-2bb0-4301-cdc9-ca9bae80d757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((bob_x_share - bob_y_share) + (alice_x_share - alice_y_share)) % field"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScVpSgYH1SbO",
        "colab_type": "code",
        "outputId": "21269c4a-a6c4-4735-d84e-ea809eea42f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_x_share + alice_x_share + bob_y_share + alice_y_share"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF9sqzjW1SbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob_z_share = (bob_x_share - bob_y_share)\n",
        "alice_z_share = (alice_x_share - alice_y_share)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDzCsOQA1Sbj",
        "colab_type": "code",
        "outputId": "fd24e2e6-8e76-4829-e56f-94644f33e9b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(bob_z_share + alice_z_share) % field"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev1fe7Xl1Sb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sub(a, b):\n",
        "    c = list()\n",
        "    for i in range(len(a)):\n",
        "        c.append((a[i] - b[i]) % Q)\n",
        "    return tuple(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iWbLqBJ1Sb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field = 10\n",
        "\n",
        "x = 5\n",
        "\n",
        "bob_x_share = 8\n",
        "alice_x_share = field - bob_x_share + x\n",
        "\n",
        "y = 1\n",
        "\n",
        "bob_y_share = 9\n",
        "alice_y_share = field - bob_y_share + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9eWrll_1ScI",
        "colab_type": "code",
        "outputId": "08276c2d-b60d-4f4c-e087-9d66e05cdddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_x_share + alice_x_share"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtrCgMoC1Sca",
        "colab_type": "code",
        "outputId": "3b585860-b6df-40bf-c957-c90880cb4f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bob_y_share + alice_y_share"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSfZPQwk1Scn",
        "colab_type": "code",
        "outputId": "836e7f06-662f-4d7e-bd3d-3c1b0c559528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((bob_y_share * 3) + (alice_y_share * 3)) % field"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQGGhbNX1Scy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imul(a, scalar):\n",
        "    \n",
        "    # logic here which can multiply by a public scalar\n",
        "    \n",
        "    c = list()\n",
        "    \n",
        "    for i in range(len(a)):\n",
        "        c.append((a[i] * scalar) % Q)\n",
        "        \n",
        "    return tuple(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8lBxKLO1Sc5",
        "colab_type": "code",
        "outputId": "0ecdc23d-035e-495f-cf67-8d572f8a793a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = encrypt(encode(5.5))\n",
        "x"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[135921453730543279725866724856646345035,\n",
              " 130368345829642556347758822663336361297,\n",
              " 27683545914981410996819730260933038081]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg2e5rfW1SdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = imul(x, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsdrm64S1SdV",
        "colab_type": "code",
        "outputId": "41166fc9-fc78-4dd4-adf9-a393043a5b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decode(decrypt(z))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whhNGQAm1Sdn",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Computation in PySyft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA4HRC2h1Sdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import syft as sy\n",
        "import torch as th\n",
        "hook = sy.TorchHook(th)\n",
        "from torch import nn, optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeS814tf1Sdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8af159e6-dc0d-45f3-9a90-9ebcc87a7021"
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id=\"bob\").add_worker(sy.local_worker)\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\").add_worker(sy.local_worker)\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\").add_worker(sy.local_worker)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0808 02:07:30.117150 140370259122048 base.py:646] Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0808 02:07:30.125979 140370259122048 base.py:646] Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n",
            "W0808 02:07:30.127928 140370259122048 base.py:646] Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02O6lqcv1Sd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4])\n",
        "y = th.tensor([2,-1,1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGTt4EoX1SeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Ln54js1SeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y.share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oorFXnxI1SeR",
        "colab_type": "code",
        "outputId": "fef752ed-accc-4164-8d2a-f2a4a2104076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x + y\n",
        "z.get()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 1, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfhDM7Tn1Seb",
        "colab_type": "code",
        "outputId": "2946da6a-585f-49d9-a462-138c5e55855a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x - y\n",
        "z.get()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1,  3,  2,  4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHQBD9t41Sel",
        "colab_type": "code",
        "outputId": "b582f907-3e2b-41d7-a856-25c661621dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x * y\n",
        "z.get()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, -2,  3,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzOxt0Ux1Sev",
        "colab_type": "code",
        "outputId": "c350e761-f9d9-47e5-dc8d-8ef6502b23d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x > y\n",
        "z.get()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhQCtZyS1Se5",
        "colab_type": "code",
        "outputId": "98c7b2e5-098b-405b-fff7-419f1c8a6671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x < y\n",
        "z.get()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDLVxwAM1SfD",
        "colab_type": "code",
        "outputId": "ddce7bfa-43f8-4a2e-9788-67c871ed93cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x == y\n",
        "z.get()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6twcabOd1SfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMg2cZR21SfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4])\n",
        "y = th.tensor([2,-1,1,0])\n",
        "\n",
        "x = x.fix_precision().share(bob, alice, crypto_provider=secure_worker)\n",
        "y = y.fix_precision().share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCg--yKF1Sff",
        "colab_type": "code",
        "outputId": "905acf1d-f0f8-4296-f1fe-0954371ff77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x + y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 1., 4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjsZuBdT1Sfr",
        "colab_type": "code",
        "outputId": "9a7df4b5-fdfe-4fc6-edf7-abca3d0da607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x - y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.,  3.,  2.,  4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqWzh88b1Sf5",
        "colab_type": "code",
        "outputId": "376cc377-6295-4a2f-d37e-4958b1b6f2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x * y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2., -2.,  3.,  0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN9i7CEJ1Sge",
        "colab_type": "code",
        "outputId": "7f0702d3-7fd5-4a18-b315-2167bf1e0ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x > y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHisRvjh1ShM",
        "colab_type": "code",
        "outputId": "fac53cf1-c177-47c4-d212-771c916e6870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x < y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7pKVX6r1ShT",
        "colab_type": "code",
        "outputId": "3a2ba488-acdd-4d8c-a3bf-09af77e517ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "z = x == y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-MQhNBL1Shc",
        "colab_type": "text"
      },
      "source": [
        "# Project: Build an Encrypted Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ZloBnz1Shd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlQaFUZ-e4bL",
        "colab_type": "text"
      },
      "source": [
        "###Instructor's work\n",
        "\n",
        "Rationale for exercise:\n",
        "* to show the general nature of encrypted computation - it can be based off of tensor computations. \n",
        "\n",
        "Process:\n",
        "* take individual strings - key-value database of string representations\n",
        "*  convert strongs to tensor operations.\n",
        "* show how tesor operations can be used to perform queries.\n",
        "\n",
        "Feature\n",
        "* encrypted database: makes it so that the database owner \n",
        " * can't see any of the data (the data is encrypted while it's in the database)\n",
        " * can't see what people are querying\n",
        " * can't see the results of the queries\n",
        "* because all the values are encrypted using secure MPC (multi-party computation), you can have a group of database owners: multiple individuals that have joint ownership and joint governance over people's ability to query and use information. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVLre41zO7I5",
        "colab_type": "text"
      },
      "source": [
        "Come up with numerical representations for strings. \n",
        "\n",
        "Two general options: \n",
        "* one-hot representation\n",
        "* integer representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QVYlrwZO4pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose what subset of characters we want to support on our database. \n",
        "# create lookup tables that map characters to integers\n",
        "char2index = {}\n",
        "index2char = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVN85bf2e3PM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "# what do we want to encode\n",
        "for i,char in enumerate(' ' + string.ascii_lowercase + '1234567890' + string.punctuation):\n",
        "  char2index[char] = i\n",
        "  index2char[i] = char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BxATq6Aa7o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str_input = \"Hello\"\n",
        "max_length = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEuSQ7XHB2g7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer representation\n",
        "def string2values(str_input, max_length):\n",
        "  \n",
        "  # trim any strings that are too long, convert them to lowercase\n",
        "  str_input = str_input[:max_length].lower()\n",
        "\n",
        "  # if a string is too short, pad it with .\n",
        "  if(len(str_input) < max_length):\n",
        "    str_input = str_input + \".\" * (max_length - len(str_input))\n",
        "\n",
        "  values = list()\n",
        "\n",
        "  for char in str_input:\n",
        "    values.append(char2index[char])\n",
        "\n",
        "  values_t = torch.tensor(values).long()\n",
        "  \n",
        "  return values_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HB8Idy7cDl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f479fe3-cc23-4452-fa0d-b07636bc043f"
      },
      "source": [
        "string2values(\"howdy!\",8)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8, 15, 23,  4, 25, 37, 50, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkrl1E5l1Shi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot encoding\n",
        "def one_hot(index, length):\n",
        "  # start with a tensor of zeros\n",
        "  vect = torch.zeros(length).long()\n",
        "  # whatever the index position is, set it to one\n",
        "  vect[index] = 1\n",
        "  return vect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGhjPAnc1Sho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c85c9fe2-0019-4730-c7ef-b68b0c8cd0ed"
      },
      "source": [
        "one_hot(3,5)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWudHGe21SiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "18ae5d30-9129-4ae9-b2d8-30c1f8417103"
      },
      "source": [
        "# representing characters\n",
        "one_hot(char2index['p'], len(index2char))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gcTY5KSP0qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer representation\n",
        "def string2one_hot_matrix(str_input, max_length):\n",
        "  \n",
        "  # trim any strings that are too long, convert them to lowercase\n",
        "  str_input = str_input[:max_length].lower()\n",
        "\n",
        "  # if a string is too short, pad it with .\n",
        "  if(len(str_input) < max_length):\n",
        "    str_input = str_input + \".\" * (max_length - len(str_input))\n",
        "\n",
        "  char_vector = list()\n",
        "  for char in str_input:\n",
        "    char_v = one_hot(char2index[char], len(index2char)).unsqueeze(0)\n",
        "    char_vector.append(char_v)\n",
        "  \n",
        "  result = torch.cat(char_vector, dim=0)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1oEarvgP0jk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "62fd66ba-6f67-4cd2-dd0e-0e54597cfec8"
      },
      "source": [
        "string2one_hot_matrix(\"Hello\", 8)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llq6FJDoR64s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fefd139-d2ed-4945-d0b4-a166cf057ab7"
      },
      "source": [
        "# 8 rows representing 8 characters, 69 columns representing the 69 possible characters to be encoded.\n",
        "matrix = string2one_hot_matrix(\"Hello\", 8)\n",
        "\n",
        "matrix.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 69])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7cB17n2P0df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# database: store keys using one-hot encoding, store values using string-to-one-hot-matrix."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCZMVUHFS3s1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9317b760-4d45-40eb-cd73-1c2ab2113c82"
      },
      "source": [
        "# test for characters in common\n",
        "m_a = string2one_hot_matrix(\"abcdefg\", 8)\n",
        "m_b = string2one_hot_matrix(\"hijklmnop\", 8)\n",
        "\n",
        "# only positions where the same character is present in both strings will return a one. No matches returns a tensor of zero. \n",
        "(m_a * m_b).sum()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWR_G_qoTXKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7b4e3a2-c5a9-4870-844f-77a7a8f58515"
      },
      "source": [
        "# test for characters in common\n",
        "m_a = string2one_hot_matrix(\"ThingOne\", 8)\n",
        "m_b = string2one_hot_matrix(\"ThingTwo\", 8)\n",
        "\n",
        "# only positions where the same character is present in both strings will return a one. No matches returns a tensor of zero. \n",
        "(m_a * m_b).sum()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBIb3ZSVTu3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful tool: allows us to use multiplication to tell whether or not a given key is a perfect match with a particular query."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTWHmkLVUFEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7992645a-ede8-4877-9b5a-790c272529af"
      },
      "source": [
        "# test for characters in common\n",
        "m_a = string2one_hot_matrix(\"ThingOne\", 8)\n",
        "m_b = string2one_hot_matrix(\"ThingTwo\", 8)\n",
        "\n",
        "# sum along the 1 dimension: see how many characters are overlapping\n",
        "(m_a * m_b).sum(1)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ3-YVLvUdwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: we mostly care whether or not the strings match completely. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj_AK-SbaYoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "827c0978-3ec4-4be2-e720-b9c756be782e"
      },
      "source": [
        "vect = (m_a * m_b).sum(1)\n",
        "print(vect)\n",
        "\n",
        "x = vect[0]\n",
        "\n",
        "for i in range(vect.shape[0] - 1):\n",
        "  x = x * vect[i + 1]\n",
        "  \n",
        "# Boolean value. 1: strings match, 2: strings do not match. \n",
        "# note: using only multiplication to encode a Boolean bit that determines whether or not the two keys match.\n",
        "key_match = x\n",
        "print(key_match)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 1, 1, 0, 0, 0])\n",
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyiMW3yZdb92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a dummy key-value pair\n",
        "\n",
        "keys = list()\n",
        "values = list()\n",
        "\n",
        "keys.append(string2one_hot_matrix(\"key0\", 8))\n",
        "values.append(string2values(\"value0\", 8))\n",
        "\n",
        "keys.append(string2one_hot_matrix(\"key1\", 8))\n",
        "values.append(string2values(\"value1\", 8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRDoxvtVeDPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_equal(str_a, str_b):\n",
        "  vect = (str_a * str_b).sum(1)\n",
        "  \n",
        "  x = vect[0]\n",
        "\n",
        "  for i in range(vect.shape[0] - 1):\n",
        "    x = x * vect[i + 1]\n",
        "\n",
        "  str_match = x\n",
        "  return str_match"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAwb5WxefbnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "987f8d48-88ab-4b4c-9f61-f9799380ae0c"
      },
      "source": [
        "# a query to a key-value store first needs to compute whether the query matches any of the other keys.\n",
        "\n",
        "query_str = \"key1\"\n",
        "\n",
        "# convert to the correct representation\n",
        "\n",
        "query_matrix = string2one_hot_matrix(query_str, 8)\n",
        "\n",
        "# perform the query: iterate all keys and figure out whether any of them match\n",
        "\n",
        "key_matches = list()\n",
        "\n",
        "for key in keys:\n",
        "  key_match = string_equal(key, query_matrix)\n",
        "  key_matches.append(key_match)\n",
        "  \n",
        "print(key_matches)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(0), tensor(1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RmMwm6mfb0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can mask out all the values that don't have matching keys."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_3_1_a5pT-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e7ca104-2b26-4f5f-8cb0-54ffdb4e03f9"
      },
      "source": [
        "print(values)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([22,  1, 12, 21,  5, 36, 50, 50]), tensor([22,  1, 12, 21,  5, 27, 50, 50])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N0cIg7Vj5gx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a7cb35d-bf41-484d-89d7-13d769625ee8"
      },
      "source": [
        "# result is the numerical representation of matching values\n",
        "# adds up all the values but first masks out the ones that don't have matching keys.\n",
        "\n",
        "result = values[0] * key_matches[0]\n",
        "\n",
        "for i in range(len(values) - 1):\n",
        "  result += values[i+1] * key_matches[i+1]\n",
        "  \n",
        "print(result)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([22,  1, 12, 21,  5, 27, 50, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mbC8Dr2m0L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how do we get a tensor that is strings instead of numbers? \n",
        "\n",
        "def values2string(input_values):\n",
        "  s = \"\"\n",
        "  for value in input_values:\n",
        "    s += index2char[int(value)]\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPs_1F1Nnxpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0a1cede-2dbf-42b9-a91a-e26ef6f18925"
      },
      "source": [
        "values2string(result).replace(\".\", \"\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'value1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDtvzpadoiZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(query_str):\n",
        "  query_matrix = string2one_hot_matrix(query_str, 8)\n",
        "\n",
        "  key_matches = list()\n",
        "\n",
        "  for key in keys:\n",
        "    key_match = string_equal(key, query_matrix)\n",
        "    key_matches.append(key_match)\n",
        "    \n",
        "  result = values[0] * key_matches[0]\n",
        "\n",
        "  for i in range(len(values) - 1):\n",
        "    result += values[i+1] * key_matches[i+1]\n",
        "    \n",
        "  return values2string(result).replace(\".\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkfej6Xwreef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e5d55af-c4d8-481c-8257-8b36441f9b12"
      },
      "source": [
        "query(\"key0\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'value0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejNH2xc-rkPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how do we pack this into a database?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsIij95d9bHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# package the convenience functions\n",
        "\n",
        "# integer representation\n",
        "def string2values(str_input, max_length):\n",
        "  \n",
        "  # trim any strings that are too long, convert them to lowercase\n",
        "  str_input = str_input[:max_length].lower()\n",
        "\n",
        "  # if a string is too short, pad it with .\n",
        "  if(len(str_input) < max_length):\n",
        "    str_input = str_input + \".\" * (max_length - len(str_input))\n",
        "\n",
        "  values = list()\n",
        "\n",
        "  for char in str_input:\n",
        "    values.append(char2index[char])\n",
        "\n",
        "  values_t = torch.tensor(values).long()\n",
        "  \n",
        "  return values_t\n",
        "\n",
        "# one-hot encoding\n",
        "def one_hot(index, length):\n",
        "  # start with a tensor of zeros\n",
        "  vect = torch.zeros(length).long()\n",
        "  # whatever the index position is, set it to one\n",
        "  vect[index] = 1\n",
        "  return vect\n",
        "\n",
        "# integer representation\n",
        "def string2one_hot_matrix(str_input, max_length):\n",
        "  \n",
        "  # trim any strings that are too long, convert them to lowercase\n",
        "  str_input = str_input[:max_length].lower()\n",
        "\n",
        "  # if a string is too short, pad it with .\n",
        "  if(len(str_input) < max_length):\n",
        "    str_input = str_input + \".\" * (max_length - len(str_input))\n",
        "\n",
        "  char_vector = list()\n",
        "  for char in str_input:\n",
        "    char_v = one_hot(char2index[char], len(index2char)).unsqueeze(0)\n",
        "    char_vector.append(char_v)\n",
        "  \n",
        "  result = torch.cat(char_vector, dim=0)\n",
        "  return result\n",
        "\n",
        "def string_equal(str_a, str_b):\n",
        "  vect = (str_a * str_b).sum(1)\n",
        "  \n",
        "  x = vect[0]\n",
        "\n",
        "  for i in range(vect.shape[0] - 1):\n",
        "    x = x * vect[i + 1]\n",
        "\n",
        "  str_match = x\n",
        "  return str_match\n",
        "\n",
        "def values2string(input_values):\n",
        "  s = \"\"\n",
        "  for value in input_values:\n",
        "    s += index2char[int(value)]\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBRnKFaE9ZiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DB():\n",
        "  \n",
        "  def __init__(self, max_key_len=8, max_val_len=8):\n",
        "    self.max_key_len = 8\n",
        "    self.max_val_len = 8\n",
        "    \n",
        "    self.keys = list()\n",
        "    self.values = list()\n",
        "\n",
        "    self.keys.append(string2one_hot_matrix(\"key0\", 8))\n",
        "    self.values.append(string2values(\"value0\", 8))\n",
        "\n",
        "    self.keys.append(string2one_hot_matrix(\"key1\", 8))\n",
        "    self.values.append(string2values(\"value1\", 8))\n",
        "  \n",
        "  def add_entry(self, key, value):\n",
        "    self.keys.append(string2one_hot_matrix(key, self.max_key_len))\n",
        "    self.values.append(string2values(value, self.max_val_len))\n",
        "    \n",
        "    \n",
        "  def query(self, query_str):\n",
        "    query_matrix = string2one_hot_matrix(query_str, 8)\n",
        "\n",
        "    key_matches = list()\n",
        "\n",
        "    for key in self.keys:\n",
        "      key_match = string_equal(key, query_matrix)\n",
        "      key_matches.append(key_match)\n",
        "\n",
        "    result = self.values[0] * key_matches[0]\n",
        "\n",
        "    for i in range(len(self.values) - 1):\n",
        "      result += self.values[i+1] * key_matches[i+1]\n",
        "\n",
        "    return values2string(result).replace(\".\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc4v5uRw-ja9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = DB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFWUDfMk-9AT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2344cf5d-be33-46d2-f3c2-8eb541f8adbb"
      },
      "source": [
        "db.query(\"key0\")"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'value0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfIPPM4HARIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db.add_entry(\"key2\", \"value2\")\n",
        "db.add_entry(\"key3\", \"value3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrT7ldxkAnjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "824659f6-203a-44ae-caff-180ddc3685a9"
      },
      "source": [
        "db.query(\"key3\")"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'value3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k_Qq_R0A12g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now add encryption\n",
        "\n",
        "class EncryptedDB():\n",
        "  \n",
        "  def __init__(self, *owners, max_key_len=8, max_val_len=8):\n",
        "    self.max_key_len = 8\n",
        "    self.max_val_len = 8\n",
        "    \n",
        "    self.keys = list()\n",
        "    self.values = list()\n",
        "    self.owners = owners\n",
        "  \n",
        "  def add_entry(self, key, value):\n",
        "    key = string2one_hot_matrix(key, self.max_key_len)\n",
        "    key = key.share(*self.owners)\n",
        "    self.keys.append(key)\n",
        "    \n",
        "    value = string2one_hot_matrix(value, self.max_val_len)\n",
        "    value = value.share(*self.owners)\n",
        "    self.values.append(value)\n",
        "        \n",
        "  def query(self, query_str):\n",
        "    query_matrix = string2one_hot_matrix(query_str, 8)\n",
        "    \n",
        "    query_matrix = query_matrix.share(*self.owners)\n",
        "\n",
        "    key_matches = list()\n",
        "\n",
        "    for key in self.keys:\n",
        "      key_match = string_equal(key, query_matrix)\n",
        "      key_matches.append(key_match)\n",
        "\n",
        "    result = self.values[0] * key_matches[0]\n",
        "\n",
        "    for i in range(len(self.values) - 1):\n",
        "      result += self.values[i+1] * key_matches[i+1]\n",
        "      \n",
        "    result = result.get()\n",
        "\n",
        "    return values2string(result).replace(\".\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oZwN1IECYX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edb = EncryptedDB(bob, alice, secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofca7-VNGASF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edb.add_entry(\"key0\", \"value0\")\n",
        "edb.add_entry(\"key1\", \"value1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FthZ81J8CbBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5307f119-5c22-46ff-cfcd-fa0a3274ccdc"
      },
      "source": [
        "edb.query(\"key0\")"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-e9e35ed4e37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-154-0d2f811aff3a>\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_str)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mkey_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mkey_matches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-148-482e88465c82>\u001b[0m in \u001b[0;36mstring_equal\u001b[0;34m(str_a, str_b)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstring_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr_a\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstr_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \"\"\"Multiplies two number for details see mul\n\u001b[1;32m    476\u001b[0m         \"\"\"\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_public_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_private_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py\u001b[0m in \u001b[0;36m_private_mul\u001b[0;34m(self, other, equation)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For multiplication a crypto_provider must be passed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mshares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspdz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspdz_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrypto_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mshares\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/crypto/spdz.py\u001b[0m in \u001b[0;36mspdz_mul\u001b[0;34m(cmd, x_sh, y_sh, crypto_provider, field)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiPointerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiPointerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdelta_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"dict_values\") to list"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRHorDE61SiL",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Deep Learning in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCOxJQhP1SiN",
        "colab_type": "text"
      },
      "source": [
        "### Train a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9nvHb2Z1SiP",
        "colab_type": "code",
        "outputId": "0a909c7b-dd08-4373-ca23-da0b47e3467f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# A Toy Dataset\n",
        "data = th.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "target = th.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 20)\n",
        "        self.fc2 = nn.Linear(20, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# A Toy Model\n",
        "model = Net()\n",
        "\n",
        "def train():\n",
        "    # Training Logic\n",
        "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
        "    for iter in range(20):\n",
        "\n",
        "        # 1) erase previous gradients (if they exist)\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # 2) make a prediction\n",
        "        pred = model(data)\n",
        "\n",
        "        # 3) calculate how much we missed\n",
        "        loss = ((pred - target)**2).sum()\n",
        "\n",
        "        # 4) figure out which weights caused us to miss\n",
        "        loss.backward()\n",
        "\n",
        "        # 5) change those weights\n",
        "        opt.step()\n",
        "\n",
        "        # 6) print our progress\n",
        "        print(loss.data)\n",
        "        \n",
        "train()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.2824)\n",
            "tensor(2.2900)\n",
            "tensor(1.7782)\n",
            "tensor(0.4646)\n",
            "tensor(0.2601)\n",
            "tensor(0.1478)\n",
            "tensor(0.0836)\n",
            "tensor(0.0483)\n",
            "tensor(0.0298)\n",
            "tensor(0.0203)\n",
            "tensor(0.0151)\n",
            "tensor(0.0121)\n",
            "tensor(0.0101)\n",
            "tensor(0.0086)\n",
            "tensor(0.0075)\n",
            "tensor(0.0065)\n",
            "tensor(0.0057)\n",
            "tensor(0.0051)\n",
            "tensor(0.0045)\n",
            "tensor(0.0040)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaJSvKr-1SiW",
        "colab_type": "code",
        "outputId": "dd46b909-67b8-4379-f12a-738f6f8aed6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "model(data)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0205],\n",
              "        [-0.0378],\n",
              "        [ 0.9581],\n",
              "        [ 1.0030]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQj85l901Sid",
        "colab_type": "text"
      },
      "source": [
        "## Encrypt the Model and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEhK7gCo1Sif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_model = model.fix_precision().share(alice, bob, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q-pjvQR1Siq",
        "colab_type": "code",
        "outputId": "13c3f61f-34a8-4bab-84d2-56537bd88ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "list(encrypted_model.parameters())"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
              " \t-> [PointerTensor | me:96788805685 -> alice:71262364326]\n",
              " \t-> [PointerTensor | me:16502040509 -> bob:2593113142]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
              " \t-> [PointerTensor | me:48916567397 -> alice:77179339694]\n",
              " \t-> [PointerTensor | me:69010484742 -> bob:81548539522]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
              " \t-> [PointerTensor | me:12874090904 -> alice:89626093199]\n",
              " \t-> [PointerTensor | me:16880910293 -> bob:86340431345]\n",
              " \t*crypto provider: secure_worker*, Parameter containing:\n",
              " Parameter>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
              " \t-> [PointerTensor | me:90895915120 -> alice:33756292886]\n",
              " \t-> [PointerTensor | me:4821978776 -> bob:63756350805]\n",
              " \t*crypto provider: secure_worker*]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I1_UpsF1Siz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_data = data.fix_precision().share(alice, bob, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT5gSr-y1Si8",
        "colab_type": "code",
        "outputId": "130a527a-dea3-4d9c-cc6d-7e5ca0cad819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "encrypted_data"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
              "\t-> [PointerTensor | me:90836164363 -> alice:86998333138]\n",
              "\t-> [PointerTensor | me:88665994108 -> bob:34988800405]\n",
              "\t*crypto provider: secure_worker*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feSxDnah1SjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encrypted_prediction = encrypted_model(encrypted_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBAMSbRw1SjM",
        "colab_type": "code",
        "outputId": "8e5f69af-d532-4a65-eef4-69c16e36ea97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "encrypted_prediction.get().float_precision()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0200],\n",
              "        [-0.0380],\n",
              "        [ 0.9550],\n",
              "        [ 1.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB7uy1Y81SjU",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Encrypted Deep Learning in Keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MePG7vB1SjW",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Public Training\n",
        "\n",
        "Welcome to this tutorial! In the following notebooks you will learn how to provide private predictions. By private predictions, we mean that the data is constantly encrypted throughout the entire process. At no point is the user sharing raw data, only encrypted (that is, secret shared) data. In order to provide these private predictions, Syft Keras uses a library called [TF Encrypted](https://github.com/tf-encrypted/tf-encrypted) under the hood. TF Encrypted combines cutting-edge cryptographic and machine learning techniques, but you don't have to worry about this and can focus on your machine learning application.\n",
        "\n",
        "You can start serving private predictions with only three steps:\n",
        "- **Step 1**: train your model with normal Keras.\n",
        "- **Step 2**: secure and serve your machine learning model (server).\n",
        "- **Step 3**: query the secured model to receive private predictions (client). \n",
        "\n",
        "Alright, let's go through these three steps so you can deploy impactful machine learning services without sacrificing user privacy or model security.\n",
        "\n",
        "Huge shoutout to the Dropout Labs ([@dropoutlabs](https://twitter.com/dropoutlabs)) and TF Encrypted ([@tf_encrypted](https://twitter.com/tf_encrypted)) teams for their great work which makes this demo possible, especially: Jason Mancuso ([@jvmancuso](https://twitter.com/jvmancuso)), Yann Dupis ([@YannDupis](https://twitter.com/YannDupis)), and Morten Dahl ([@mortendahlcs](https://github.com/mortendahlcs)). \n",
        "\n",
        "_Demo Ref: https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYikqlhJ1SjX",
        "colab_type": "text"
      },
      "source": [
        "## Train Your Model in Keras\n",
        "\n",
        "To use privacy-preserving machine learning techniques for your projects you should not have to learn a new machine learning framework. If you have basic [Keras](https://keras.io/) knowledge, you can start using these techniques with Syft Keras. If you have never used Keras before, you can learn a bit more about it through the [Keras documentation](https://keras.io). \n",
        "\n",
        "Before serving private predictions, the first step is to train your model with normal Keras. As an example, we will train a model to classify handwritten digits. To train this model we will use the canonical [MNIST dataset](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "We borrow [this example](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py) from the reference Keras repository.  To train your classification model, you just run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EPjKtIX1SjZ",
        "colab_type": "code",
        "outputId": "20d8e964-81e4-4a68-b5d2-4df492a24050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10, (3, 3), input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0807 01:13:06.251907 139885005793152 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 22s 364us/sample - loss: 2.3022 - acc: 0.0938 - val_loss: 2.3010 - val_acc: 0.1002\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 21s 356us/sample - loss: 2.3005 - acc: 0.0959 - val_loss: 2.2992 - val_acc: 0.1019\n",
            "Test loss: 2.299177756500244\n",
            "Test accuracy: 0.1019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQSWSYrK1Sjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Save your model's weights for future private prediction\n",
        "model.save('short-conv-mnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAoOm9jR1Sjx",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Load and Serve the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2pYsdZS1Sjz",
        "colab_type": "text"
      },
      "source": [
        "Now that you have a trained model with normal Keras, you are ready to serve some private predictions. We can do that using Syft Keras.\n",
        "\n",
        "To secure and serve this model, we will need three TFEWorkers (servers). This is because TF Encrypted under the hood uses an encryption technique called [multi-party computation (MPC)](https://en.wikipedia.org/wiki/Secure_multi-party_computation). The idea is to split the model weights and input data into shares, then send a share of each value to the different servers. The key property is that if you look at the share on one server, it reveals nothing about the original value (input data or model weights).\n",
        "\n",
        "We'll define a Syft Keras model like we did in the previous notebook. However, there is a trick: before instantiating this model, we'll run `hook = sy.KerasHook(tf.keras)`. This will add three important new methods to the Keras Sequential class:\n",
        " - `share`: will secure your model via secret sharing; by default, it will use the SecureNN protocol from TF Encrypted to secret share your model between each of the three TFEWorkers. Most importantly, this will add the capability of providing predictions on encrypted data.\n",
        " - `serve`: this function will launch a serving queue, so that the TFEWorkers can can accept prediction requests on the secured model from external clients.\n",
        " - `shutdown_workers`: once you are done providing private predictions, you can shut down your model by running this function. It will direct you to shutdown the server processes manually if you've opted to manually manage each worker.\n",
        "\n",
        "If you want learn more about MPC, you can read this excellent [blog](https://mortendahl.github.io/2017/04/17/private-deep-learning-with-mpc/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2311ZTy1Sj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Activation, Flatten, ReLU, Activation\n",
        "\n",
        "import syft as sy\n",
        "hook = sy.KerasHook(tf.keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2ZS6vEx1Sj5",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "As you can see, we define almost the exact same model as before, except we provide a `batch_input_shape`. This allows TF Encrypted to better optimize the secure computations via predefined tensor shapes. For this MNIST demo, we'll send input data with the shape of (1, 28, 28, 1). \n",
        "We also return the logit instead of softmax because this operation is complex to perform using MPC, and we don't need it to serve prediction requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5L68U4o1Sj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (1, 28, 28, 1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10, (3, 3), batch_input_shape=input_shape))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(AveragePooling2D((2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, name=\"logit\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IaVvtSL1SkE",
        "colab_type": "text"
      },
      "source": [
        "### Load Pre-trained Weights\n",
        "\n",
        "With `load_weights` you can easily load the weights you have saved previously after training your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMN0xWKb1SkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_weights = 'short-conv-mnist.h5'\n",
        "model.load_weights(pre_trained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJspZ4wn1SkK",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Setup Your Worker Connectors\n",
        "\n",
        "Let's now connect to the TFEWorkers (`alice`, `bob`, and `carol`) required by TF Encrypted to perform private predictions. For each TFEWorker, you just have to specify a host.\n",
        "\n",
        "These workers run a [TensorFlow server](https://www.tensorflow.org/api_docs/python/tf/distribute/Server), which you can either manage manually (`AUTO = False`) or ask the workers to manage for you (`AUTO = True`). If choosing to manually manage them, you will be instructed to execute a terminal command on each worker's host device after calling `model.share()` below.  If all workers are hosted on a single device (e.g. `localhost`), you can choose to have Syft automatically manage the worker's TensorFlow server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c8DAPuN1SkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTO = False\n",
        "\n",
        "alice = sy.TFEWorker(host='localhost:4000', auto_managed=AUTO)\n",
        "bob = sy.TFEWorker(host='localhost:4001', auto_managed=AUTO)\n",
        "carol = sy.TFEWorker(host='localhost:4002', auto_managed=AUTO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj41nj7_1SkQ",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Split the Model Into Shares\n",
        "\n",
        "Thanks to `sy.KerasHook(tf.keras)` you can call the `share` method to transform your model into a TF Encrypted Keras model.\n",
        "\n",
        "If you have asked to manually manage servers above then this step will not complete until they have all been launched. Note that your firewall may ask for Python to accept incoming connection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EXxy8Hj1SkU",
        "colab_type": "code",
        "outputId": "c96b2dbb-4617-4631-dd16-93bb71b4be1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "model.share(alice, bob, carol)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-5b486064ddb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: share() takes from 2 to 3 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfq4eCkW1Ska",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Launch 3 Servers\n",
        "\n",
        "```\n",
        "python -m tf_encrypted.player --config /tmp/tfe.config server0\n",
        "python -m tf_encrypted.player --config /tmp/tfe.config server1\n",
        "python -m tf_encrypted.player --config /tmp/tfe.config server2```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6_FkZkv1Skb",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Serve the Model\n",
        "\n",
        "Perfect! Now by calling `model.serve`, your model is ready to provide some private predictions. You can set `num_requests` to set a limit on the number of predictions requests served by the model; if not specified then the model will be served until interrupted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m90FVTE_1Skc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.serve(num_requests=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll5-M5X41Skk",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Run the Client\n",
        "\n",
        "At this point open up and run the companion notebook: Section 4b - Encrytped Keras Client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45UXMU301Skm",
        "colab_type": "text"
      },
      "source": [
        "## Step 8: Shutdown the Servers\n",
        "\n",
        "Once your request limit above, the model will no longer be available for serving requests, but it's still secret shared between the three workers above. You can kill the workers by executing the cell below.\n",
        "\n",
        "**Congratulations** on finishing Part 12: Secure Classification with Syft Keras and TFE!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ICXjCoO1Skr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.shutdown_workers()\n",
        "\n",
        "if not AUTO:\n",
        "    process_ids = !ps aux | grep '[p]ython -m tf_encrypted.player --config /tmp/tfe.config' | awk '{print $2}'\n",
        "    for process_id in process_ids:\n",
        "        !kill {process_id}\n",
        "        print(\"Process ID {id} has been killed.\".format(id=process_id))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YAjsn711Skz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2O9EBzD1Sk8",
        "colab_type": "text"
      },
      "source": [
        "# Keystone Project - Mix and Match What You've Learned\n",
        "\n",
        "Description: Take two of the concepts you've learned about in this course (Encrypted Computation, Federated Learning, Differential Privacy) and combine them for a use case of your own design. Extra credit if you can get your demo working with [WebSocketWorkers](https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials/advanced/websockets-example-MNIST) instead of VirtualWorkers! Then take your demo or example application, write a blogpost, and share that blogpost in #general-discussion on OpenMined's slack!!!\n",
        "\n",
        "Inspiration:\n",
        "- This Course's Code: https://github.com/Udacity/private-ai\n",
        "- OpenMined's Tutorials: https://github.com/OpenMined/PySyft/tree/dev/examples/tutorials\n",
        "- OpenMined's Blog: https://blog.openmined.org"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDMwWxxh1Sk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEcRs2Sz1SlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohiaiDEM1SlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzSP4MFW1Slm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFBhDikV1Slq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqEn98MW1Slx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFwiut451Sl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mM2g1Ms1Sl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWcAj9Y91SmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_jNSIi91SmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyPYsXY_1SmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QBOZ-Fv1SmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHMKN0NF1Smc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX5jjO4N1Smh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjcQ5QOO1Smp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDK9BXYw1Smv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wykwjlq1Sm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S3GPRbZ1SnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMOJ7cCq1SnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}