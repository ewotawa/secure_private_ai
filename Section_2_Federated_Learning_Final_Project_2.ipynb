{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 2 - Federated Learning Final Project 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewotawa/secure_private_ai/blob/master/Section_2_Federated_Learning_Final_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM6v2FitGLvc",
        "colab_type": "text"
      },
      "source": [
        "# Federated Learning Final Project\n",
        "\n",
        "## Overview\n",
        "* See  <a href=\"https://classroom.udacity.com/nanodegrees/nd185/parts/3fe1bb10-68d7-4d84-9c99-9539dedffad5/modules/28d685f0-0cb1-4f94-a8ea-2e16614ab421/lessons/c8fe481d-81ea-41be-8206-06d2deeb8575/concepts/a5fb4b4c-e38a-48de-b2a7-4e853c62acbe\">video</a> for additional details. \n",
        "* Do Federated Learning where the central server is not trusted with the raw gradients.  \n",
        "* In the final project notebook, you'll receive a dataset.  \n",
        "* Train on the dataset using Federated Learning.  \n",
        "* The gradients should not come up to the server in raw form.  \n",
        "* Instead, use the new .move() command to move all of the gradients to one of the workers, sum them up there, and then bring that batch up to the central server and then bring that batch up \n",
        "* Idea: the central server never actually sees the raw gradient for any person.  \n",
        "* We'll look at secure aggregation in course 3.  \n",
        "* For now, do a larger-scale Federated Learning case where you handle the gradients in a special way.\n",
        "\n",
        "## Approach\n",
        "* Reviewing methods of classmates for Federated Learning. \n",
        "\n",
        "## References\n",
        "*  <a href = \"https://github.com/edgarinvillegas/private-ai/blob/master/Section%203%20-%20Final%20project.ipynb/\">GitHub Notebook</a>\n",
        "* <a href = \"https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2010%20-%20Federated%20Learning%20with%20Secure%20Aggregation.ipynb\">Part 10: Federated Learning with Encrypted Gradient Aggregation</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCOI3fXnGWr0",
        "colab_type": "text"
      },
      "source": [
        "### Install libraries and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGKXOXqmF8TZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2d80aa2-3b90-49f7-fdc3-5e7a2d5af7b0"
      },
      "source": [
        "# PySyft\n",
        "\n",
        "!pip install syft\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "# PyTorch\n",
        "\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Numpy\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 9.7MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d2/bf72435a7d56f94b57efdeae26c76bf0d16f409fd44ff595da745c3fbefd/websockets-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Collecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 51.5MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Collecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 49.4MB/s \n",
            "\u001b[?25hCollecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 58.7MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 57.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 25.1MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 57.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: websockets, websocket-client, zstd, python-engineio, python-socketio, flask-socketio, pyyaml, tf-encrypted, lz4, msgpack, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.7 websocket-client-0.56.0 websockets-8.0.1 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0721 19:27:25.114496 140153441781632 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0721 19:27:25.129579 140153441781632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrMvtqXSHd9i",
        "colab_type": "text"
      },
      "source": [
        "###  Recall Toy Federated Learning\n",
        "\n",
        "Use the data and model from Section 2\n",
        "\n",
        "- a toy dataset\n",
        "- a model\n",
        "- some basic training logic for training a model to fit the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI096VvCHCVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Dataset\n",
        "data = torch.tensor([[1.,1],[0,1],[1,0],[0,0]], requires_grad=True)\n",
        "target = torch.tensor([[1.],[1], [0], [0]], requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5IEgR_LH5RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Model\n",
        "model = nn.Linear(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOGXMlEkH8P1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer\n",
        "opt = optim.SGD(params=model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vanu9rXIV3k",
        "colab_type": "text"
      },
      "source": [
        "### Federated Learning\n",
        "\n",
        "Set up hook, virtual workers, and virtual aggregator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkNHvMkJIVSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "vw00 = sy.VirtualWorker(hook, id=\"vw00\")\n",
        "vw01 = sy.VirtualWorker(hook, id=\"vw01\")\n",
        "\n",
        "aggr = sy.VirtualWorker(hook, id=\"aggr\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zu-lAUzRuTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vw00.clear_objects()\n",
        "vw01.clear_objects()\n",
        "aggr.clear_objects()\n",
        "\n",
        "compute_nodes = [vw00, vw01]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSrPCbiGIk7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "42df9861-846f-4439-a8f0-5aa13d26e090"
      },
      "source": [
        "data_vw00 = data[0:2].send(vw00)\n",
        "target_vw00 = target[0:2].send(vw00)\n",
        "\n",
        "vw00._objects"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{33131537139: tensor([[1., 1.],\n",
              "         [0., 1.]], requires_grad=True), 56770717889: tensor([[1.],\n",
              "         [1.]], requires_grad=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVk2J-Q4IrAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f6d5fe8e-dc89-404b-82d1-9208a8ef3532"
      },
      "source": [
        "data_vw01 = data[2:4].send(vw01)\n",
        "target_vw01 = target[2:4].send(vw01)\n",
        "\n",
        "vw01._objects"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4977808065: tensor([[1., 0.],\n",
              "         [0., 0.]], requires_grad=True), 20190781258: tensor([[0.],\n",
              "         [0.]], requires_grad=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE_1M0b1IyOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = [(data_vw00, target_vw00), (data_vw01, target_vw01)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqfmssraMmnc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "253a53a1-c5fa-4326-8554-94ebf7ec0ff6"
      },
      "source": [
        "vw00_m = nn.Linear(2,1).send('vw00')\n",
        "vw01_m = nn.Linear(2,1).send('vw01')\n",
        "\n",
        "models = [vw00_m, vw01_m]\n",
        "print('models: \\n', models)\n",
        "\n",
        "vw00_o = optim.SGD(params=models[0].parameters(), lr=0.1)\n",
        "vw01_o = optim.SGD(params=models[1].parameters(), lr=0.1)\n",
        "\n",
        "opts = [vw00_o, vw01_o]\n",
        "print('\\noptimizers: \\n', opts)\n",
        "\n",
        "vw00_p = list(models[0].parameters())\n",
        "vw01_p = list(models[1].parameters())\n",
        "\n",
        "params = [vw00_p, vw01_p]\n",
        "print('\\nparameters: \\n', params)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models: \n",
            " [Linear(in_features=2, out_features=1, bias=True), Linear(in_features=2, out_features=1, bias=True)]\n",
            "\n",
            "optimizers: \n",
            " [SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            "), SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")]\n",
            "\n",
            "parameters: \n",
            " [[Parameter containing:\n",
            "Parameter>[PointerTensor | me:16636253281 -> vw00:32115523423], Parameter containing:\n",
            "Parameter>[PointerTensor | me:32201929280 -> vw00:24923104342]], [Parameter containing:\n",
            "Parameter>[PointerTensor | me:79356677133 -> vw01:62241726400], Parameter containing:\n",
            "Parameter>[PointerTensor | me:14087045917 -> vw01:62576430508]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zwHPn6FI6bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fed_train(iterations=20):\n",
        "\n",
        "    for iter in range(iterations):\n",
        "        \n",
        "        print('iter: \\t', iter)\n",
        "\n",
        "        for i in range(len(compute_nodes)): \n",
        "          # locate the data, identify model, optimizer by dataset ids\n",
        "          data = datasets[i][0]\n",
        "          target = datasets[i][1]\n",
        "          \n",
        "          worker_id = data.location.id\n",
        "          model = models[i]\n",
        "          opt = opts[i]\n",
        "          \n",
        "\n",
        "          print(\"data location: \", data.location, \"\\tworker ID: \", worker_id)\n",
        "\n",
        "          # do normal training\n",
        "          opt.zero_grad()\n",
        "          pred = model(data)\n",
        "          loss = ((pred - target)**2).sum()\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "\n",
        "    return models, params\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBvQNMDcJZUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03801772-d9a8-49e2-8098-dd40a9dc9640"
      },
      "source": [
        "models, params = fed_train()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter: \t 0\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 1\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 2\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 3\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 4\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 5\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 6\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 7\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 8\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 9\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 10\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 11\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 12\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 13\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 14\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 15\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 16\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 17\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 18\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "iter: \t 19\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDplfWolWIm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1408408f-42b0-428f-e6b1-a487541d9c86"
      },
      "source": [
        "print(models)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Linear(in_features=2, out_features=1, bias=True), Linear(in_features=2, out_features=1, bias=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xghCTwuP5Sa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "587830b3-ed8f-4223-eb13-14c8eb419aaf"
      },
      "source": [
        "print(params)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[Parameter containing:\n",
            "Parameter>[PointerTensor | me:16636253281 -> vw00:32115523423], Parameter containing:\n",
            "Parameter>[PointerTensor | me:32201929280 -> vw00:24923104342]], [Parameter containing:\n",
            "Parameter>[PointerTensor | me:79356677133 -> vw01:62241726400], Parameter containing:\n",
            "Parameter>[PointerTensor | me:14087045917 -> vw01:62576430508]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8mFqh9I3tIO",
        "colab_type": "text"
      },
      "source": [
        "### Encrypted Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGWdbJvI3nB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create list to deposit encrypted averages\n",
        "new_params = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUhwt5mPAl-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0f8f6f0f-ec88-4e8e-a764-6223e0cadf30"
      },
      "source": [
        "print(len(params[0]))\n",
        "print(len(compute_nodes))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S793SeG379H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# iterate through each parameter\n",
        "for param_i in range(len(params[0])):\n",
        "  \n",
        "  # for each worker\n",
        "  spdz_params = list()\n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    \n",
        "    # select the identical parameter from each worker and copy it\n",
        "    copy_of_parameter = params[remote_index][param_i].copy()\n",
        "    \n",
        "    # SMPC can only work with integers (not floats). Use Integers to store decimal information.\n",
        "    # Use fixed precision encoding.\n",
        "    fixed_precision_param = copy_of_parameter\n",
        "    \n",
        "    # encrypt on the remote machine. \n",
        "    # note: fixed_precision_param is already a pointer. \n",
        "    # calling share encrypts the data to which it is pointing.\n",
        "    # returns a pointer to MPC secret shared object; need to fetch.\n",
        "    encrypted_param = fixed_precision_param.share(vw00, vw01, crypto_provider=aggr)\n",
        "    \n",
        "    # fetch the pointer to MPC shared value\n",
        "    param = encrypted_param.get()\n",
        "    \n",
        "    # save the parameter so that can average it with same parameter from other workers\n",
        "    spdz_params.append(param)\n",
        "    \n",
        "  # average params from multiple workers, fetch to local machine\n",
        "  # decrypt and decode (from fixed precision) back to floating point number\n",
        "  new_param = (spdz_params[0] + spdz_params[1]).get() / 2\n",
        "  \n",
        "  # save the new averaged parameter\n",
        "  new_params.append(new_param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgdv2NB238G3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "457ddcb7-f51a-4372-ff1d-628afff732b7"
      },
      "source": [
        "print(new_params)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[0, 0]]), tensor([0])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcOwRFT7EY2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "ed2e1086-5b47-4646-e96a-d15e410cde9c"
      },
      "source": [
        "# cleanup\n",
        "with torch.no_grad():\n",
        "  for model in params: \n",
        "    \n",
        "    for param in model: \n",
        "      param *= 0\n",
        "      \n",
        "    for model in models:\n",
        "      model.get()\n",
        "    \n",
        "    for remote_index in range(len(compute_nodes)):\n",
        "      for param_index in range(len(params[remote_index])):\n",
        "        params[remote_index][param_index].set_(new_params[param_index])"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-89797ba01e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mremote_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mparam_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Long for argument #2 'source'"
          ]
        }
      ]
    }
  ]
}