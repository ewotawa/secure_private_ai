{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 2 - Federated Learning Final Project 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewotawa/secure_private_ai/blob/master/Section_2_Federated_Learning_Final_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM6v2FitGLvc",
        "colab_type": "text"
      },
      "source": [
        "# Federated Learning Final Project\n",
        "\n",
        "## Overview\n",
        "* See  <a href=\"https://classroom.udacity.com/nanodegrees/nd185/parts/3fe1bb10-68d7-4d84-9c99-9539dedffad5/modules/28d685f0-0cb1-4f94-a8ea-2e16614ab421/lessons/c8fe481d-81ea-41be-8206-06d2deeb8575/concepts/a5fb4b4c-e38a-48de-b2a7-4e853c62acbe\">video</a> for additional details. \n",
        "* Do Federated Learning where the central server is not trusted with the raw gradients.  \n",
        "* In the final project notebook, you'll receive a dataset.  \n",
        "* Train on the dataset using Federated Learning.  \n",
        "* The gradients should not come up to the server in raw form.  \n",
        "* Instead, use the new .move() command to move all of the gradients to one of the workers, sum them up there, and then bring that batch up to the central server and then bring that batch up \n",
        "* Idea: the central server never actually sees the raw gradient for any person.â€¯ \n",
        "* We'll look at secure aggregation in course 3.  \n",
        "* For now, do a larger-scale Federated Learning case where you handle the gradients in a special way.\n",
        "\n",
        "## Approach\n",
        "* Reviewing methods of classmates for Federated Learning. \n",
        "\n",
        "## References\n",
        "*  <a href = \"https://github.com/edgarinvillegas/private-ai/blob/master/Section%203%20-%20Final%20project.ipynb/\">GitHub Notebook</a>\n",
        "* <a href = \"https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2010%20-%20Federated%20Learning%20with%20Secure%20Aggregation.ipynb\">Part 10: Federated Learning with Encrypted Gradient Aggregation</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCOI3fXnGWr0",
        "colab_type": "text"
      },
      "source": [
        "### Install libraries and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGKXOXqmF8TZ",
        "colab_type": "code",
        "outputId": "862dbdc1-c8b0-4a50-d60d-1bbb8719a885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "# PySyft\n",
        "\n",
        "!pip install syft\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "# PyTorch\n",
        "\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# time\n",
        "\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages (0.1.21a1)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.0.1)\n",
            "Requirement already satisfied: flask-socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from syft) (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: websocket-client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.56.0)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.1.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: tf-encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.7)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 01:21:48.830574 140093551527808 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0723 01:21:48.855294 140093551527808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vanu9rXIV3k",
        "colab_type": "text"
      },
      "source": [
        "### Normal Federated Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUQ84pJSQGqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Establish a parser to contain parameters for training\n",
        "\n",
        "class Parser: \n",
        "  def __init__(self):\n",
        "    self.epochs = 10\n",
        "    self.lr = 0.001\n",
        "    self.test_batch_size = 1\n",
        "    self.batch_size = 1\n",
        "    self.log_interval = 10\n",
        "    self.seed = 1\n",
        "    \n",
        "args = Parser()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "kwargs = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI096VvCHCVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Dataset\n",
        "\n",
        "data = torch.randn(50, 2, requires_grad=True) \n",
        "target = torch.randn(50, 1, requires_grad=True) \n",
        "\n",
        "data_test = torch.randn(50, 2, requires_grad=True) \n",
        "target_test = torch.randn(50, 1, requires_grad=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk3eED_kPuoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = TensorDataset(data, target)\n",
        "test = TensorDataset(data_test, target_test)\n",
        "\n",
        "trainloader = DataLoader(train, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "testloader = DataLoader(test, batch_size=args.test_batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5IEgR_LH5RE",
        "colab_type": "code",
        "outputId": "71fbd847-9b4d-4ad1-f7da-69a0c6a15352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# A Toy Model\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(2,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "# model = nn.Linear(2,1)\n",
        "\n",
        "model = Net() \n",
        "\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOGXMlEkH8P1",
        "colab_type": "code",
        "outputId": "31973ccb-ce26-4e1c-d256-e684abca1ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Optimizer\n",
        "opt = optim.SGD(params=model.parameters(), lr=args.lr)\n",
        "print(opt)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moXQNSWnOCzL",
        "colab_type": "text"
      },
      "source": [
        "Set up hook, virtual workers, and virtual aggregator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkNHvMkJIVSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "vw00 = sy.VirtualWorker(hook, id=\"vw00\")\n",
        "vw01 = sy.VirtualWorker(hook, id=\"vw01\")\n",
        "\n",
        "aggr = sy.VirtualWorker(hook, id=\"aggr\")\n",
        "\n",
        "compute_nodes = [vw00, vw01]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zu-lAUzRuTK",
        "colab_type": "code",
        "outputId": "c08f2645-e11f-43a7-f638-7df4ae116e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vw00.clear_objects()\n",
        "vw01.clear_objects()\n",
        "aggr.clear_objects()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:aggr #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqKMB3YFTavk",
        "colab_type": "code",
        "outputId": "dbdfcf31-e677-4ed0-f317-ecbd1e8f500f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Send data to the workers\n",
        "train_dist_dataset = []\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(trainloader):\n",
        "  data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  train_dist_dataset.append((data, target))\n",
        "  \n",
        "print(train_dist_dataset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[((Wrapper)>[PointerTensor | me:23057976256 -> vw00:74434554886], (Wrapper)>[PointerTensor | me:78022778411 -> vw00:71221936494]), ((Wrapper)>[PointerTensor | me:94649119312 -> vw01:29352242619], (Wrapper)>[PointerTensor | me:48998014840 -> vw01:3068112642]), ((Wrapper)>[PointerTensor | me:94957918638 -> vw00:98460832350], (Wrapper)>[PointerTensor | me:531957120 -> vw00:29260999285]), ((Wrapper)>[PointerTensor | me:12904795259 -> vw01:79023830739], (Wrapper)>[PointerTensor | me:26971837612 -> vw01:28527986412]), ((Wrapper)>[PointerTensor | me:95576926687 -> vw00:69814432694], (Wrapper)>[PointerTensor | me:34637773911 -> vw00:111067070]), ((Wrapper)>[PointerTensor | me:57091636702 -> vw01:76557673477], (Wrapper)>[PointerTensor | me:50997522599 -> vw01:46841931117]), ((Wrapper)>[PointerTensor | me:16848481345 -> vw00:34213218728], (Wrapper)>[PointerTensor | me:70543753909 -> vw00:47363178782]), ((Wrapper)>[PointerTensor | me:27010973785 -> vw01:11569731442], (Wrapper)>[PointerTensor | me:62064313823 -> vw01:98753626913]), ((Wrapper)>[PointerTensor | me:21146917036 -> vw00:42247055014], (Wrapper)>[PointerTensor | me:69968418311 -> vw00:44826510977]), ((Wrapper)>[PointerTensor | me:37910986853 -> vw01:61797695939], (Wrapper)>[PointerTensor | me:23437636516 -> vw01:42074104367]), ((Wrapper)>[PointerTensor | me:62479454075 -> vw00:35835503208], (Wrapper)>[PointerTensor | me:71576188089 -> vw00:60334806572]), ((Wrapper)>[PointerTensor | me:65194556868 -> vw01:68413330551], (Wrapper)>[PointerTensor | me:71118236083 -> vw01:99368997181]), ((Wrapper)>[PointerTensor | me:41436235861 -> vw00:16487862879], (Wrapper)>[PointerTensor | me:21990389290 -> vw00:7742361441]), ((Wrapper)>[PointerTensor | me:99442544536 -> vw01:47757616544], (Wrapper)>[PointerTensor | me:68955772673 -> vw01:6985563143]), ((Wrapper)>[PointerTensor | me:97783767217 -> vw00:23066241065], (Wrapper)>[PointerTensor | me:53126689352 -> vw00:63479498132]), ((Wrapper)>[PointerTensor | me:54434322587 -> vw01:98384067955], (Wrapper)>[PointerTensor | me:76427768866 -> vw01:763080570]), ((Wrapper)>[PointerTensor | me:39077860160 -> vw00:33387142871], (Wrapper)>[PointerTensor | me:49395749525 -> vw00:14926623534]), ((Wrapper)>[PointerTensor | me:92771548560 -> vw01:71826381886], (Wrapper)>[PointerTensor | me:74457260571 -> vw01:14098897887]), ((Wrapper)>[PointerTensor | me:2616767244 -> vw00:11070767850], (Wrapper)>[PointerTensor | me:57346287715 -> vw00:12421140938]), ((Wrapper)>[PointerTensor | me:96455216980 -> vw01:70516808239], (Wrapper)>[PointerTensor | me:43609120681 -> vw01:88646909929]), ((Wrapper)>[PointerTensor | me:58532883457 -> vw00:55605395463], (Wrapper)>[PointerTensor | me:67413731911 -> vw00:40545515025]), ((Wrapper)>[PointerTensor | me:70592937922 -> vw01:62852106642], (Wrapper)>[PointerTensor | me:14592307319 -> vw01:65769505881]), ((Wrapper)>[PointerTensor | me:99899381490 -> vw00:37250638364], (Wrapper)>[PointerTensor | me:10634135238 -> vw00:70794855525]), ((Wrapper)>[PointerTensor | me:84949049062 -> vw01:87208093946], (Wrapper)>[PointerTensor | me:91561808377 -> vw01:51376438561]), ((Wrapper)>[PointerTensor | me:58715921214 -> vw00:99568071651], (Wrapper)>[PointerTensor | me:761450252 -> vw00:83744334286]), ((Wrapper)>[PointerTensor | me:15345555263 -> vw01:58040074118], (Wrapper)>[PointerTensor | me:64041449188 -> vw01:12828390026]), ((Wrapper)>[PointerTensor | me:91822856831 -> vw00:67900984353], (Wrapper)>[PointerTensor | me:94414987696 -> vw00:94280143086]), ((Wrapper)>[PointerTensor | me:29155632419 -> vw01:3653077576], (Wrapper)>[PointerTensor | me:13594083970 -> vw01:91657469683]), ((Wrapper)>[PointerTensor | me:6239425863 -> vw00:57476121003], (Wrapper)>[PointerTensor | me:38382468994 -> vw00:25329332578]), ((Wrapper)>[PointerTensor | me:24504605978 -> vw01:37018729589], (Wrapper)>[PointerTensor | me:98376341049 -> vw01:54050048435]), ((Wrapper)>[PointerTensor | me:86474257206 -> vw00:47068396471], (Wrapper)>[PointerTensor | me:62868100536 -> vw00:7238068196]), ((Wrapper)>[PointerTensor | me:97733002264 -> vw01:38354132331], (Wrapper)>[PointerTensor | me:76984986931 -> vw01:68713164199]), ((Wrapper)>[PointerTensor | me:53887628496 -> vw00:57598627191], (Wrapper)>[PointerTensor | me:49247154501 -> vw00:634881260]), ((Wrapper)>[PointerTensor | me:95322083452 -> vw01:88996077673], (Wrapper)>[PointerTensor | me:44142270272 -> vw01:33851284064]), ((Wrapper)>[PointerTensor | me:8334727005 -> vw00:63026994767], (Wrapper)>[PointerTensor | me:33265948304 -> vw00:46848460688]), ((Wrapper)>[PointerTensor | me:69971268002 -> vw01:17611632217], (Wrapper)>[PointerTensor | me:43628388667 -> vw01:81894487592]), ((Wrapper)>[PointerTensor | me:40783299552 -> vw00:92529641825], (Wrapper)>[PointerTensor | me:22437360565 -> vw00:85129652313]), ((Wrapper)>[PointerTensor | me:25083161368 -> vw01:96626267920], (Wrapper)>[PointerTensor | me:25843448947 -> vw01:97514726119]), ((Wrapper)>[PointerTensor | me:62114129711 -> vw00:77267076409], (Wrapper)>[PointerTensor | me:56541647468 -> vw00:85518735606]), ((Wrapper)>[PointerTensor | me:65996537094 -> vw01:17839548583], (Wrapper)>[PointerTensor | me:55802643805 -> vw01:18561806459]), ((Wrapper)>[PointerTensor | me:37187415410 -> vw00:55788352808], (Wrapper)>[PointerTensor | me:60588742293 -> vw00:98081762434]), ((Wrapper)>[PointerTensor | me:59852472587 -> vw01:7260389901], (Wrapper)>[PointerTensor | me:98762436504 -> vw01:38308555067]), ((Wrapper)>[PointerTensor | me:12855634618 -> vw00:99364074251], (Wrapper)>[PointerTensor | me:76118314813 -> vw00:38143253833]), ((Wrapper)>[PointerTensor | me:70423813485 -> vw01:90226027160], (Wrapper)>[PointerTensor | me:61917287646 -> vw01:20677130593]), ((Wrapper)>[PointerTensor | me:93142411716 -> vw00:34540993417], (Wrapper)>[PointerTensor | me:69242513950 -> vw00:95955729612]), ((Wrapper)>[PointerTensor | me:1946210236 -> vw01:60023362368], (Wrapper)>[PointerTensor | me:22820227170 -> vw01:80014476801]), ((Wrapper)>[PointerTensor | me:86259896348 -> vw00:16421508257], (Wrapper)>[PointerTensor | me:35408348351 -> vw00:94873031678]), ((Wrapper)>[PointerTensor | me:97522197712 -> vw01:20751282449], (Wrapper)>[PointerTensor | me:38882429633 -> vw01:69529543058]), ((Wrapper)>[PointerTensor | me:62382773627 -> vw00:71611344200], (Wrapper)>[PointerTensor | me:69204271789 -> vw00:65465751065]), ((Wrapper)>[PointerTensor | me:10616321722 -> vw01:83167855363], (Wrapper)>[PointerTensor | me:63523293656 -> vw01:22182922107])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_F9JxO5y9Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define loss function\n",
        "\n",
        "def loss_func(pred, target):\n",
        "  loss = ((pred - target)**2).sum()\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zwHPn6FI6bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training function\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  \n",
        "  for batch_idx, (data, target) in enumerate(train_dist_dataset):\n",
        "    # determine the active worker\n",
        "    worker = data.location\n",
        "    # send the model to the active worker\n",
        "    model.send(worker)\n",
        "    \n",
        "    # do normal training\n",
        "    opt.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = loss_func(pred, target)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    model.get()\n",
        "\n",
        "    if batch_idx % args.log_interval == 0:\n",
        "      loss = loss.get()\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss: {:.6f}'.format(\n",
        "        epoch, batch_idx, len(trainloader),\n",
        "          100. * batch_idx / len(trainloader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3S388XyXIug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing function\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  for data, target in testloader:\n",
        "    pred = model(data)\n",
        "    test_loss += loss_func(pred, target).item() # sum up batch loss\n",
        "    \n",
        "  test_loss /= len(testloader.dataset)\n",
        "  print('\\nTest Set: Average Loss: {:.4f}\\n'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZj1yCMzzpj",
        "colab_type": "code",
        "outputId": "526cceff-6206-4e2e-9e93-6e987a529b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "# train the model\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "  train(epoch)\n",
        "  \n",
        "total_time = time.time() - t\n",
        "print('total', round(total_time, 2), 'sec')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50 (0%)]\tloss: 2.548004\n",
            "Train Epoch: 1 [10/50 (20%)]\tloss: 1.465525\n",
            "Train Epoch: 1 [20/50 (40%)]\tloss: 1.308707\n",
            "Train Epoch: 1 [30/50 (60%)]\tloss: 0.103834\n",
            "Train Epoch: 1 [40/50 (80%)]\tloss: 0.000071\n",
            "Train Epoch: 2 [0/50 (0%)]\tloss: 2.288096\n",
            "Train Epoch: 2 [10/50 (20%)]\tloss: 1.318819\n",
            "Train Epoch: 2 [20/50 (40%)]\tloss: 1.319915\n",
            "Train Epoch: 2 [30/50 (60%)]\tloss: 0.120199\n",
            "Train Epoch: 2 [40/50 (80%)]\tloss: 0.000036\n",
            "Train Epoch: 3 [0/50 (0%)]\tloss: 2.069994\n",
            "Train Epoch: 3 [10/50 (20%)]\tloss: 1.193838\n",
            "Train Epoch: 3 [20/50 (40%)]\tloss: 1.322092\n",
            "Train Epoch: 3 [30/50 (60%)]\tloss: 0.137194\n",
            "Train Epoch: 3 [40/50 (80%)]\tloss: 0.000446\n",
            "Train Epoch: 4 [0/50 (0%)]\tloss: 1.886120\n",
            "Train Epoch: 4 [10/50 (20%)]\tloss: 1.086949\n",
            "Train Epoch: 4 [20/50 (40%)]\tloss: 1.317107\n",
            "Train Epoch: 4 [30/50 (60%)]\tloss: 0.154615\n",
            "Train Epoch: 4 [40/50 (80%)]\tloss: 0.001332\n",
            "Train Epoch: 5 [0/50 (0%)]\tloss: 1.730398\n",
            "Train Epoch: 5 [10/50 (20%)]\tloss: 0.995188\n",
            "Train Epoch: 5 [20/50 (40%)]\tloss: 1.306569\n",
            "Train Epoch: 5 [30/50 (60%)]\tloss: 0.172268\n",
            "Train Epoch: 5 [40/50 (80%)]\tloss: 0.002692\n",
            "Train Epoch: 6 [0/50 (0%)]\tloss: 1.597936\n",
            "Train Epoch: 6 [10/50 (20%)]\tloss: 0.916121\n",
            "Train Epoch: 6 [20/50 (40%)]\tloss: 1.291839\n",
            "Train Epoch: 6 [30/50 (60%)]\tloss: 0.189977\n",
            "Train Epoch: 6 [40/50 (80%)]\tloss: 0.004501\n",
            "Train Epoch: 7 [0/50 (0%)]\tloss: 1.484778\n",
            "Train Epoch: 7 [10/50 (20%)]\tloss: 0.847747\n",
            "Train Epoch: 7 [20/50 (40%)]\tloss: 1.274053\n",
            "Train Epoch: 7 [30/50 (60%)]\tloss: 0.207586\n",
            "Train Epoch: 7 [40/50 (80%)]\tloss: 0.006713\n",
            "Train Epoch: 8 [0/50 (0%)]\tloss: 1.387714\n",
            "Train Epoch: 8 [10/50 (20%)]\tloss: 0.788412\n",
            "Train Epoch: 8 [20/50 (40%)]\tloss: 1.254141\n",
            "Train Epoch: 8 [30/50 (60%)]\tloss: 0.224958\n",
            "Train Epoch: 8 [40/50 (80%)]\tloss: 0.009275\n",
            "Train Epoch: 9 [0/50 (0%)]\tloss: 1.304126\n",
            "Train Epoch: 9 [10/50 (20%)]\tloss: 0.736747\n",
            "Train Epoch: 9 [20/50 (40%)]\tloss: 1.232861\n",
            "Train Epoch: 9 [30/50 (60%)]\tloss: 0.241977\n",
            "Train Epoch: 9 [40/50 (80%)]\tloss: 0.012127\n",
            "Train Epoch: 10 [0/50 (0%)]\tloss: 1.231869\n",
            "Train Epoch: 10 [10/50 (20%)]\tloss: 0.691614\n",
            "Train Epoch: 10 [20/50 (40%)]\tloss: 1.210818\n",
            "Train Epoch: 10 [30/50 (60%)]\tloss: 0.258547\n",
            "Train Epoch: 10 [40/50 (80%)]\tloss: 0.015207\n",
            "total 4.09 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af28LU0X0TGf",
        "colab_type": "code",
        "outputId": "1e20020c-cd4f-4c30-9560-a4334cf0bde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# calculating performance\n",
        "test()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.8006\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvfrM-2R2hnp",
        "colab_type": "text"
      },
      "source": [
        "### Add Encrypted Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsPiFsaM2gkj",
        "colab_type": "code",
        "outputId": "8efd850e-3aae-416e-be40-ad866329531f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Send data to the workers\n",
        "remote_dataset = (list(), list())\n",
        "\n",
        "train_dist_dataset = []\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(trainloader):\n",
        "  data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  remote_dataset[batch_idx % len(compute_nodes)].append((data, target))\n",
        "  \n",
        "\n",
        "print(remote_dataset)\n",
        "\n",
        "print(train_dist_dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([((Wrapper)>[PointerTensor | me:31192220479 -> vw00:18290419548], (Wrapper)>[PointerTensor | me:56859330528 -> vw00:28909432247]), ((Wrapper)>[PointerTensor | me:46971318934 -> vw00:43390385218], (Wrapper)>[PointerTensor | me:28431509042 -> vw00:3823324905]), ((Wrapper)>[PointerTensor | me:87717970918 -> vw00:43651640595], (Wrapper)>[PointerTensor | me:1800993000 -> vw00:72475751692]), ((Wrapper)>[PointerTensor | me:44479519180 -> vw00:56191800751], (Wrapper)>[PointerTensor | me:11059976197 -> vw00:57119073294]), ((Wrapper)>[PointerTensor | me:76246985749 -> vw00:32720019172], (Wrapper)>[PointerTensor | me:85259343275 -> vw00:8980836595]), ((Wrapper)>[PointerTensor | me:84570747535 -> vw00:52138823568], (Wrapper)>[PointerTensor | me:20867184953 -> vw00:24207539347]), ((Wrapper)>[PointerTensor | me:88075766084 -> vw00:11326470052], (Wrapper)>[PointerTensor | me:78972214920 -> vw00:65772199605]), ((Wrapper)>[PointerTensor | me:21597290794 -> vw00:19225691414], (Wrapper)>[PointerTensor | me:20152148584 -> vw00:15668848304]), ((Wrapper)>[PointerTensor | me:12523464613 -> vw00:87261782469], (Wrapper)>[PointerTensor | me:83768977172 -> vw00:82708268226]), ((Wrapper)>[PointerTensor | me:74013339674 -> vw00:23992813960], (Wrapper)>[PointerTensor | me:69223909028 -> vw00:10221497306]), ((Wrapper)>[PointerTensor | me:78189911561 -> vw00:65297237390], (Wrapper)>[PointerTensor | me:92809625992 -> vw00:62468114530]), ((Wrapper)>[PointerTensor | me:4802345791 -> vw00:3770564253], (Wrapper)>[PointerTensor | me:37240068785 -> vw00:63291590510]), ((Wrapper)>[PointerTensor | me:69357313585 -> vw00:41460286443], (Wrapper)>[PointerTensor | me:71880659819 -> vw00:95014153128]), ((Wrapper)>[PointerTensor | me:81242406378 -> vw00:31458990572], (Wrapper)>[PointerTensor | me:56482100730 -> vw00:21795946113]), ((Wrapper)>[PointerTensor | me:73078373825 -> vw00:168605972], (Wrapper)>[PointerTensor | me:24583288457 -> vw00:35846966312]), ((Wrapper)>[PointerTensor | me:10251058554 -> vw00:8082965842], (Wrapper)>[PointerTensor | me:32321510845 -> vw00:15292869360]), ((Wrapper)>[PointerTensor | me:85605602101 -> vw00:20068951639], (Wrapper)>[PointerTensor | me:76991381451 -> vw00:92460656265]), ((Wrapper)>[PointerTensor | me:96239080559 -> vw00:86968080422], (Wrapper)>[PointerTensor | me:58508361757 -> vw00:63559219706]), ((Wrapper)>[PointerTensor | me:75124571459 -> vw00:65542158988], (Wrapper)>[PointerTensor | me:97151342488 -> vw00:12230244574]), ((Wrapper)>[PointerTensor | me:68465886865 -> vw00:75134634091], (Wrapper)>[PointerTensor | me:23640029312 -> vw00:16191471538]), ((Wrapper)>[PointerTensor | me:59861110019 -> vw00:6459059582], (Wrapper)>[PointerTensor | me:7882127097 -> vw00:84598267430]), ((Wrapper)>[PointerTensor | me:86300709837 -> vw00:90984767676], (Wrapper)>[PointerTensor | me:76505337265 -> vw00:59764491717]), ((Wrapper)>[PointerTensor | me:55700038518 -> vw00:77160836501], (Wrapper)>[PointerTensor | me:49502414130 -> vw00:18061165439]), ((Wrapper)>[PointerTensor | me:53956185279 -> vw00:11512556102], (Wrapper)>[PointerTensor | me:99270854784 -> vw00:54048757729]), ((Wrapper)>[PointerTensor | me:6367830409 -> vw00:7672718159], (Wrapper)>[PointerTensor | me:30175663001 -> vw00:66181499197])], [((Wrapper)>[PointerTensor | me:19315786523 -> vw01:45543891369], (Wrapper)>[PointerTensor | me:46757521477 -> vw01:1097684419]), ((Wrapper)>[PointerTensor | me:58764145583 -> vw01:57754314216], (Wrapper)>[PointerTensor | me:30371469261 -> vw01:59263862471]), ((Wrapper)>[PointerTensor | me:23269200640 -> vw01:59903178478], (Wrapper)>[PointerTensor | me:68233284786 -> vw01:3539207396]), ((Wrapper)>[PointerTensor | me:54622242510 -> vw01:64171721532], (Wrapper)>[PointerTensor | me:55659301714 -> vw01:43852414825]), ((Wrapper)>[PointerTensor | me:90882527919 -> vw01:36255810398], (Wrapper)>[PointerTensor | me:80698548111 -> vw01:7995496903]), ((Wrapper)>[PointerTensor | me:41643510681 -> vw01:70190326680], (Wrapper)>[PointerTensor | me:51628265824 -> vw01:9876557100]), ((Wrapper)>[PointerTensor | me:35892519110 -> vw01:93537650811], (Wrapper)>[PointerTensor | me:73216106580 -> vw01:12345270358]), ((Wrapper)>[PointerTensor | me:56893225831 -> vw01:68873047610], (Wrapper)>[PointerTensor | me:70631323553 -> vw01:17281487279]), ((Wrapper)>[PointerTensor | me:16024948763 -> vw01:52449524053], (Wrapper)>[PointerTensor | me:33555189144 -> vw01:31526608311]), ((Wrapper)>[PointerTensor | me:27060903635 -> vw01:61094253891], (Wrapper)>[PointerTensor | me:84776920258 -> vw01:84343749853]), ((Wrapper)>[PointerTensor | me:23901629784 -> vw01:55368834558], (Wrapper)>[PointerTensor | me:80214781591 -> vw01:92734780217]), ((Wrapper)>[PointerTensor | me:37239668119 -> vw01:18757989918], (Wrapper)>[PointerTensor | me:41553864860 -> vw01:47265306274]), ((Wrapper)>[PointerTensor | me:99808285010 -> vw01:94952829273], (Wrapper)>[PointerTensor | me:32637063636 -> vw01:21417821589]), ((Wrapper)>[PointerTensor | me:547228078 -> vw01:69764029565], (Wrapper)>[PointerTensor | me:37180609683 -> vw01:11952027607]), ((Wrapper)>[PointerTensor | me:33048464257 -> vw01:7526314286], (Wrapper)>[PointerTensor | me:70125100118 -> vw01:20828216791]), ((Wrapper)>[PointerTensor | me:23751645137 -> vw01:40153733703], (Wrapper)>[PointerTensor | me:27916063619 -> vw01:47184176952]), ((Wrapper)>[PointerTensor | me:83264289943 -> vw01:78720982060], (Wrapper)>[PointerTensor | me:70958012634 -> vw01:47799555573]), ((Wrapper)>[PointerTensor | me:15096900339 -> vw01:97805379279], (Wrapper)>[PointerTensor | me:87238224894 -> vw01:56059276466]), ((Wrapper)>[PointerTensor | me:79014269482 -> vw01:99826520944], (Wrapper)>[PointerTensor | me:6142278292 -> vw01:45321958019]), ((Wrapper)>[PointerTensor | me:37818533702 -> vw01:32639870514], (Wrapper)>[PointerTensor | me:9188111578 -> vw01:16795926972]), ((Wrapper)>[PointerTensor | me:32294595079 -> vw01:19059868281], (Wrapper)>[PointerTensor | me:68345429851 -> vw01:99553653333]), ((Wrapper)>[PointerTensor | me:14868948544 -> vw01:82816144257], (Wrapper)>[PointerTensor | me:70743586241 -> vw01:24857498890]), ((Wrapper)>[PointerTensor | me:16203815251 -> vw01:70718168677], (Wrapper)>[PointerTensor | me:33629243066 -> vw01:55591928991]), ((Wrapper)>[PointerTensor | me:95833379130 -> vw01:90015768084], (Wrapper)>[PointerTensor | me:80196989658 -> vw01:70313779556]), ((Wrapper)>[PointerTensor | me:54260900043 -> vw01:75138848792], (Wrapper)>[PointerTensor | me:94269437373 -> vw01:58911381913])])\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-wPwQW03QKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to be able to send distinct model to each worker to train.\n",
        "\n",
        "def update(data, target, model, optimizer):\n",
        "  model.send(data.location)\n",
        "  optimizer.zero_grad()\n",
        "  pred = model(data)\n",
        "  loss = loss_func(pred, target)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rs_5FPc3oFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define worker-based models and optimizer\n",
        "\n",
        "vw00_model = Net()\n",
        "vw01_model = Net()\n",
        "\n",
        "vw00_optimizer = optim.SGD(vw00_model.parameters(), lr=args.lr)\n",
        "vw01_optimizer = optim.SGD(vw01_model.parameters(), lr=args.lr)\n",
        "\n",
        "models = [vw00_model, vw01_model]\n",
        "params = [list(vw00_model.parameters()), list(vw01_model.parameters())]\n",
        "optimizers = [vw00_optimizer, vw01_optimizer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3gBf6h64T45",
        "colab_type": "text"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y47sg78I4WwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select batch on which to train\n",
        "data_index = 0\n",
        "\n",
        "# update remote models\n",
        "# here, iterate once per model\n",
        "\n",
        "for remote_index in range(len(compute_nodes)):\n",
        "  data, target = remote_dataset[remote_index][data_index]\n",
        "  models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmLAKR1742Qe",
        "colab_type": "text"
      },
      "source": [
        "#### Encrypted Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdMDzV043vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list to store encrypted model average\n",
        "new_params = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIcDKd2ZVMil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "52b08bae-b518-4e82-a188-d67eddb3107d"
      },
      "source": [
        "# visualize the parameters\n",
        "for i in range(len(params[0])):\n",
        "  \n",
        "  # for each worker\n",
        "  spdz2_params = list()\n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    \n",
        "    lcop = params[remote_index][i].copy().get() \n",
        "    \n",
        "    print(\"\\nremote index: \", remote_index, \"\\n\")\n",
        "    print(lcop)\n",
        "    print(lcop.type())\n",
        "    \n",
        "    lcop_th = lcop * 10000\n",
        "    print(lcop_th)\n",
        "    \n",
        "    lcop_fx = lcop_th.type(torch.LongTensor)\n",
        "    print(lcop_fx)\n",
        "    print(lcop_fx.type())\n",
        "    \n",
        "    lcop_th_fl = lcop_fx.type(torch.FloatTensor)\n",
        "    lcop_fl = lcop_th_fl / 10000\n",
        "    print(lcop_fl)\n",
        "    print(lcop_fl.type())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "remote index:  0 \n",
            "\n",
            "tensor([[-0.6983, -0.5240]], requires_grad=True)\n",
            "torch.FloatTensor\n",
            "tensor([[-6983.4028, -5239.7515]], grad_fn=<MulBackward0>)\n",
            "tensor([[-6983, -5239]])\n",
            "torch.LongTensor\n",
            "tensor([[-0.6983, -0.5239]])\n",
            "torch.FloatTensor\n",
            "\n",
            "remote index:  1 \n",
            "\n",
            "tensor([[-0.2316, -0.2829]], requires_grad=True)\n",
            "torch.FloatTensor\n",
            "tensor([[-2316.2527, -2829.3748]], grad_fn=<MulBackward0>)\n",
            "tensor([[-2316, -2829]])\n",
            "torch.LongTensor\n",
            "tensor([[-0.2316, -0.2829]])\n",
            "torch.FloatTensor\n",
            "\n",
            "remote index:  0 \n",
            "\n",
            "tensor([0.3239], requires_grad=True)\n",
            "torch.FloatTensor\n",
            "tensor([3239.4980], grad_fn=<MulBackward0>)\n",
            "tensor([3239])\n",
            "torch.LongTensor\n",
            "tensor([0.3239])\n",
            "torch.FloatTensor\n",
            "\n",
            "remote index:  1 \n",
            "\n",
            "tensor([-0.5834], requires_grad=True)\n",
            "torch.FloatTensor\n",
            "tensor([-5834.4795], grad_fn=<MulBackward0>)\n",
            "tensor([-5834])\n",
            "torch.LongTensor\n",
            "tensor([-0.5834])\n",
            "torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Q8MBkO4-g-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3efca025-16fb-4ef0-c25f-904977557862"
      },
      "source": [
        "# iterate through each parameter\n",
        "for i in range(len(params[0])):\n",
        "  \n",
        "  # for each worker\n",
        "  spdz_params_th = list()\n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    \n",
        "    # copy of parameter (cop): copy same parameter from each worker's model, floating type tensor\n",
        "    cop = params[remote_index][i].copy()\n",
        "    \n",
        "    # copy of parameter, thousands (cop_th): copy of parameter scaled up so that precision is not lost\n",
        "    # fixed precision parameter, thousands (fpp_th): fixed precision version of parameter scaled up so that precision is not lost\n",
        "    fpp_th = cop * 10000\n",
        "    \n",
        "    # encrypt on the remote machine. Note: fixed_precision_param is already a pointer. \n",
        "    # calling share encrypts data to which pointer is pointing. Returns a pointer to the MPC secret shared object. Need to fetch object.\n",
        "    encrypted_param_th = fpp_th.share(vw00, vw01, crypto_provider=aggr)\n",
        "    \n",
        "    # fetch the pointer to the MPC shared value\n",
        "    param_th = encrypted_param_th.get()\n",
        "    \n",
        "    # save parameter so can average with same parameter from other workers.\n",
        "    spdz_params_th.append(param_th)\n",
        "    \n",
        "  # average param from multiple workers, fetch back to local machine. Decrypt and decode from fixed precision back to float. \n",
        "  new_param_th = (spdz_params_th[0] + spdz_params_th[1]).get() / 2 #.float_precision() / 2 \n",
        "  new_param_float_th = new_param_th.type(torch.FloatTensor) \n",
        "  new_param_float = new_param_float_th / 10000\n",
        "  \n",
        "  # save new averaged parameter\n",
        "  new_params.append(new_param_float)\n",
        "\n",
        "print(new_params)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[-0.4649, -0.4034]]), tensor([-0.1297])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmLBZx--7DL_",
        "colab_type": "text"
      },
      "source": [
        "#### Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5TGZCcH7ESW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  for model in params:\n",
        "    for param in model:\n",
        "      param *= 0\n",
        "  \n",
        "  for model in models:\n",
        "    model.get()\n",
        "    \n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    for param_index in range(len(params[remote_index])):\n",
        "      params[remote_index][param_index].set_(new_params[param_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuQTWVNhAleq",
        "colab_type": "text"
      },
      "source": [
        "### Bring components together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nAnWJfz2Rtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a115f3a-cc25-4104-c86f-4f70f0fb872f"
      },
      "source": [
        "vw00.clear_objects()\n",
        "vw01.clear_objects()\n",
        "aggr.clear_objects()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:aggr #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMFCypLh18Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2809e121-38af-4dfd-e5c9-f5a2afe311da"
      },
      "source": [
        "# Send data to the workers\n",
        "remote_dataset = (list(), list())\n",
        "\n",
        "train_dist_dataset = []\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(trainloader):\n",
        "  data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  remote_dataset[batch_idx % len(compute_nodes)].append((data, target))\n",
        "  \n",
        "\n",
        "print(remote_dataset)\n",
        "\n",
        "print(train_dist_dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([((Wrapper)>[PointerTensor | me:29749669973 -> vw00:45909376964], (Wrapper)>[PointerTensor | me:27669986400 -> vw00:25310339928]), ((Wrapper)>[PointerTensor | me:11705437616 -> vw00:51062433809], (Wrapper)>[PointerTensor | me:64923833069 -> vw00:81043591030]), ((Wrapper)>[PointerTensor | me:31897506250 -> vw00:83744512707], (Wrapper)>[PointerTensor | me:76184888489 -> vw00:9472155134]), ((Wrapper)>[PointerTensor | me:86371790521 -> vw00:29026377830], (Wrapper)>[PointerTensor | me:35159309332 -> vw00:75851581792]), ((Wrapper)>[PointerTensor | me:32755151679 -> vw00:39333086639], (Wrapper)>[PointerTensor | me:60901587106 -> vw00:99952271307]), ((Wrapper)>[PointerTensor | me:26346893311 -> vw00:49956652854], (Wrapper)>[PointerTensor | me:53598473660 -> vw00:52839988176]), ((Wrapper)>[PointerTensor | me:59422295593 -> vw00:35859508747], (Wrapper)>[PointerTensor | me:58334536721 -> vw00:27391220429]), ((Wrapper)>[PointerTensor | me:34802389450 -> vw00:2256219752], (Wrapper)>[PointerTensor | me:64756927368 -> vw00:62535581749]), ((Wrapper)>[PointerTensor | me:86955527113 -> vw00:23356945709], (Wrapper)>[PointerTensor | me:46200433893 -> vw00:10447404243]), ((Wrapper)>[PointerTensor | me:65415559560 -> vw00:80210351348], (Wrapper)>[PointerTensor | me:78403030993 -> vw00:9261595645]), ((Wrapper)>[PointerTensor | me:54959829415 -> vw00:86747656763], (Wrapper)>[PointerTensor | me:20023902920 -> vw00:55173672854]), ((Wrapper)>[PointerTensor | me:49832041833 -> vw00:48795136706], (Wrapper)>[PointerTensor | me:58844308647 -> vw00:79104253252]), ((Wrapper)>[PointerTensor | me:38287978281 -> vw00:58620095634], (Wrapper)>[PointerTensor | me:6228398358 -> vw00:94228148207]), ((Wrapper)>[PointerTensor | me:5340954020 -> vw00:67206791585], (Wrapper)>[PointerTensor | me:50567204018 -> vw00:54268229743]), ((Wrapper)>[PointerTensor | me:1357056257 -> vw00:22524481204], (Wrapper)>[PointerTensor | me:41944106628 -> vw00:26196407538]), ((Wrapper)>[PointerTensor | me:22499978313 -> vw00:17027048696], (Wrapper)>[PointerTensor | me:79198228157 -> vw00:73346292754]), ((Wrapper)>[PointerTensor | me:22298978771 -> vw00:1487273845], (Wrapper)>[PointerTensor | me:45460473419 -> vw00:56961672915]), ((Wrapper)>[PointerTensor | me:79991602337 -> vw00:8367487569], (Wrapper)>[PointerTensor | me:94912169493 -> vw00:20088031234]), ((Wrapper)>[PointerTensor | me:80789771277 -> vw00:31343287628], (Wrapper)>[PointerTensor | me:85927267097 -> vw00:7166810655]), ((Wrapper)>[PointerTensor | me:8426798053 -> vw00:56439596702], (Wrapper)>[PointerTensor | me:27308978953 -> vw00:32587063718]), ((Wrapper)>[PointerTensor | me:15234118836 -> vw00:59521488127], (Wrapper)>[PointerTensor | me:25537281428 -> vw00:47534142663]), ((Wrapper)>[PointerTensor | me:99361134218 -> vw00:42529764109], (Wrapper)>[PointerTensor | me:47495398345 -> vw00:60824870052]), ((Wrapper)>[PointerTensor | me:89456416251 -> vw00:5055012813], (Wrapper)>[PointerTensor | me:51162314106 -> vw00:47489011521]), ((Wrapper)>[PointerTensor | me:61921762757 -> vw00:430154510], (Wrapper)>[PointerTensor | me:38911043115 -> vw00:87850717632]), ((Wrapper)>[PointerTensor | me:29271362271 -> vw00:99300116579], (Wrapper)>[PointerTensor | me:9164355058 -> vw00:82347117893])], [((Wrapper)>[PointerTensor | me:22596889116 -> vw01:72420686586], (Wrapper)>[PointerTensor | me:29168336732 -> vw01:34671125220]), ((Wrapper)>[PointerTensor | me:24096112450 -> vw01:99269268067], (Wrapper)>[PointerTensor | me:91423833554 -> vw01:97371221283]), ((Wrapper)>[PointerTensor | me:31335513312 -> vw01:89373643372], (Wrapper)>[PointerTensor | me:35820428686 -> vw01:9353451639]), ((Wrapper)>[PointerTensor | me:78195289955 -> vw01:71025719042], (Wrapper)>[PointerTensor | me:80785372709 -> vw01:66248745910]), ((Wrapper)>[PointerTensor | me:9683301050 -> vw01:81581363911], (Wrapper)>[PointerTensor | me:66650147773 -> vw01:9186620563]), ((Wrapper)>[PointerTensor | me:64141621964 -> vw01:21422327259], (Wrapper)>[PointerTensor | me:91025622889 -> vw01:44215403950]), ((Wrapper)>[PointerTensor | me:51368935006 -> vw01:913842092], (Wrapper)>[PointerTensor | me:14334615554 -> vw01:24103524182]), ((Wrapper)>[PointerTensor | me:53487122694 -> vw01:55213658824], (Wrapper)>[PointerTensor | me:43495438727 -> vw01:45022163937]), ((Wrapper)>[PointerTensor | me:33734654171 -> vw01:79841072888], (Wrapper)>[PointerTensor | me:70709627828 -> vw01:42939636627]), ((Wrapper)>[PointerTensor | me:57732532365 -> vw01:60901606441], (Wrapper)>[PointerTensor | me:77467263841 -> vw01:34359458235]), ((Wrapper)>[PointerTensor | me:58853664414 -> vw01:10602786433], (Wrapper)>[PointerTensor | me:48025028184 -> vw01:62678969903]), ((Wrapper)>[PointerTensor | me:86280856371 -> vw01:21090008597], (Wrapper)>[PointerTensor | me:38897626095 -> vw01:78507387479]), ((Wrapper)>[PointerTensor | me:8354025420 -> vw01:53231457492], (Wrapper)>[PointerTensor | me:92059965707 -> vw01:96950183586]), ((Wrapper)>[PointerTensor | me:19630658979 -> vw01:69920218850], (Wrapper)>[PointerTensor | me:35502075841 -> vw01:34061866867]), ((Wrapper)>[PointerTensor | me:11027004825 -> vw01:37382529799], (Wrapper)>[PointerTensor | me:54596549472 -> vw01:22961161921]), ((Wrapper)>[PointerTensor | me:98796361617 -> vw01:61335550269], (Wrapper)>[PointerTensor | me:5080115352 -> vw01:25307132849]), ((Wrapper)>[PointerTensor | me:85226940907 -> vw01:34494925163], (Wrapper)>[PointerTensor | me:36803393477 -> vw01:28353547061]), ((Wrapper)>[PointerTensor | me:32037383495 -> vw01:1718936275], (Wrapper)>[PointerTensor | me:82504689120 -> vw01:89256428383]), ((Wrapper)>[PointerTensor | me:41453854550 -> vw01:25146938609], (Wrapper)>[PointerTensor | me:23658668973 -> vw01:74332012304]), ((Wrapper)>[PointerTensor | me:70748335418 -> vw01:18268642389], (Wrapper)>[PointerTensor | me:98834555390 -> vw01:38931309839]), ((Wrapper)>[PointerTensor | me:45439956907 -> vw01:41219771766], (Wrapper)>[PointerTensor | me:3066842490 -> vw01:52572045667]), ((Wrapper)>[PointerTensor | me:59889777390 -> vw01:18488051792], (Wrapper)>[PointerTensor | me:17220674271 -> vw01:12788204414]), ((Wrapper)>[PointerTensor | me:76736909547 -> vw01:64257762087], (Wrapper)>[PointerTensor | me:2511855901 -> vw01:50056492983]), ((Wrapper)>[PointerTensor | me:94838826234 -> vw01:99227248334], (Wrapper)>[PointerTensor | me:59853804420 -> vw01:42701766963]), ((Wrapper)>[PointerTensor | me:43961331914 -> vw01:79928157987], (Wrapper)>[PointerTensor | me:82879861230 -> vw01:25434532056])])\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3TCJ6Gbz9hw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a02f37e7-8f9e-46b5-d026-4d76b1490cd5"
      },
      "source": [
        "print('length of remote dataset:\\t', len(remote_dataset))\n",
        "print('length of one item in remote dataset:\\t', len(remote_dataset[0]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of remote dataset:\t 2\n",
            "length of one item in remote dataset:\t 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nKeBU4h1Zbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define worker-based models and optimizer\n",
        "\n",
        "vw00_model = Net().send(vw00)\n",
        "vw01_model = Net().send(vw01)\n",
        "\n",
        "vw00_optimizer = optim.SGD(vw00_model.parameters(), lr=args.lr)\n",
        "vw01_optimizer = optim.SGD(vw01_model.parameters(), lr=args.lr)\n",
        "\n",
        "models = [vw00_model, vw01_model]\n",
        "params = [list(vw00_model.parameters()), list(vw01_model.parameters())]\n",
        "optimizers = [vw00_optimizer, vw01_optimizer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J3nO2tb4o8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to be able to send distinct model to each worker to train.\n",
        "\n",
        "def update2(data, target, model, optimizer):\n",
        "  # model.send(data.location)\n",
        "  optimizer.zero_grad()\n",
        "  pred = model(data)\n",
        "  loss = loss_func(pred, target)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPzaH99hx6zW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46f7082a-5357-420c-949a-91e08f7eea58"
      },
      "source": [
        "# figure out the guts of the training mechanism before putting into function.\n",
        "\n",
        "for data_index in range(len(remote_dataset[0])):\n",
        "  \n",
        "  # update remote models\n",
        "  \n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    print('data index: \\t', data_index, '\\tremote index:\\t', remote_index)\n",
        "    data, target = remote_dataset[remote_index][data_index]\n",
        "    model = models[remote_index]\n",
        "    opt = optimizers[remote_index]\n",
        "    \n",
        "    models[remote_index] = update2(data, target, model, opt)\n",
        "    \n",
        "  # encrypted aggregation\n",
        "  new_params = list() # list to store encrypted model average\n",
        "  \n",
        "  for i in range(len(params[0])): # iterate through each parameter\n",
        "\n",
        "    # for each worker\n",
        "    spdz_params_th = list()\n",
        "    for remote_index in range(len(compute_nodes)):\n",
        "\n",
        "      # copy of parameter (cop): copy same parameter from each worker's model, floating type tensor\n",
        "      cop = params[remote_index][i].copy()\n",
        "\n",
        "      # copy of parameter, thousands (cop_th): copy of parameter scaled up so that precision is not lost\n",
        "      # fixed precision parameter, thousands (fpp_th): fixed precision version of parameter scaled up so that precision is not lost\n",
        "      fpp_th = cop * 10000\n",
        "\n",
        "      # encrypt on the remote machine. Note: fixed_precision_param is already a pointer. \n",
        "      # calling share encrypts data to which pointer is pointing. Returns a pointer to the MPC secret shared object. Need to fetch object.\n",
        "      encrypted_param_th = fpp_th.share(vw00, vw01, crypto_provider=aggr)\n",
        "\n",
        "      # fetch the pointer to the MPC shared value\n",
        "      param_th = encrypted_param_th.get()\n",
        "\n",
        "      # save parameter so can average with same parameter from other workers.\n",
        "      spdz_params_th.append(param_th)\n",
        "\n",
        "    # average param from multiple workers, fetch back to local machine. Decrypt and decode from fixed precision back to float. \n",
        "    new_param_th = (spdz_params_th[0] + spdz_params_th[1]).get() / 2 #.float_precision() / 2 \n",
        "    new_param_float_th = new_param_th.type(torch.FloatTensor) \n",
        "    new_param_float = new_param_float_th / 10000\n",
        "\n",
        "    # save new averaged parameter\n",
        "    new_params.append(new_param_float)\n",
        "\n",
        "  print(new_params)  \n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for model in params:\n",
        "      for param in model:\n",
        "        param *= 0\n",
        "      \n",
        "    for remote_index in range(len(compute_nodes)):\n",
        "      for param_index in range(len(params[remote_index])):\n",
        "        params[remote_index][param_index].set_(new_params[param_index])\n",
        "  \n",
        "  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data index: \t 0 \tremote index:\t 0\n",
            "data index: \t 0 \tremote index:\t 1\n",
            "[tensor([[0.4501, 0.0806]]), tensor([0.1653])]\n",
            "data index: \t 1 \tremote index:\t 0\n",
            "data index: \t 1 \tremote index:\t 1\n",
            "[tensor([[-0.0008, -0.0004]]), tensor([0.0003])]\n",
            "data index: \t 2 \tremote index:\t 0\n",
            "data index: \t 2 \tremote index:\t 1\n",
            "[tensor([[0.0003, 0.0000]]), tensor([-0.0011])]\n",
            "data index: \t 3 \tremote index:\t 0\n",
            "data index: \t 3 \tremote index:\t 1\n",
            "[tensor([[0.0013, 0.0020]]), tensor([-0.0013])]\n",
            "data index: \t 4 \tremote index:\t 0\n",
            "data index: \t 4 \tremote index:\t 1\n",
            "[tensor([[0.0012, 0.0005]]), tensor([0.0012])]\n",
            "data index: \t 5 \tremote index:\t 0\n",
            "data index: \t 5 \tremote index:\t 1\n",
            "[tensor([[0., 0.]]), tensor([-0.0018])]\n",
            "data index: \t 6 \tremote index:\t 0\n",
            "data index: \t 6 \tremote index:\t 1\n",
            "[tensor([[-0.0003, -0.0004]]), tensor([0.0007])]\n",
            "data index: \t 7 \tremote index:\t 0\n",
            "data index: \t 7 \tremote index:\t 1\n",
            "[tensor([[0.0005, 0.0020]]), tensor([-0.0025])]\n",
            "data index: \t 8 \tremote index:\t 0\n",
            "data index: \t 8 \tremote index:\t 1\n",
            "[tensor([[-0.0002,  0.0003]]), tensor([0.0017])]\n",
            "data index: \t 9 \tremote index:\t 0\n",
            "data index: \t 9 \tremote index:\t 1\n",
            "[tensor([[0.0014, 0.0006]]), tensor([-0.0005])]\n",
            "data index: \t 10 \tremote index:\t 0\n",
            "data index: \t 10 \tremote index:\t 1\n",
            "[tensor([[-2.0000e-04,  1.0000e-04]]), tensor([-1.0000e-04])]\n",
            "data index: \t 11 \tremote index:\t 0\n",
            "data index: \t 11 \tremote index:\t 1\n",
            "[tensor([[ 0.0000, -0.0023]]), tensor([0.0038])]\n",
            "data index: \t 12 \tremote index:\t 0\n",
            "data index: \t 12 \tremote index:\t 1\n",
            "[tensor([[ 0.0000, -0.0002]]), tensor([0.])]\n",
            "data index: \t 13 \tremote index:\t 0\n",
            "data index: \t 13 \tremote index:\t 1\n",
            "[tensor([[-0.0004,  0.0017]]), tensor([0.0016])]\n",
            "data index: \t 14 \tremote index:\t 0\n",
            "data index: \t 14 \tremote index:\t 1\n",
            "[tensor([[0.0003, 0.0006]]), tensor([-0.0002])]\n",
            "data index: \t 15 \tremote index:\t 0\n",
            "data index: \t 15 \tremote index:\t 1\n",
            "[tensor([[0.0009, 0.0002]]), tensor([-0.0006])]\n",
            "data index: \t 16 \tremote index:\t 0\n",
            "data index: \t 16 \tremote index:\t 1\n",
            "[tensor([[1.0000e-04, 0.0000e+00]]), tensor([0.0006])]\n",
            "data index: \t 17 \tremote index:\t 0\n",
            "data index: \t 17 \tremote index:\t 1\n",
            "[tensor([[-3.0000e-04, -1.0000e-04]]), tensor([0.0025])]\n",
            "data index: \t 18 \tremote index:\t 0\n",
            "data index: \t 18 \tremote index:\t 1\n",
            "[tensor([[0.0003, 0.0003]]), tensor([-0.0004])]\n",
            "data index: \t 19 \tremote index:\t 0\n",
            "data index: \t 19 \tremote index:\t 1\n",
            "[tensor([[-0.0007,  0.0002]]), tensor([0.])]\n",
            "data index: \t 20 \tremote index:\t 0\n",
            "data index: \t 20 \tremote index:\t 1\n",
            "[tensor([[-0.0009,  0.0004]]), tensor([-0.0002])]\n",
            "data index: \t 21 \tremote index:\t 0\n",
            "data index: \t 21 \tremote index:\t 1\n",
            "[tensor([[-0.0012, -0.0045]]), tensor([-0.0031])]\n",
            "data index: \t 22 \tremote index:\t 0\n",
            "data index: \t 22 \tremote index:\t 1\n",
            "[tensor([[-0.0004,  0.0012]]), tensor([0.0032])]\n",
            "data index: \t 23 \tremote index:\t 0\n",
            "data index: \t 23 \tremote index:\t 1\n",
            "[tensor([[ 0.0000, -0.0010]]), tensor([0.0010])]\n",
            "data index: \t 24 \tremote index:\t 0\n",
            "data index: \t 24 \tremote index:\t 1\n",
            "[tensor([[-0.0011, -0.0017]]), tensor([-0.0002])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5DIph0UW-Ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in models:\n",
        "    model.get()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXmKVghlXJ1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d8288cae-554f-4570-bf0a-9595aae76809"
      },
      "source": [
        "print(models)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Net(\n",
            "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
            "), Net(\n",
            "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
            ")]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdNAC7AaXiPR",
        "colab_type": "text"
      },
      "source": [
        "#### Function format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayhWr4jBXhWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01fd5ba5-9198-4cea-9eb5-cf93a40ecee9"
      },
      "source": [
        "vw00.clear_objects()\n",
        "vw01.clear_objects()\n",
        "aggr.clear_objects()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:aggr #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Of_VLEXpDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6cfe87de-aa09-4070-db4a-21c3ed24cfd7"
      },
      "source": [
        "# Send data to the workers\n",
        "remote_dataset = (list(), list())\n",
        "\n",
        "train_dist_dataset = []\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(trainloader):\n",
        "  data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  remote_dataset[batch_idx % len(compute_nodes)].append((data, target))\n",
        "  \n",
        "\n",
        "print(remote_dataset)\n",
        "\n",
        "print(train_dist_dataset)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([((Wrapper)>[PointerTensor | me:23346371630 -> vw00:84856797594], (Wrapper)>[PointerTensor | me:28006523667 -> vw00:17957738723]), ((Wrapper)>[PointerTensor | me:54408080141 -> vw00:7138146363], (Wrapper)>[PointerTensor | me:27288325316 -> vw00:59691869718]), ((Wrapper)>[PointerTensor | me:39382705125 -> vw00:7569723539], (Wrapper)>[PointerTensor | me:75153453676 -> vw00:92230941306]), ((Wrapper)>[PointerTensor | me:89576194768 -> vw00:11849055876], (Wrapper)>[PointerTensor | me:18790677881 -> vw00:65096482723]), ((Wrapper)>[PointerTensor | me:96826137396 -> vw00:18026092680], (Wrapper)>[PointerTensor | me:63508153839 -> vw00:39498580148]), ((Wrapper)>[PointerTensor | me:37997568066 -> vw00:91782948201], (Wrapper)>[PointerTensor | me:51781461830 -> vw00:71812447239]), ((Wrapper)>[PointerTensor | me:14181505680 -> vw00:50989497145], (Wrapper)>[PointerTensor | me:94247327934 -> vw00:14413084282]), ((Wrapper)>[PointerTensor | me:37210288798 -> vw00:66521945095], (Wrapper)>[PointerTensor | me:59507794507 -> vw00:94033162013]), ((Wrapper)>[PointerTensor | me:90567256874 -> vw00:68743333061], (Wrapper)>[PointerTensor | me:16236734679 -> vw00:76110739997]), ((Wrapper)>[PointerTensor | me:79817338545 -> vw00:80682052524], (Wrapper)>[PointerTensor | me:61430544572 -> vw00:81118843426]), ((Wrapper)>[PointerTensor | me:23163297599 -> vw00:56503378586], (Wrapper)>[PointerTensor | me:16492950076 -> vw00:93923848379]), ((Wrapper)>[PointerTensor | me:11300011837 -> vw00:15233003113], (Wrapper)>[PointerTensor | me:12583271726 -> vw00:42891367193]), ((Wrapper)>[PointerTensor | me:84248181449 -> vw00:5091554977], (Wrapper)>[PointerTensor | me:9069316243 -> vw00:62910077090]), ((Wrapper)>[PointerTensor | me:67789404707 -> vw00:68536538826], (Wrapper)>[PointerTensor | me:49626671632 -> vw00:13542832516]), ((Wrapper)>[PointerTensor | me:91608457706 -> vw00:55182315113], (Wrapper)>[PointerTensor | me:44483325877 -> vw00:67294500069]), ((Wrapper)>[PointerTensor | me:29916762145 -> vw00:12791261877], (Wrapper)>[PointerTensor | me:12086101965 -> vw00:9118651143]), ((Wrapper)>[PointerTensor | me:24716603282 -> vw00:37122699967], (Wrapper)>[PointerTensor | me:51599403440 -> vw00:90584293971]), ((Wrapper)>[PointerTensor | me:94844108204 -> vw00:46917611650], (Wrapper)>[PointerTensor | me:26856718780 -> vw00:55804329461]), ((Wrapper)>[PointerTensor | me:30974931066 -> vw00:68153459934], (Wrapper)>[PointerTensor | me:74389762557 -> vw00:33610881152]), ((Wrapper)>[PointerTensor | me:27496900158 -> vw00:14523583678], (Wrapper)>[PointerTensor | me:9352634686 -> vw00:32780284976]), ((Wrapper)>[PointerTensor | me:41627620428 -> vw00:4898513582], (Wrapper)>[PointerTensor | me:57681230139 -> vw00:75314683941]), ((Wrapper)>[PointerTensor | me:56867710638 -> vw00:65578768142], (Wrapper)>[PointerTensor | me:48029007986 -> vw00:69815070117]), ((Wrapper)>[PointerTensor | me:61852971195 -> vw00:46571718517], (Wrapper)>[PointerTensor | me:48996099703 -> vw00:18157739778]), ((Wrapper)>[PointerTensor | me:21723519704 -> vw00:84797083397], (Wrapper)>[PointerTensor | me:54510145565 -> vw00:31534899679]), ((Wrapper)>[PointerTensor | me:66832201484 -> vw00:59639022637], (Wrapper)>[PointerTensor | me:68368955373 -> vw00:52463324991])], [((Wrapper)>[PointerTensor | me:76536932589 -> vw01:18449936599], (Wrapper)>[PointerTensor | me:71621853279 -> vw01:22630736587]), ((Wrapper)>[PointerTensor | me:97007854194 -> vw01:17797664354], (Wrapper)>[PointerTensor | me:42011919926 -> vw01:19821646021]), ((Wrapper)>[PointerTensor | me:80961238976 -> vw01:31157743440], (Wrapper)>[PointerTensor | me:6373055046 -> vw01:59290898022]), ((Wrapper)>[PointerTensor | me:1130768370 -> vw01:72814960541], (Wrapper)>[PointerTensor | me:1618552176 -> vw01:73732107918]), ((Wrapper)>[PointerTensor | me:6015595535 -> vw01:36076603993], (Wrapper)>[PointerTensor | me:83650159352 -> vw01:35477406103]), ((Wrapper)>[PointerTensor | me:26953974673 -> vw01:81635365485], (Wrapper)>[PointerTensor | me:25492412608 -> vw01:10170692218]), ((Wrapper)>[PointerTensor | me:21503135196 -> vw01:18208004342], (Wrapper)>[PointerTensor | me:25812890116 -> vw01:42833247464]), ((Wrapper)>[PointerTensor | me:4015038097 -> vw01:6240197523], (Wrapper)>[PointerTensor | me:95133172730 -> vw01:15898750764]), ((Wrapper)>[PointerTensor | me:3414612909 -> vw01:62501892591], (Wrapper)>[PointerTensor | me:10622198669 -> vw01:95135290025]), ((Wrapper)>[PointerTensor | me:95431406875 -> vw01:93560250249], (Wrapper)>[PointerTensor | me:11829771176 -> vw01:88515694914]), ((Wrapper)>[PointerTensor | me:99753392037 -> vw01:91851936886], (Wrapper)>[PointerTensor | me:50883896596 -> vw01:61541662209]), ((Wrapper)>[PointerTensor | me:61382951231 -> vw01:1750159090], (Wrapper)>[PointerTensor | me:75766334122 -> vw01:42960031970]), ((Wrapper)>[PointerTensor | me:90178831991 -> vw01:13953668706], (Wrapper)>[PointerTensor | me:89126763964 -> vw01:64695214771]), ((Wrapper)>[PointerTensor | me:15635296674 -> vw01:21022820367], (Wrapper)>[PointerTensor | me:35830187209 -> vw01:27319462076]), ((Wrapper)>[PointerTensor | me:87462649330 -> vw01:25161811800], (Wrapper)>[PointerTensor | me:38671354623 -> vw01:23144031722]), ((Wrapper)>[PointerTensor | me:18879498564 -> vw01:8746818617], (Wrapper)>[PointerTensor | me:55745746023 -> vw01:85891597864]), ((Wrapper)>[PointerTensor | me:93904958402 -> vw01:69090869695], (Wrapper)>[PointerTensor | me:51261923104 -> vw01:16010489999]), ((Wrapper)>[PointerTensor | me:40253662063 -> vw01:52973637619], (Wrapper)>[PointerTensor | me:13955834870 -> vw01:80121046619]), ((Wrapper)>[PointerTensor | me:28390714380 -> vw01:51069746382], (Wrapper)>[PointerTensor | me:62331352984 -> vw01:56778661628]), ((Wrapper)>[PointerTensor | me:80357961078 -> vw01:76174871779], (Wrapper)>[PointerTensor | me:6278660959 -> vw01:82565319636]), ((Wrapper)>[PointerTensor | me:99389672304 -> vw01:59860615538], (Wrapper)>[PointerTensor | me:66987006398 -> vw01:14075094381]), ((Wrapper)>[PointerTensor | me:60247113096 -> vw01:70698861721], (Wrapper)>[PointerTensor | me:78738238804 -> vw01:46440586117]), ((Wrapper)>[PointerTensor | me:87072019993 -> vw01:44284264767], (Wrapper)>[PointerTensor | me:87193480513 -> vw01:8044939998]), ((Wrapper)>[PointerTensor | me:65303953118 -> vw01:40645119977], (Wrapper)>[PointerTensor | me:51572591103 -> vw01:53922988509]), ((Wrapper)>[PointerTensor | me:28430382984 -> vw01:72126579085], (Wrapper)>[PointerTensor | me:54161303785 -> vw01:74731365403])])\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYaMcdfkXu1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define worker-based models and optimizer\n",
        "\n",
        "vw00_model = Net().send(vw00)\n",
        "vw01_model = Net().send(vw01)\n",
        "\n",
        "vw00_optimizer = optim.SGD(vw00_model.parameters(), lr=args.lr)\n",
        "vw01_optimizer = optim.SGD(vw01_model.parameters(), lr=args.lr)\n",
        "\n",
        "models = [vw00_model, vw01_model]\n",
        "params = [list(vw00_model.parameters()), list(vw01_model.parameters())]\n",
        "optimizers = [vw00_optimizer, vw01_optimizer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhfbtjKKX7gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# figure out the guts of the training mechanism before putting into function.\n",
        "\n",
        "def train_agg(epoch):\n",
        "  \n",
        "  for data_index in range(len(remote_dataset[0])):\n",
        "\n",
        "    # update remote models\n",
        "\n",
        "    for remote_index in range(len(compute_nodes)):\n",
        "      print('data index: \\t', data_index, '\\tremote index:\\t', remote_index)\n",
        "      data, target = remote_dataset[remote_index][data_index]\n",
        "      model = models[remote_index]\n",
        "      opt = optimizers[remote_index]\n",
        "\n",
        "      models[remote_index] = update2(data, target, model, opt)\n",
        "\n",
        "    # encrypted aggregation\n",
        "    new_params = list() # list to store encrypted model average\n",
        "\n",
        "    for i in range(len(params[0])): # iterate through each parameter\n",
        "\n",
        "      # for each worker\n",
        "      spdz_params_th = list()\n",
        "      for remote_index in range(len(compute_nodes)):\n",
        "\n",
        "        # copy of parameter (cop): copy same parameter from each worker's model, floating type tensor\n",
        "        cop = params[remote_index][i].copy()\n",
        "\n",
        "        # copy of parameter, thousands (cop_th): copy of parameter scaled up so that precision is not lost\n",
        "        # fixed precision parameter, thousands (fpp_th): fixed precision version of parameter scaled up so that precision is not lost\n",
        "        fpp_th = cop * 10000\n",
        "\n",
        "        # encrypt on the remote machine. Note: fixed_precision_param is already a pointer. \n",
        "        # calling share encrypts data to which pointer is pointing. Returns a pointer to the MPC secret shared object. Need to fetch object.\n",
        "        encrypted_param_th = fpp_th.share(vw00, vw01, crypto_provider=aggr)\n",
        "\n",
        "        # fetch the pointer to the MPC shared value\n",
        "        param_th = encrypted_param_th.get()\n",
        "\n",
        "        # save parameter so can average with same parameter from other workers.\n",
        "        spdz_params_th.append(param_th)\n",
        "\n",
        "      # average param from multiple workers, fetch back to local machine. Decrypt and decode from fixed precision back to float. \n",
        "      new_param_th = (spdz_params_th[0] + spdz_params_th[1]).get() / 2 #.float_precision() / 2 \n",
        "      new_param_float_th = new_param_th.type(torch.FloatTensor) \n",
        "      new_param_float = new_param_float_th / 10000\n",
        "\n",
        "      # save new averaged parameter\n",
        "      new_params.append(new_param_float)\n",
        "\n",
        "    print(new_params)  \n",
        "\n",
        "    with torch.no_grad():\n",
        "      for model in params:\n",
        "        for param in model:\n",
        "          param *= 0\n",
        "\n",
        "      for remote_index in range(len(compute_nodes)):\n",
        "        for param_index in range(len(params[remote_index])):\n",
        "          params[remote_index][param_index].set_(new_params[param_index])\n",
        "\n",
        "  for model in models:\n",
        "    model.get()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QbiqL-JYPel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_agg():\n",
        "  models[0].eval()\n",
        "  test_loss = 0\n",
        "  for data, target in testloader:\n",
        "    output = models[0](data)\n",
        "    test_loss += loss_func(output, target).item()\n",
        "    pred = output\n",
        "  \n",
        "  test_loss /= len(testloader.dataset)\n",
        "  print('Test set: Average loss: {:.4f}\\n'.format(test_loss))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmjrpQoJZOQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "eb58e1b6-2e15-4e14-a00f-abcabadedd6c"
      },
      "source": [
        "t = time.time()\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "  print(f\"Epoch {epoch + 1}\")\n",
        "  train(epoch)\n",
        "  test()\n",
        "  \n",
        "total_time = time.time() - t\n",
        "\n",
        "print('Total', round(total_time, 2), 's')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 2\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 3\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 4\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 5\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 6\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 7\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 8\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 9\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Epoch 10\n",
            "\n",
            "Test Set: Average Loss: 0.8211\n",
            "\n",
            "Total 0.25 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}