{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 2 - Federated Learning Final Project 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewotawa/secure_private_ai/blob/master/Section_2_Federated_Learning_Final_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM6v2FitGLvc",
        "colab_type": "text"
      },
      "source": [
        "# Federated Learning Final Project\n",
        "\n",
        "## Overview\n",
        "* See  <a href=\"https://classroom.udacity.com/nanodegrees/nd185/parts/3fe1bb10-68d7-4d84-9c99-9539dedffad5/modules/28d685f0-0cb1-4f94-a8ea-2e16614ab421/lessons/c8fe481d-81ea-41be-8206-06d2deeb8575/concepts/a5fb4b4c-e38a-48de-b2a7-4e853c62acbe\">video</a> for additional details. \n",
        "* Do Federated Learning where the central server is not trusted with the raw gradients.  \n",
        "* In the final project notebook, you'll receive a dataset.  \n",
        "* Train on the dataset using Federated Learning.  \n",
        "* The gradients should not come up to the server in raw form.  \n",
        "* Instead, use the new .move() command to move all of the gradients to one of the workers, sum them up there, and then bring that batch up to the central server and then bring that batch up \n",
        "* Idea: the central server never actually sees the raw gradient for any person.â€¯ \n",
        "* We'll look at secure aggregation in course 3.  \n",
        "* For now, do a larger-scale Federated Learning case where you handle the gradients in a special way.\n",
        "\n",
        "## Approach\n",
        "* Reviewing methods of classmates for Federated Learning. \n",
        "\n",
        "## References\n",
        "*  <a href = \"https://github.com/edgarinvillegas/private-ai/blob/master/Section%203%20-%20Final%20project.ipynb/\">GitHub Notebook</a>\n",
        "* <a href = \"https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2010%20-%20Federated%20Learning%20with%20Secure%20Aggregation.ipynb\">Part 10: Federated Learning with Encrypted Gradient Aggregation</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCOI3fXnGWr0",
        "colab_type": "text"
      },
      "source": [
        "### Install libraries and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGKXOXqmF8TZ",
        "colab_type": "code",
        "outputId": "0bb2085d-3e0b-4efb-a3c3-b2362440f3e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "# PySyft\n",
        "\n",
        "!pip install syft\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "# PyTorch\n",
        "\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# time\n",
        "\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages (0.1.21a1)\n",
            "Requirement already satisfied: tf-encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.7)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.0.1)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.1.0)\n",
            "Requirement already satisfied: flask-socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from syft) (4.1.0)\n",
            "Requirement already satisfied: websocket-client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.56.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0722 23:10:22.735807 140675696850816 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0722 23:10:22.750314 140675696850816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vanu9rXIV3k",
        "colab_type": "text"
      },
      "source": [
        "### Normal Federated Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUQ84pJSQGqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Establish a parser to contain parameters for training\n",
        "\n",
        "class Parser: \n",
        "  def __init__(self):\n",
        "    self.epochs = 10\n",
        "    self.lr = 0.001\n",
        "    self.test_batch_size = 1\n",
        "    self.batch_size = 1\n",
        "    self.log_interval = 10\n",
        "    self.seed = 1\n",
        "    \n",
        "args = Parser()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "kwargs = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI096VvCHCVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Dataset\n",
        "\n",
        "data = torch.randn(50, 2, requires_grad=True) \n",
        "target = torch.randn(50, 1, requires_grad=True) \n",
        "\n",
        "data_test = torch.randn(50, 2, requires_grad=True) \n",
        "target_test = torch.randn(50, 1, requires_grad=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk3eED_kPuoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = TensorDataset(data, target)\n",
        "test = TensorDataset(data_test, target_test)\n",
        "\n",
        "trainloader = DataLoader(train, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "testloader = DataLoader(test, batch_size=args.test_batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5IEgR_LH5RE",
        "colab_type": "code",
        "outputId": "3fee4056-273a-4f21-9e77-30a2f1bca95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# A Toy Model\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(2,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "# model = nn.Linear(2,1)\n",
        "\n",
        "model = Net() \n",
        "\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOGXMlEkH8P1",
        "colab_type": "code",
        "outputId": "f8de1836-2d84-487d-88c3-53b04b29874e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Optimizer\n",
        "opt = optim.SGD(params=model.parameters(), lr=args.lr)\n",
        "print(opt)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.001\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moXQNSWnOCzL",
        "colab_type": "text"
      },
      "source": [
        "Set up hook, virtual workers, and virtual aggregator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkNHvMkJIVSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "vw00 = sy.VirtualWorker(hook, id=\"vw00\")\n",
        "vw01 = sy.VirtualWorker(hook, id=\"vw01\")\n",
        "\n",
        "aggr = sy.VirtualWorker(hook, id=\"aggr\")\n",
        "\n",
        "compute_nodes = [vw00, vw01]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zu-lAUzRuTK",
        "colab_type": "code",
        "outputId": "d2fca432-7e20-4418-ca67-47f7b3ddd1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vw00.clear_objects()\n",
        "vw01.clear_objects()\n",
        "aggr.clear_objects()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:aggr #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqKMB3YFTavk",
        "colab_type": "code",
        "outputId": "977170d9-b058-46ff-e4b8-d0bc21599fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Send data to the workers\n",
        "train_dist_dataset = []\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(trainloader):\n",
        "  data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  train_dist_dataset.append((data, target))\n",
        "  \n",
        "print(train_dist_dataset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[((Wrapper)>[PointerTensor | me:84986651634 -> vw00:9736110717], (Wrapper)>[PointerTensor | me:28922064506 -> vw00:79239569856]), ((Wrapper)>[PointerTensor | me:91960528364 -> vw01:14849918809], (Wrapper)>[PointerTensor | me:47627793448 -> vw01:12761496262]), ((Wrapper)>[PointerTensor | me:73105945937 -> vw00:3638353867], (Wrapper)>[PointerTensor | me:91887967349 -> vw00:54943560023]), ((Wrapper)>[PointerTensor | me:23581797819 -> vw01:21710482536], (Wrapper)>[PointerTensor | me:23349144114 -> vw01:90651078906]), ((Wrapper)>[PointerTensor | me:54854929432 -> vw00:82710441413], (Wrapper)>[PointerTensor | me:75836206845 -> vw00:81188717192]), ((Wrapper)>[PointerTensor | me:29587680328 -> vw01:99436922736], (Wrapper)>[PointerTensor | me:16339480525 -> vw01:38537620918]), ((Wrapper)>[PointerTensor | me:65998914431 -> vw00:11070956072], (Wrapper)>[PointerTensor | me:8069036501 -> vw00:23946814010]), ((Wrapper)>[PointerTensor | me:30923284894 -> vw01:74647737767], (Wrapper)>[PointerTensor | me:40120163882 -> vw01:54820903470]), ((Wrapper)>[PointerTensor | me:71292745439 -> vw00:30598505134], (Wrapper)>[PointerTensor | me:17432946459 -> vw00:22128634016]), ((Wrapper)>[PointerTensor | me:56255163505 -> vw01:71044893603], (Wrapper)>[PointerTensor | me:99323697139 -> vw01:35440048722]), ((Wrapper)>[PointerTensor | me:21515699008 -> vw00:37981996666], (Wrapper)>[PointerTensor | me:19774614563 -> vw00:99621126306]), ((Wrapper)>[PointerTensor | me:40691792687 -> vw01:84409355046], (Wrapper)>[PointerTensor | me:66558614827 -> vw01:70070237924]), ((Wrapper)>[PointerTensor | me:59391692215 -> vw00:48910842528], (Wrapper)>[PointerTensor | me:64498979708 -> vw00:40412597955]), ((Wrapper)>[PointerTensor | me:48733313229 -> vw01:22913317562], (Wrapper)>[PointerTensor | me:34637779492 -> vw01:15688861431]), ((Wrapper)>[PointerTensor | me:93481967428 -> vw00:71731784995], (Wrapper)>[PointerTensor | me:21276374586 -> vw00:20944823133]), ((Wrapper)>[PointerTensor | me:3808134712 -> vw01:31262579472], (Wrapper)>[PointerTensor | me:27159006744 -> vw01:54871861147]), ((Wrapper)>[PointerTensor | me:46746813346 -> vw00:39556219124], (Wrapper)>[PointerTensor | me:93845890982 -> vw00:78363961591]), ((Wrapper)>[PointerTensor | me:74525458154 -> vw01:75908946742], (Wrapper)>[PointerTensor | me:92252559663 -> vw01:55693402292]), ((Wrapper)>[PointerTensor | me:87868880372 -> vw00:52773051318], (Wrapper)>[PointerTensor | me:49366860057 -> vw00:93134280625]), ((Wrapper)>[PointerTensor | me:15147677859 -> vw01:54619998212], (Wrapper)>[PointerTensor | me:572749450 -> vw01:95682460809]), ((Wrapper)>[PointerTensor | me:83682631696 -> vw00:97592945263], (Wrapper)>[PointerTensor | me:3455966380 -> vw00:2407399671]), ((Wrapper)>[PointerTensor | me:65312251308 -> vw01:53065200902], (Wrapper)>[PointerTensor | me:14051798093 -> vw01:49021848067]), ((Wrapper)>[PointerTensor | me:85011741492 -> vw00:56659973499], (Wrapper)>[PointerTensor | me:78945407554 -> vw00:58740199057]), ((Wrapper)>[PointerTensor | me:20227574780 -> vw01:71938785571], (Wrapper)>[PointerTensor | me:43944949395 -> vw01:10158516155]), ((Wrapper)>[PointerTensor | me:38239960223 -> vw00:73968077313], (Wrapper)>[PointerTensor | me:30023203317 -> vw00:88420511809]), ((Wrapper)>[PointerTensor | me:87985153694 -> vw01:60181920278], (Wrapper)>[PointerTensor | me:60460081863 -> vw01:49021374946]), ((Wrapper)>[PointerTensor | me:36439718720 -> vw00:13776966948], (Wrapper)>[PointerTensor | me:85675077280 -> vw00:62200561991]), ((Wrapper)>[PointerTensor | me:58481356878 -> vw01:59605378690], (Wrapper)>[PointerTensor | me:69701215454 -> vw01:50336980566]), ((Wrapper)>[PointerTensor | me:77639321641 -> vw00:97822732213], (Wrapper)>[PointerTensor | me:83475163414 -> vw00:79962253305]), ((Wrapper)>[PointerTensor | me:40379356947 -> vw01:46881205988], (Wrapper)>[PointerTensor | me:36355202315 -> vw01:83800474001]), ((Wrapper)>[PointerTensor | me:75172363607 -> vw00:43652759186], (Wrapper)>[PointerTensor | me:56587262232 -> vw00:3354513425]), ((Wrapper)>[PointerTensor | me:6799125164 -> vw01:42045448765], (Wrapper)>[PointerTensor | me:69961294859 -> vw01:25174993665]), ((Wrapper)>[PointerTensor | me:16353910799 -> vw00:32025124767], (Wrapper)>[PointerTensor | me:34621915580 -> vw00:81633204319]), ((Wrapper)>[PointerTensor | me:16682707143 -> vw01:93952374279], (Wrapper)>[PointerTensor | me:97046769257 -> vw01:6795264612]), ((Wrapper)>[PointerTensor | me:76348798665 -> vw00:71159869572], (Wrapper)>[PointerTensor | me:47913695610 -> vw00:67315348229]), ((Wrapper)>[PointerTensor | me:64537843185 -> vw01:35608109461], (Wrapper)>[PointerTensor | me:67012201698 -> vw01:90412515540]), ((Wrapper)>[PointerTensor | me:99673558705 -> vw00:27441888078], (Wrapper)>[PointerTensor | me:53399974348 -> vw00:52215335069]), ((Wrapper)>[PointerTensor | me:3153603624 -> vw01:23802587940], (Wrapper)>[PointerTensor | me:23854526923 -> vw01:30846416210]), ((Wrapper)>[PointerTensor | me:31342284392 -> vw00:58997289499], (Wrapper)>[PointerTensor | me:95216882143 -> vw00:81179603881]), ((Wrapper)>[PointerTensor | me:84871640160 -> vw01:15664561880], (Wrapper)>[PointerTensor | me:11601763216 -> vw01:44233465217]), ((Wrapper)>[PointerTensor | me:189989321 -> vw00:14588324574], (Wrapper)>[PointerTensor | me:564222352 -> vw00:34379997996]), ((Wrapper)>[PointerTensor | me:1794194013 -> vw01:38083162723], (Wrapper)>[PointerTensor | me:32828625397 -> vw01:78078909084]), ((Wrapper)>[PointerTensor | me:67746883256 -> vw00:27007159999], (Wrapper)>[PointerTensor | me:82211939124 -> vw00:4950344391]), ((Wrapper)>[PointerTensor | me:13436132081 -> vw01:94255573943], (Wrapper)>[PointerTensor | me:54920201070 -> vw01:29368780516]), ((Wrapper)>[PointerTensor | me:3032976872 -> vw00:6062081094], (Wrapper)>[PointerTensor | me:914051294 -> vw00:34317653361]), ((Wrapper)>[PointerTensor | me:14511190785 -> vw01:60733043276], (Wrapper)>[PointerTensor | me:1643764736 -> vw01:54647995202]), ((Wrapper)>[PointerTensor | me:18916267773 -> vw00:65909519589], (Wrapper)>[PointerTensor | me:51555098795 -> vw00:17437515810]), ((Wrapper)>[PointerTensor | me:9171489522 -> vw01:72498331733], (Wrapper)>[PointerTensor | me:12373557139 -> vw01:33136936518]), ((Wrapper)>[PointerTensor | me:46890472285 -> vw00:89953624867], (Wrapper)>[PointerTensor | me:51392925134 -> vw00:97408000940]), ((Wrapper)>[PointerTensor | me:73898651150 -> vw01:98342244538], (Wrapper)>[PointerTensor | me:60051839281 -> vw01:11768324752])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_F9JxO5y9Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define loss function\n",
        "\n",
        "def loss_func(pred, target):\n",
        "  loss = ((pred - target)**2).sum()\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zwHPn6FI6bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training function\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  \n",
        "  for batch_idx, (data, target) in enumerate(train_dist_dataset):\n",
        "    # determine the active worker\n",
        "    worker = data.location\n",
        "    # send the model to the active worker\n",
        "    model.send(worker)\n",
        "    \n",
        "    # do normal training\n",
        "    opt.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = loss_func(pred, target)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    model.get()\n",
        "\n",
        "    if batch_idx % args.log_interval == 0:\n",
        "      loss = loss.get()\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss: {:.6f}'.format(\n",
        "        epoch, batch_idx, len(trainloader),\n",
        "          100. * batch_idx / len(trainloader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3S388XyXIug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing function\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  for data, target in testloader:\n",
        "    pred = model(data)\n",
        "    test_loss += loss_func(pred, target).item() # sum up batch loss\n",
        "    \n",
        "  test_loss /= len(testloader.dataset)\n",
        "  print('\\nTest Set: Average Loss: {:.4f}\\n'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZj1yCMzzpj",
        "colab_type": "code",
        "outputId": "b5cbf811-110f-4496-b32a-4e425d043254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "# train the model\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "  train(epoch)\n",
        "  \n",
        "total_time = time.time() - t\n",
        "print('total', round(total_time, 2), 'sec')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50 (0%)]\tloss: 2.548004\n",
            "Train Epoch: 1 [10/50 (20%)]\tloss: 1.465525\n",
            "Train Epoch: 1 [20/50 (40%)]\tloss: 1.308707\n",
            "Train Epoch: 1 [30/50 (60%)]\tloss: 0.103834\n",
            "Train Epoch: 1 [40/50 (80%)]\tloss: 0.000071\n",
            "Train Epoch: 2 [0/50 (0%)]\tloss: 2.288096\n",
            "Train Epoch: 2 [10/50 (20%)]\tloss: 1.318819\n",
            "Train Epoch: 2 [20/50 (40%)]\tloss: 1.319915\n",
            "Train Epoch: 2 [30/50 (60%)]\tloss: 0.120199\n",
            "Train Epoch: 2 [40/50 (80%)]\tloss: 0.000036\n",
            "Train Epoch: 3 [0/50 (0%)]\tloss: 2.069994\n",
            "Train Epoch: 3 [10/50 (20%)]\tloss: 1.193838\n",
            "Train Epoch: 3 [20/50 (40%)]\tloss: 1.322092\n",
            "Train Epoch: 3 [30/50 (60%)]\tloss: 0.137194\n",
            "Train Epoch: 3 [40/50 (80%)]\tloss: 0.000446\n",
            "Train Epoch: 4 [0/50 (0%)]\tloss: 1.886120\n",
            "Train Epoch: 4 [10/50 (20%)]\tloss: 1.086949\n",
            "Train Epoch: 4 [20/50 (40%)]\tloss: 1.317107\n",
            "Train Epoch: 4 [30/50 (60%)]\tloss: 0.154615\n",
            "Train Epoch: 4 [40/50 (80%)]\tloss: 0.001332\n",
            "Train Epoch: 5 [0/50 (0%)]\tloss: 1.730398\n",
            "Train Epoch: 5 [10/50 (20%)]\tloss: 0.995188\n",
            "Train Epoch: 5 [20/50 (40%)]\tloss: 1.306569\n",
            "Train Epoch: 5 [30/50 (60%)]\tloss: 0.172268\n",
            "Train Epoch: 5 [40/50 (80%)]\tloss: 0.002692\n",
            "Train Epoch: 6 [0/50 (0%)]\tloss: 1.597936\n",
            "Train Epoch: 6 [10/50 (20%)]\tloss: 0.916121\n",
            "Train Epoch: 6 [20/50 (40%)]\tloss: 1.291839\n",
            "Train Epoch: 6 [30/50 (60%)]\tloss: 0.189977\n",
            "Train Epoch: 6 [40/50 (80%)]\tloss: 0.004501\n",
            "Train Epoch: 7 [0/50 (0%)]\tloss: 1.484778\n",
            "Train Epoch: 7 [10/50 (20%)]\tloss: 0.847747\n",
            "Train Epoch: 7 [20/50 (40%)]\tloss: 1.274053\n",
            "Train Epoch: 7 [30/50 (60%)]\tloss: 0.207586\n",
            "Train Epoch: 7 [40/50 (80%)]\tloss: 0.006713\n",
            "Train Epoch: 8 [0/50 (0%)]\tloss: 1.387714\n",
            "Train Epoch: 8 [10/50 (20%)]\tloss: 0.788412\n",
            "Train Epoch: 8 [20/50 (40%)]\tloss: 1.254141\n",
            "Train Epoch: 8 [30/50 (60%)]\tloss: 0.224958\n",
            "Train Epoch: 8 [40/50 (80%)]\tloss: 0.009275\n",
            "Train Epoch: 9 [0/50 (0%)]\tloss: 1.304126\n",
            "Train Epoch: 9 [10/50 (20%)]\tloss: 0.736747\n",
            "Train Epoch: 9 [20/50 (40%)]\tloss: 1.232861\n",
            "Train Epoch: 9 [30/50 (60%)]\tloss: 0.241977\n",
            "Train Epoch: 9 [40/50 (80%)]\tloss: 0.012127\n",
            "Train Epoch: 10 [0/50 (0%)]\tloss: 1.231869\n",
            "Train Epoch: 10 [10/50 (20%)]\tloss: 0.691614\n",
            "Train Epoch: 10 [20/50 (40%)]\tloss: 1.210818\n",
            "Train Epoch: 10 [30/50 (60%)]\tloss: 0.258547\n",
            "Train Epoch: 10 [40/50 (80%)]\tloss: 0.015207\n",
            "total 2.68 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af28LU0X0TGf",
        "colab_type": "code",
        "outputId": "4f1a64d9-679e-4938-f67d-ca0f28ce91bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# calculating performance\n",
        "test()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.8006\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvfrM-2R2hnp",
        "colab_type": "text"
      },
      "source": [
        "### Add Encrypted Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsPiFsaM2gkj",
        "colab_type": "code",
        "outputId": "4f18402a-509a-4a0d-bfcb-74644640cb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Send data to the workers\n",
        "remote_dataset = (list(), list())\n",
        "\n",
        "train_dist_dataset = []\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(trainloader):\n",
        "  data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  remote_dataset[batch_idx % len(compute_nodes)].append((data, target))\n",
        "  \n",
        "\n",
        "print(remote_dataset)\n",
        "\n",
        "print(train_dist_dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([((Wrapper)>[PointerTensor | me:82925490801 -> vw00:58106901474], (Wrapper)>[PointerTensor | me:29269605164 -> vw00:10994019681]), ((Wrapper)>[PointerTensor | me:77539390988 -> vw00:24317123840], (Wrapper)>[PointerTensor | me:7820972731 -> vw00:83437010019]), ((Wrapper)>[PointerTensor | me:23040771618 -> vw00:79590846742], (Wrapper)>[PointerTensor | me:98537957199 -> vw00:49993631202]), ((Wrapper)>[PointerTensor | me:40347384483 -> vw00:29895684361], (Wrapper)>[PointerTensor | me:96608799219 -> vw00:37541652217]), ((Wrapper)>[PointerTensor | me:94995372736 -> vw00:57199813825], (Wrapper)>[PointerTensor | me:2976383923 -> vw00:3290409406]), ((Wrapper)>[PointerTensor | me:46471665959 -> vw00:2818563227], (Wrapper)>[PointerTensor | me:30049133190 -> vw00:76489210412]), ((Wrapper)>[PointerTensor | me:953423876 -> vw00:65863077940], (Wrapper)>[PointerTensor | me:52218564031 -> vw00:15857973164]), ((Wrapper)>[PointerTensor | me:74175956840 -> vw00:46622251441], (Wrapper)>[PointerTensor | me:61601537513 -> vw00:78229641289]), ((Wrapper)>[PointerTensor | me:37977273744 -> vw00:59871946143], (Wrapper)>[PointerTensor | me:15542252734 -> vw00:75705938633]), ((Wrapper)>[PointerTensor | me:77726591097 -> vw00:65706960174], (Wrapper)>[PointerTensor | me:16570877381 -> vw00:55649121879]), ((Wrapper)>[PointerTensor | me:60429357307 -> vw00:2017603477], (Wrapper)>[PointerTensor | me:48856868506 -> vw00:33280732664]), ((Wrapper)>[PointerTensor | me:52777076670 -> vw00:83621739484], (Wrapper)>[PointerTensor | me:9382806166 -> vw00:50655540463]), ((Wrapper)>[PointerTensor | me:70235857305 -> vw00:95194978028], (Wrapper)>[PointerTensor | me:35782939204 -> vw00:9537059761]), ((Wrapper)>[PointerTensor | me:25916979915 -> vw00:21057417661], (Wrapper)>[PointerTensor | me:25066183266 -> vw00:35578023853]), ((Wrapper)>[PointerTensor | me:24228207775 -> vw00:4686981398], (Wrapper)>[PointerTensor | me:74922687361 -> vw00:46322852295]), ((Wrapper)>[PointerTensor | me:61755451436 -> vw00:53928129148], (Wrapper)>[PointerTensor | me:94490999185 -> vw00:83637543280]), ((Wrapper)>[PointerTensor | me:74111926490 -> vw00:13786587722], (Wrapper)>[PointerTensor | me:6592129211 -> vw00:55270853639]), ((Wrapper)>[PointerTensor | me:61682004200 -> vw00:92537396996], (Wrapper)>[PointerTensor | me:14965299949 -> vw00:6241425312]), ((Wrapper)>[PointerTensor | me:81732697399 -> vw00:49847370036], (Wrapper)>[PointerTensor | me:21653376029 -> vw00:9361098358]), ((Wrapper)>[PointerTensor | me:69478664520 -> vw00:13837409210], (Wrapper)>[PointerTensor | me:74160615607 -> vw00:21076392510]), ((Wrapper)>[PointerTensor | me:70310921776 -> vw00:37124699846], (Wrapper)>[PointerTensor | me:54218109322 -> vw00:11969093274]), ((Wrapper)>[PointerTensor | me:35306818429 -> vw00:66175356935], (Wrapper)>[PointerTensor | me:52599674590 -> vw00:24923733757]), ((Wrapper)>[PointerTensor | me:47898629835 -> vw00:78249270471], (Wrapper)>[PointerTensor | me:76454705818 -> vw00:48258435304]), ((Wrapper)>[PointerTensor | me:57325065161 -> vw00:59237973547], (Wrapper)>[PointerTensor | me:34629598001 -> vw00:13872955307]), ((Wrapper)>[PointerTensor | me:77860416974 -> vw00:19411725992], (Wrapper)>[PointerTensor | me:32547424223 -> vw00:11145921901])], [((Wrapper)>[PointerTensor | me:27240490237 -> vw01:35556471814], (Wrapper)>[PointerTensor | me:89265483596 -> vw01:75462877143]), ((Wrapper)>[PointerTensor | me:18085357308 -> vw01:35585636922], (Wrapper)>[PointerTensor | me:92934748260 -> vw01:79188795895]), ((Wrapper)>[PointerTensor | me:7918891472 -> vw01:84443010648], (Wrapper)>[PointerTensor | me:20695150289 -> vw01:64163908775]), ((Wrapper)>[PointerTensor | me:17177386418 -> vw01:65449774385], (Wrapper)>[PointerTensor | me:46320836140 -> vw01:14758289339]), ((Wrapper)>[PointerTensor | me:49108516875 -> vw01:49089619923], (Wrapper)>[PointerTensor | me:20651909112 -> vw01:31712278825]), ((Wrapper)>[PointerTensor | me:7494374720 -> vw01:98321668660], (Wrapper)>[PointerTensor | me:59911680841 -> vw01:5732914828]), ((Wrapper)>[PointerTensor | me:29335629252 -> vw01:36606298129], (Wrapper)>[PointerTensor | me:17650081944 -> vw01:71403298076]), ((Wrapper)>[PointerTensor | me:94614725177 -> vw01:9526778212], (Wrapper)>[PointerTensor | me:45711024999 -> vw01:12112399554]), ((Wrapper)>[PointerTensor | me:45271403161 -> vw01:73631025404], (Wrapper)>[PointerTensor | me:1803841667 -> vw01:65570802781]), ((Wrapper)>[PointerTensor | me:85169832365 -> vw01:58085772800], (Wrapper)>[PointerTensor | me:80250473820 -> vw01:48380630801]), ((Wrapper)>[PointerTensor | me:78272913244 -> vw01:90967071931], (Wrapper)>[PointerTensor | me:34650379189 -> vw01:31525132483]), ((Wrapper)>[PointerTensor | me:89427594393 -> vw01:23256432966], (Wrapper)>[PointerTensor | me:8611976686 -> vw01:84861314256]), ((Wrapper)>[PointerTensor | me:78969314957 -> vw01:70008194654], (Wrapper)>[PointerTensor | me:45446503888 -> vw01:67737975827]), ((Wrapper)>[PointerTensor | me:77495574405 -> vw01:29027426457], (Wrapper)>[PointerTensor | me:54011124787 -> vw01:40499029200]), ((Wrapper)>[PointerTensor | me:7696316884 -> vw01:9629927214], (Wrapper)>[PointerTensor | me:67403306657 -> vw01:68801357320]), ((Wrapper)>[PointerTensor | me:34605973312 -> vw01:95562973312], (Wrapper)>[PointerTensor | me:34062432650 -> vw01:96531980348]), ((Wrapper)>[PointerTensor | me:53102967699 -> vw01:65893381178], (Wrapper)>[PointerTensor | me:24225668403 -> vw01:46871030966]), ((Wrapper)>[PointerTensor | me:47918271535 -> vw01:97555185389], (Wrapper)>[PointerTensor | me:86806130833 -> vw01:93459562945]), ((Wrapper)>[PointerTensor | me:90860161719 -> vw01:28888082134], (Wrapper)>[PointerTensor | me:97194537794 -> vw01:98074737224]), ((Wrapper)>[PointerTensor | me:97673971511 -> vw01:31569518363], (Wrapper)>[PointerTensor | me:3394630714 -> vw01:59572398722]), ((Wrapper)>[PointerTensor | me:44750036052 -> vw01:2192612609], (Wrapper)>[PointerTensor | me:62066742470 -> vw01:22828110608]), ((Wrapper)>[PointerTensor | me:49110356713 -> vw01:52203125671], (Wrapper)>[PointerTensor | me:18944313073 -> vw01:84066919905]), ((Wrapper)>[PointerTensor | me:96382164136 -> vw01:95041250289], (Wrapper)>[PointerTensor | me:97674678019 -> vw01:72885780145]), ((Wrapper)>[PointerTensor | me:94052782763 -> vw01:24510204795], (Wrapper)>[PointerTensor | me:30433856592 -> vw01:37913647438]), ((Wrapper)>[PointerTensor | me:85010511392 -> vw01:61547947461], (Wrapper)>[PointerTensor | me:46467149975 -> vw01:62573605024])])\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-wPwQW03QKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to be able to send distinct model to each worker to train.\n",
        "\n",
        "def update(data, target, model, optimizer):\n",
        "  model.send(data.location)\n",
        "  optimizer.zero_grad()\n",
        "  pred = model(data)\n",
        "  loss = loss_func(pred, target)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rs_5FPc3oFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define worker-based models and optimizer\n",
        "\n",
        "vw00_model = Net()\n",
        "vw01_model = Net()\n",
        "\n",
        "vw00_optimizer = optim.SGD(vw00_model.parameters(), lr=args.lr)\n",
        "vw01_optimizer = optim.SGD(vw01_model.parameters(), lr=args.lr)\n",
        "\n",
        "models = [vw00_model, vw01_model]\n",
        "params = [list(vw00_model.parameters()), list(vw01_model.parameters())]\n",
        "optimizers = [vw00_optimizer, vw01_optimizer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3gBf6h64T45",
        "colab_type": "text"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y47sg78I4WwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select batch on which to train\n",
        "data_index = 0\n",
        "\n",
        "# update remote models\n",
        "# here, iterate once per model\n",
        "\n",
        "for remote_index in range(len(compute_nodes)):\n",
        "  data, target = remote_dataset[remote_index][data_index]\n",
        "  models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmLAKR1742Qe",
        "colab_type": "text"
      },
      "source": [
        "#### Encrypted Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdMDzV043vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list to store encrypted model average\n",
        "new_params = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIcDKd2ZVMil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "3a447c5e-3c14-41ec-9d06-f0fed0b3cb65"
      },
      "source": [
        "# visualize the parameters\n",
        "for i in range(len(params[0])):\n",
        "  \n",
        "  # for each worker\n",
        "  spdz2_params = list()\n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    \n",
        "    lcop = params[remote_index][i].copy().get() \n",
        "    \n",
        "    print(\"\\nremote index: \", remote_index, \"\\n\")\n",
        "    print(lcop)\n",
        "    print(lcop.type())\n",
        "    \n",
        "    lcop_th = lcop * 10000\n",
        "    print(lcop_th)\n",
        "    \n",
        "    lcop_fx = lcop_th.type(torch.LongTensor)\n",
        "    print(lcop_fx)\n",
        "    print(lcop_fx.type())\n",
        "    \n",
        "    lcop_th_fl = lcop_fx.type(torch.FloatTensor)\n",
        "    lcop_fl = lcop_th_fl / 10000\n",
        "    print(lcop_fl)\n",
        "    print(lcop_fl.type())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "remote index:  0 \n",
            "\n",
            "tensor([[-0.6983, -0.5240]], requires_grad=True)\n",
            "torch.FloatTensor\n",
            "tensor([[-6983.4028, -5239.7515]], grad_fn=<MulBackward0>)\n",
            "tensor([[-6983, -5239]])\n",
            "torch.LongTensor\n",
            "tensor([[-0.6983, -0.5239]])\n",
            "torch.FloatTensor\n",
            "\n",
            "remote index:  1 \n",
            "\n",
            "tensor([[-0.2316, -0.2829]], requires_grad=True)\n",
            "torch.FloatTensor\n",
            "tensor([[-2316.2527, -2829.3748]], grad_fn=<MulBackward0>)\n",
            "tensor([[-2316, -2829]])\n",
            "torch.LongTensor\n",
            "tensor([[-0.2316, -0.2829]])\n",
            "torch.FloatTensor\n",
            "\n",
            "remote index:  0 \n",
            "\n",
            "tensor([0.3239], requires_grad=True)\n",
            "torch.FloatTensor\n",
            "tensor([3239.4980], grad_fn=<MulBackward0>)\n",
            "tensor([3239])\n",
            "torch.LongTensor\n",
            "tensor([0.3239])\n",
            "torch.FloatTensor\n",
            "\n",
            "remote index:  1 \n",
            "\n",
            "tensor([-0.5834], requires_grad=True)\n",
            "torch.FloatTensor\n",
            "tensor([-5834.4795], grad_fn=<MulBackward0>)\n",
            "tensor([-5834])\n",
            "torch.LongTensor\n",
            "tensor([-0.5834])\n",
            "torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Q8MBkO4-g-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6791f649-b638-432e-8f07-754e245fd912"
      },
      "source": [
        "# iterate through each parameter\n",
        "for i in range(len(params[0])):\n",
        "  \n",
        "  # for each worker\n",
        "  spdz_params_th = list()\n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    \n",
        "    # copy of parameter (cop): copy same parameter from each worker's model, floating type tensor\n",
        "    cop = params[remote_index][i].copy()\n",
        "    \n",
        "    # copy of parameter, thousands (cop_th): copy of parameter scaled up so that precision is not lost\n",
        "    # fixed precision parameter, thousands (fpp_th): fixed precision version of parameter scaled up so that precision is not lost\n",
        "    fpp_th = cop * 10000\n",
        "    \n",
        "    # encrypt on the remote machine. Note: fixed_precision_param is already a pointer. \n",
        "    # calling share encrypts data to which pointer is pointing. Returns a pointer to the MPC secret shared object. Need to fetch object.\n",
        "    encrypted_param_th = fpp_th.share(vw00, vw01, crypto_provider=aggr)\n",
        "    \n",
        "    # fetch the pointer to the MPC shared value\n",
        "    param_th = encrypted_param_th.get()\n",
        "    \n",
        "    # save parameter so can average with same parameter from other workers.\n",
        "    spdz_params_th.append(param_th)\n",
        "    \n",
        "  # average param from multiple workers, fetch back to local machine. Decrypt and decode from fixed precision back to float. \n",
        "  new_param_th = (spdz_params_th[0] + spdz_params_th[1]).get() / 2 #.float_precision() / 2 \n",
        "  new_param_float_th = new_param_th.type(torch.FloatTensor) \n",
        "  new_param_float = new_param_float_th / 10000\n",
        "  \n",
        "  # save new averaged parameter\n",
        "  new_params.append(new_param_float)\n",
        "\n",
        "print(new_params)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[-0.4649, -0.4034]]), tensor([-0.1297])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmLBZx--7DL_",
        "colab_type": "text"
      },
      "source": [
        "#### Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5TGZCcH7ESW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  for model in params:\n",
        "    for param in model:\n",
        "      param *= 0\n",
        "  \n",
        "  for model in models:\n",
        "    model.get()\n",
        "    \n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    for param_index in range(len(params[remote_index])):\n",
        "      params[remote_index][param_index].set_(new_params[param_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuQTWVNhAleq",
        "colab_type": "text"
      },
      "source": [
        "### Bring components together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nAnWJfz2Rtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f39acf8-441d-4f41-8860-5b5cf7a5ad8e"
      },
      "source": [
        "vw00.clear_objects()\n",
        "vw01.clear_objects()\n",
        "aggr.clear_objects()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:aggr #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMFCypLh18Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "693c6879-ac4e-406b-9ac8-70eb4f22d35a"
      },
      "source": [
        "# Send data to the workers\n",
        "remote_dataset = (list(), list())\n",
        "\n",
        "train_dist_dataset = []\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(trainloader):\n",
        "  data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "  remote_dataset[batch_idx % len(compute_nodes)].append((data, target))\n",
        "  \n",
        "\n",
        "print(remote_dataset)\n",
        "\n",
        "print(train_dist_dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([((Wrapper)>[PointerTensor | me:4123999739 -> vw00:5431085165], (Wrapper)>[PointerTensor | me:58315752382 -> vw00:8723786173]), ((Wrapper)>[PointerTensor | me:22099175038 -> vw00:20626012743], (Wrapper)>[PointerTensor | me:4690546354 -> vw00:58771177119]), ((Wrapper)>[PointerTensor | me:40550134044 -> vw00:99008222936], (Wrapper)>[PointerTensor | me:20968524747 -> vw00:90109189516]), ((Wrapper)>[PointerTensor | me:76869575886 -> vw00:72968744763], (Wrapper)>[PointerTensor | me:63865429116 -> vw00:3678453272]), ((Wrapper)>[PointerTensor | me:57349627461 -> vw00:21577710447], (Wrapper)>[PointerTensor | me:42807941661 -> vw00:20612847089]), ((Wrapper)>[PointerTensor | me:25291463134 -> vw00:44532892051], (Wrapper)>[PointerTensor | me:70257934229 -> vw00:51605873455]), ((Wrapper)>[PointerTensor | me:75944110813 -> vw00:66112569301], (Wrapper)>[PointerTensor | me:60131188431 -> vw00:77377266206]), ((Wrapper)>[PointerTensor | me:25121896235 -> vw00:83845377390], (Wrapper)>[PointerTensor | me:24111315256 -> vw00:85841445921]), ((Wrapper)>[PointerTensor | me:45872980558 -> vw00:2360086910], (Wrapper)>[PointerTensor | me:85431955463 -> vw00:13667609022]), ((Wrapper)>[PointerTensor | me:92656887667 -> vw00:17791386344], (Wrapper)>[PointerTensor | me:81338227909 -> vw00:56840228853]), ((Wrapper)>[PointerTensor | me:44999616572 -> vw00:52633400489], (Wrapper)>[PointerTensor | me:36645490188 -> vw00:75190779366]), ((Wrapper)>[PointerTensor | me:93049166222 -> vw00:16382047322], (Wrapper)>[PointerTensor | me:35541406010 -> vw00:89860840936]), ((Wrapper)>[PointerTensor | me:7036413918 -> vw00:29652905774], (Wrapper)>[PointerTensor | me:3399932752 -> vw00:26801910829]), ((Wrapper)>[PointerTensor | me:81827844928 -> vw00:51798394631], (Wrapper)>[PointerTensor | me:35844386004 -> vw00:77152218958]), ((Wrapper)>[PointerTensor | me:35646911299 -> vw00:14914251500], (Wrapper)>[PointerTensor | me:39755588285 -> vw00:60617810392]), ((Wrapper)>[PointerTensor | me:59953516165 -> vw00:79507458952], (Wrapper)>[PointerTensor | me:4625983285 -> vw00:41973569112]), ((Wrapper)>[PointerTensor | me:8999135226 -> vw00:28899948254], (Wrapper)>[PointerTensor | me:83429895732 -> vw00:18448461162]), ((Wrapper)>[PointerTensor | me:2197469482 -> vw00:84436661039], (Wrapper)>[PointerTensor | me:83595338761 -> vw00:13085072966]), ((Wrapper)>[PointerTensor | me:65895558706 -> vw00:9877304861], (Wrapper)>[PointerTensor | me:8979008572 -> vw00:32800175201]), ((Wrapper)>[PointerTensor | me:28283152742 -> vw00:80566870967], (Wrapper)>[PointerTensor | me:55627675948 -> vw00:59799114065]), ((Wrapper)>[PointerTensor | me:40709226977 -> vw00:93369386923], (Wrapper)>[PointerTensor | me:95716041375 -> vw00:34527909976]), ((Wrapper)>[PointerTensor | me:57219198646 -> vw00:12318903134], (Wrapper)>[PointerTensor | me:41444379916 -> vw00:71740179108]), ((Wrapper)>[PointerTensor | me:51006270466 -> vw00:63708066933], (Wrapper)>[PointerTensor | me:52268321922 -> vw00:5706538348]), ((Wrapper)>[PointerTensor | me:99575238014 -> vw00:84931218842], (Wrapper)>[PointerTensor | me:66065287173 -> vw00:11538448966]), ((Wrapper)>[PointerTensor | me:51062530739 -> vw00:83004592074], (Wrapper)>[PointerTensor | me:79998076291 -> vw00:31561174850])], [((Wrapper)>[PointerTensor | me:46034889169 -> vw01:33071047083], (Wrapper)>[PointerTensor | me:75971975237 -> vw01:74209488704]), ((Wrapper)>[PointerTensor | me:35324167464 -> vw01:60015440024], (Wrapper)>[PointerTensor | me:27227341957 -> vw01:29490899875]), ((Wrapper)>[PointerTensor | me:53507486431 -> vw01:87900741763], (Wrapper)>[PointerTensor | me:63844395163 -> vw01:70594437014]), ((Wrapper)>[PointerTensor | me:66761444221 -> vw01:54622768300], (Wrapper)>[PointerTensor | me:53372478246 -> vw01:74783524561]), ((Wrapper)>[PointerTensor | me:28792894748 -> vw01:78632047971], (Wrapper)>[PointerTensor | me:90069274997 -> vw01:68219312801]), ((Wrapper)>[PointerTensor | me:46924317749 -> vw01:18041904900], (Wrapper)>[PointerTensor | me:9695850488 -> vw01:5720534863]), ((Wrapper)>[PointerTensor | me:28756011599 -> vw01:16866600032], (Wrapper)>[PointerTensor | me:89132600971 -> vw01:45955024727]), ((Wrapper)>[PointerTensor | me:38646811332 -> vw01:95782749469], (Wrapper)>[PointerTensor | me:93994704713 -> vw01:18782089114]), ((Wrapper)>[PointerTensor | me:86143716886 -> vw01:63203233922], (Wrapper)>[PointerTensor | me:31663956713 -> vw01:2515233091]), ((Wrapper)>[PointerTensor | me:17587495404 -> vw01:62239083320], (Wrapper)>[PointerTensor | me:15792753803 -> vw01:82841769973]), ((Wrapper)>[PointerTensor | me:95299623587 -> vw01:5922451789], (Wrapper)>[PointerTensor | me:97734362376 -> vw01:21361615971]), ((Wrapper)>[PointerTensor | me:60604848295 -> vw01:48143825417], (Wrapper)>[PointerTensor | me:21475485310 -> vw01:39610604032]), ((Wrapper)>[PointerTensor | me:59043657666 -> vw01:26678420872], (Wrapper)>[PointerTensor | me:24889600046 -> vw01:38091580107]), ((Wrapper)>[PointerTensor | me:5216740095 -> vw01:63855420426], (Wrapper)>[PointerTensor | me:59389602890 -> vw01:12933472036]), ((Wrapper)>[PointerTensor | me:30496726173 -> vw01:51910207791], (Wrapper)>[PointerTensor | me:91736481484 -> vw01:96916812153]), ((Wrapper)>[PointerTensor | me:92312933049 -> vw01:53723632898], (Wrapper)>[PointerTensor | me:46881035859 -> vw01:44242665609]), ((Wrapper)>[PointerTensor | me:84835384167 -> vw01:81193237293], (Wrapper)>[PointerTensor | me:71202801555 -> vw01:50554704872]), ((Wrapper)>[PointerTensor | me:73479627697 -> vw01:90631506884], (Wrapper)>[PointerTensor | me:82022496499 -> vw01:36039452156]), ((Wrapper)>[PointerTensor | me:2002129594 -> vw01:54705154548], (Wrapper)>[PointerTensor | me:89588839117 -> vw01:69326312328]), ((Wrapper)>[PointerTensor | me:48251180846 -> vw01:95851979214], (Wrapper)>[PointerTensor | me:73178231737 -> vw01:58815415577]), ((Wrapper)>[PointerTensor | me:14176532784 -> vw01:99070868742], (Wrapper)>[PointerTensor | me:77567739328 -> vw01:82126273756]), ((Wrapper)>[PointerTensor | me:51794187385 -> vw01:93184658130], (Wrapper)>[PointerTensor | me:38921418131 -> vw01:78904195144]), ((Wrapper)>[PointerTensor | me:97284956641 -> vw01:8308040322], (Wrapper)>[PointerTensor | me:66494435081 -> vw01:84184023737]), ((Wrapper)>[PointerTensor | me:3189703913 -> vw01:47767758278], (Wrapper)>[PointerTensor | me:4090633882 -> vw01:16930579915]), ((Wrapper)>[PointerTensor | me:16331494554 -> vw01:36928440934], (Wrapper)>[PointerTensor | me:26099622711 -> vw01:54929034219])])\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3TCJ6Gbz9hw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4677afd5-3000-4139-8534-69d5e50d8bfd"
      },
      "source": [
        "print('length of remote dataset:\\t', len(remote_dataset))\n",
        "print('length of one item in remote dataset:\\t', len(remote_dataset[0]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of remote dataset:\t 2\n",
            "length of one item in remote dataset:\t 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nKeBU4h1Zbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define worker-based models and optimizer\n",
        "\n",
        "vw00_model = Net().send(vw00)\n",
        "vw01_model = Net().send(vw01)\n",
        "\n",
        "vw00_optimizer = optim.SGD(vw00_model.parameters(), lr=args.lr)\n",
        "vw01_optimizer = optim.SGD(vw01_model.parameters(), lr=args.lr)\n",
        "\n",
        "models = [vw00_model, vw01_model]\n",
        "params = [list(vw00_model.parameters()), list(vw01_model.parameters())]\n",
        "optimizers = [vw00_optimizer, vw01_optimizer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J3nO2tb4o8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to be able to send distinct model to each worker to train.\n",
        "\n",
        "def update2(data, target, model, optimizer):\n",
        "  # model.send(data.location)\n",
        "  optimizer.zero_grad()\n",
        "  pred = model(data)\n",
        "  loss = loss_func(pred, target)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPzaH99hx6zW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "dded7c5b-dbf0-4fe9-ed9e-2a5ef0f57c9b"
      },
      "source": [
        "# figure out the guts of the training mechanism before putting into function.\n",
        "\n",
        "for data_index in range(len(remote_dataset[0])):\n",
        "  \n",
        "  # update remote models\n",
        "  \n",
        "  for remote_index in range(len(compute_nodes)):\n",
        "    print('data index: \\t', data_index, '\\tremote index:\\t', remote_index)\n",
        "    data, target = remote_dataset[remote_index][data_index]\n",
        "    model = models[remote_index]\n",
        "    opt = optimizers[remote_index]\n",
        "    \n",
        "    models[remote_index] = update2(data, target, model, opt)\n",
        "    \n",
        "  # encrypted aggregation\n",
        "  new_params = list() # list to store encrypted model average\n",
        "  \n",
        "  for i in range(len(params[0])): # iterate through each parameter\n",
        "\n",
        "    # for each worker\n",
        "    spdz_params_th = list()\n",
        "    for remote_index in range(len(compute_nodes)):\n",
        "\n",
        "      # copy of parameter (cop): copy same parameter from each worker's model, floating type tensor\n",
        "      cop = params[remote_index][i].copy()\n",
        "\n",
        "      # copy of parameter, thousands (cop_th): copy of parameter scaled up so that precision is not lost\n",
        "      # fixed precision parameter, thousands (fpp_th): fixed precision version of parameter scaled up so that precision is not lost\n",
        "      fpp_th = cop * 10000\n",
        "\n",
        "      # encrypt on the remote machine. Note: fixed_precision_param is already a pointer. \n",
        "      # calling share encrypts data to which pointer is pointing. Returns a pointer to the MPC secret shared object. Need to fetch object.\n",
        "      encrypted_param_th = fpp_th.share(vw00, vw01, crypto_provider=aggr)\n",
        "\n",
        "      # fetch the pointer to the MPC shared value\n",
        "      param_th = encrypted_param_th.get()\n",
        "\n",
        "      # save parameter so can average with same parameter from other workers.\n",
        "      spdz_params_th.append(param_th)\n",
        "\n",
        "    # average param from multiple workers, fetch back to local machine. Decrypt and decode from fixed precision back to float. \n",
        "    new_param_th = (spdz_params_th[0] + spdz_params_th[1]).get() / 2 #.float_precision() / 2 \n",
        "    new_param_float_th = new_param_th.type(torch.FloatTensor) \n",
        "    new_param_float = new_param_float_th / 10000\n",
        "\n",
        "    # save new averaged parameter\n",
        "    new_params.append(new_param_float)\n",
        "\n",
        "  print(new_params)  \n",
        "  \n",
        "  # cleanup\n",
        "  with torch.no_grad():\n",
        "    for model in params:\n",
        "      for param in model:\n",
        "        param *= 0\n",
        "\n",
        "    for model in models:\n",
        "      model.get()\n",
        "\n",
        "    for remote_index in range(len(compute_nodes)):\n",
        "      for param_index in range(len(params[remote_index])):\n",
        "        params[remote_index][param_index].set_(new_params[param_index])\n",
        "\n",
        "  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data index: \t 0 \tremote index:\t 0\n",
            "data index: \t 0 \tremote index:\t 1\n",
            "[tensor([[0.4501, 0.0806]]), tensor([0.1653])]\n",
            "data index: \t 1 \tremote index:\t 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    259\u001b[0m             new_args, new_kwargs, new_type, args_type = syft.frameworks.torch.hook_args.hook_function_args(\n\u001b[0;32m--> 260\u001b[0;31m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_args_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mhook_function_args\u001b[0;34m(attr, args, kwargs, return_args_type)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Try running it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36mthree_fold\u001b[0;34m(lambdas, args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     return (\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mLoggingTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureTorchTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mLoggingTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPureTorchTensorFoundError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ce31d80160ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# encrypted aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-8d65af4ac83c>\u001b[0m in \u001b[0;36mupdate2\u001b[0;34m(data, target, model, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# model.send(data.location)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b7ff37e9aa9a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mcmd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{attr.__module__}.{attr.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mcmd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{attr.__module__}.{attr.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: matrices expected, got 1D, 2D tensors at /pytorch/aten/src/TH/generic/THTensorMath.cpp:956"
          ]
        }
      ]
    }
  ]
}