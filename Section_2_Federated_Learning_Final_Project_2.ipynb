{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 2 - Federated Learning Final Project 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewotawa/secure_private_ai/blob/master/Section_2_Federated_Learning_Final_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM6v2FitGLvc",
        "colab_type": "text"
      },
      "source": [
        "# Federated Learning Final Project\n",
        "\n",
        "## Overview\n",
        "* See  <a href=\"https://classroom.udacity.com/nanodegrees/nd185/parts/3fe1bb10-68d7-4d84-9c99-9539dedffad5/modules/28d685f0-0cb1-4f94-a8ea-2e16614ab421/lessons/c8fe481d-81ea-41be-8206-06d2deeb8575/concepts/a5fb4b4c-e38a-48de-b2a7-4e853c62acbe\">video</a> for additional details. \n",
        "* Do Federated Learning where the central server is not trusted with the raw gradients.  \n",
        "* In the final project notebook, you'll receive a dataset.  \n",
        "* Train on the dataset using Federated Learning.  \n",
        "* The gradients should not come up to the server in raw form.  \n",
        "* Instead, use the new .move() command to move all of the gradients to one of the workers, sum them up there, and then bring that batch up to the central server and then bring that batch up \n",
        "* Idea: the central server never actually sees the raw gradient for any person.  \n",
        "* We'll look at secure aggregation in course 3.  \n",
        "* For now, do a larger-scale Federated Learning case where you handle the gradients in a special way.\n",
        "\n",
        "## Approach\n",
        "* Reviewing methods of classmates for Federated Learning. \n",
        "\n",
        "## References\n",
        "*  <a href = \"https://github.com/edgarinvillegas/private-ai/blob/master/Section%203%20-%20Final%20project.ipynb/\">GitHub Notebook</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCOI3fXnGWr0",
        "colab_type": "text"
      },
      "source": [
        "### Install libraries and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGKXOXqmF8TZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89c39011-6897-43da-ed21-accc6c65a64e"
      },
      "source": [
        "# PySyft\n",
        "\n",
        "!pip install syft\n",
        "\n",
        "import syft as sy\n",
        "\n",
        "# PyTorch\n",
        "\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Numpy\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 42.9MB/s \n",
            "\u001b[?25hCollecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 61.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Collecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 50.6MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.7MB/s \n",
            "\u001b[?25hCollecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 47.2MB/s \n",
            "\u001b[?25hCollecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d2/bf72435a7d56f94b57efdeae26c76bf0d16f409fd44ff595da745c3fbefd/websockets-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 59.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 25.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 27.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: lz4, msgpack, zstd, websocket-client, pyyaml, tf-encrypted, python-engineio, python-socketio, flask-socketio, websockets, syft\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.7 websocket-client-0.56.0 websockets-8.0.1 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0721 06:17:45.494817 139874483152768 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0721 06:17:45.508292 139874483152768 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrMvtqXSHd9i",
        "colab_type": "text"
      },
      "source": [
        "###  Recall Toy Federated Learning\n",
        "\n",
        "Use the data and model from Section 2\n",
        "\n",
        "- a toy dataset\n",
        "- a model\n",
        "- some basic training logic for training a model to fit the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI096VvCHCVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Dataset\n",
        "data = torch.tensor([[1.,1],[0,1],[1,0],[0,0]], requires_grad=True)\n",
        "target = torch.tensor([[1.],[1], [0], [0]], requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5IEgR_LH5RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Toy Model\n",
        "model = nn.Linear(2,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOGXMlEkH8P1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer\n",
        "opt = optim.SGD(params=model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vanu9rXIV3k",
        "colab_type": "text"
      },
      "source": [
        "### Federated Learning\n",
        "\n",
        "Set up hook, virtual workers, and virtual aggregator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkNHvMkJIVSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "411cb252-f74e-475c-a920-ad52133fba22"
      },
      "source": [
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "vw00 = sy.VirtualWorker(hook, id=\"vw00\")\n",
        "vw01 = sy.VirtualWorker(hook, id=\"vw01\")\n",
        "\n",
        "aggr = sy.VirtualWorker(hook, id=\"aggr\")"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0721 07:50:33.475393 139874483152768 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zu-lAUzRuTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f7a8bfd-3efa-4570-bcee-e29af60e7b76"
      },
      "source": [
        "vw00.clear_objects()\n",
        "vw01.clear_objects()\n",
        "aggr.clear_objects()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:aggr #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSrPCbiGIk7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e1206b13-f8cf-4f1f-e87b-eed8814fe667"
      },
      "source": [
        "data_vw00 = data[0:2].send(vw00)\n",
        "target_vw00 = target[0:2].send(vw00)\n",
        "\n",
        "vw00._objects"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{11294118747: tensor([[1., 1.],\n",
              "         [0., 1.]], requires_grad=True), 70488089605: tensor([[1.],\n",
              "         [1.]], requires_grad=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVk2J-Q4IrAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6b4c2f85-5445-48fd-c469-9b7984a0c64d"
      },
      "source": [
        "data_vw01 = data[2:4].send(vw01)\n",
        "target_vw01 = target[2:4].send(vw01)\n",
        "\n",
        "vw01._objects"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3132272333: tensor([[1., 0.],\n",
              "         [0., 0.]], requires_grad=True), 85255226377: tensor([[0.],\n",
              "         [0.]], requires_grad=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE_1M0b1IyOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = [(data_vw00, target_vw00), (data_vw01, target_vw01)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zwHPn6FI6bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fed_train(iterations=20):\n",
        "\n",
        "    # Need to define separate model and optimizer for each worker. Need to move the models to the workers\n",
        "\n",
        "    models = {\n",
        "        'vw00': nn.Linear(2,1).send('vw00'),\n",
        "        'vw01': nn.Linear(2,1).send('vw01')\n",
        "    }\n",
        "\n",
        "    opts = {\n",
        "        'vw00': optim.SGD(params=models['vw00'].parameters(), lr=0.1),\n",
        "        'vw01': optim.SGD(params=models['vw01'].parameters(), lr=0.1)\n",
        "    }\n",
        "    \n",
        "    for iter in range(iterations):\n",
        "        \n",
        "        print(iter)\n",
        "\n",
        "        for _data, _target in datasets:\n",
        "\n",
        "            # locate the data, identify model, optimizer by dataset ids\n",
        "            worker_id = _data.location.id\n",
        "            model = models[worker_id]\n",
        "            opt = opts[worker_id]\n",
        "            \n",
        "            print(\"data location: \", _data.location, \"\\tworker ID: \", worker_id)\n",
        "            \n",
        "            # do normal training\n",
        "            opt.zero_grad()\n",
        "            pred = model(_data)\n",
        "            loss = ((pred - _target)**2).sum()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    return models, model.parameters()\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBvQNMDcJZUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "caa85216-7152-4f58-9815-1911e985621a"
      },
      "source": [
        "models, params = fed_train()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "1\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "2\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "3\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "4\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "5\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "6\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "7\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "8\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "9\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "10\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "11\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "12\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "13\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "14\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "15\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "16\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "17\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "18\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n",
            "19\n",
            "data location:  <VirtualWorker id:vw00 #objects:4> \tworker ID:  vw00\n",
            "data location:  <VirtualWorker id:vw01 #objects:4> \tworker ID:  vw01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULPslqU2LOR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8f5273d-9dfc-4303-cc9d-786f5d4d63c7"
      },
      "source": [
        "aggr._objects"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDplfWolWIm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f919bdb5-7567-43d1-9bbb-c5787986f515"
      },
      "source": [
        "print(models)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'vw00': Linear(in_features=2, out_features=1, bias=True), 'vw01': Linear(in_features=2, out_features=1, bias=True)}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}