{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 1 - Differential Privacy Work Copy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "W3vT3Lf30W83"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewotawa/secure_private_ai/blob/master/Section_1_Differential_Privacy_Work_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umYMDOuy0Wqb",
        "colab_type": "text"
      },
      "source": [
        "## Lesson: Toy Differential Privacy - Simple Database Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21BKLtV40Wqo",
        "colab_type": "text"
      },
      "source": [
        "In this section we're going to play around with Differential Privacy in the context of a database query. The database is going to be a VERY simple database with only one boolean column. Each row corresponds to a person. Each value corresponds to whether or not that person has a certain private attribute (such as whether they have a certain disease, or whether they are above/below a certain age). We are then going to learn how to know whether a database query over such a small database is differentially private or not - and more importantly - what techniques are at our disposal to ensure various levels of privacy\n",
        "\n",
        "\n",
        "### First We Create a Simple Database\n",
        "\n",
        "Step one is to create our database - we're going to do this by initializing a random list of 1s and 0s (which are the entries in our database). Note - the number of entries directly corresponds to the number of people in our database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nF0ueKI9tsI",
        "colab_type": "code",
        "outputId": "be631dd0-4d38-4919-c058-a7040d1d8b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# PySyft\n",
        "# Install prerequisite for install\n",
        "\n",
        "# ERROR: syft 0.1.19a1 has requirement msgpack>=0.6.1, but you'll have msgpack 0.5.6 which is incompatible.\n",
        "\n",
        "!pip install --upgrade --force-reinstall msgpack"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting msgpack\n",
            "  Using cached https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: msgpack\n",
            "  Found existing installation: msgpack 0.6.1\n",
            "    Uninstalling msgpack-0.6.1:\n",
            "      Successfully uninstalled msgpack-0.6.1\n",
            "Successfully installed msgpack-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwlOPvkH2sfy",
        "colab_type": "code",
        "outputId": "24a21453-56ca-4508-e772-d6e1df7897c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# PySyft\n",
        "# Install dependencies\n",
        "\n",
        "# https://github.com/OpenMined/PySyft\n",
        "# https://colab.research.google.com/drive/14tNU98OKPsP55Y3IgFtXPfd4frqbkrxK#scrollTo=qpX6fqECKGyk\n",
        "\n",
        "!pip install tf-encrypted\n",
        "\n",
        "! URL=\"https://github.com/openmined/PySyft.git\" && FOLDER=\"PySyft\" && if [ ! -d $FOLDER ]; then git clone -b dev --single-branch $URL; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
        "\n",
        "!cd PySyft; python setup.py install  > /dev/null\n",
        "\n",
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('./PySyft'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    \n",
        "!pip install --upgrade --force-reinstall lz4\n",
        "!pip install --upgrade --force-reinstall websocket\n",
        "!pip install --upgrade --force-reinstall websockets\n",
        "!pip install --upgrade --force-reinstall zstd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-encrypted in /usr/local/lib/python3.6/dist-packages (0.5.6)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (5.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted) (1.16.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.12.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.33.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (0.15.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted) (3.1.1)\n",
            "From https://github.com/openmined/PySyft\n",
            " * branch              HEAD       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Collecting lz4\n",
            "  Using cached https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: lz4\n",
            "  Found existing installation: lz4 2.1.10\n",
            "    Uninstalling lz4-2.1.10:\n",
            "      Successfully uninstalled lz4-2.1.10\n",
            "Successfully installed lz4-2.1.10\n",
            "Collecting websocket\n",
            "Collecting greenlet (from websocket)\n",
            "  Using cached https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting gevent (from websocket)\n",
            "  Using cached https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: greenlet, gevent, websocket\n",
            "  Found existing installation: greenlet 0.4.15\n",
            "    Uninstalling greenlet-0.4.15:\n",
            "      Successfully uninstalled greenlet-0.4.15\n",
            "  Found existing installation: gevent 1.4.0\n",
            "    Uninstalling gevent-1.4.0:\n",
            "      Successfully uninstalled gevent-1.4.0\n",
            "  Found existing installation: websocket 0.2.1\n",
            "    Uninstalling websocket-0.2.1:\n",
            "      Successfully uninstalled websocket-0.2.1\n",
            "Successfully installed gevent-1.4.0 greenlet-0.4.15 websocket-0.2.1\n",
            "Collecting websockets\n",
            "  Using cached https://files.pythonhosted.org/packages/43/71/8bfa882b9c502c36e5c9ef6732969533670d2b039cbf95a82ced8f762b80/websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: websockets\n",
            "  Found existing installation: websockets 7.0\n",
            "    Uninstalling websockets-7.0:\n",
            "      Successfully uninstalled websockets-7.0\n",
            "Successfully installed websockets-7.0\n",
            "Collecting zstd\n",
            "Installing collected packages: zstd\n",
            "  Found existing installation: zstd 1.4.0.0\n",
            "    Uninstalling zstd-1.4.0.0:\n",
            "      Successfully uninstalled zstd-1.4.0.0\n",
            "Successfully installed zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg98YzRlC9sL",
        "colab_type": "code",
        "outputId": "76488308-6208-430b-b32b-d03a7073e7ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "# PySyft\n",
        "# make sure nothing's missing.\n",
        "\n",
        "!pip install syft\n",
        "!pip install numpy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages/syft-0.1.21a1-py3.6.egg (0.1.21a1)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.0.3)\n",
            "Requirement already satisfied: flask_socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages/Flask_SocketIO-4.1.0-py3.6.egg (from syft) (4.1.0)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: tf_encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.6)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: websocket_client>=0.56.0 in /usr/local/lib/python3.6/dist-packages/websocket_client-0.56.0-py3.6.egg (from syft) (0.56.0)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (7.0)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages/python_socketio-4.2.0-py3.6.egg (from flask_socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages/python_engineio-3.8.2.post1-py3.6.egg (from python-socketio>=2.1.0->flask_socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl8yhsLZ7CsZ",
        "colab_type": "code",
        "outputId": "3bff7d09-e49e-4097-b04b-12c0513cfa2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# PyTorch\n",
        "# Install Dependencies\n",
        "# https://colab.research.google.com/drive/1gJAAN3UI9005ecVmxPun5ZLCGu4YBtLo#scrollTo=XiHYo3hEhwdk\n",
        "\n",
        "!pip3 install torch torchvision"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARnKAxeAAw1Z",
        "colab_type": "code",
        "outputId": "13aff384-241e-48e4-dfd4-1c510ae342c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import libraries\n",
        "# https://colab.research.google.com/drive/14tNU98OKPsP55Y3IgFtXPfd4frqbkrxK#scrollTo=ZgomH7s4R5cT\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_JcVpZg0Wq2",
        "colab_type": "code",
        "outputId": "995b81d0-bbeb-47e9-d9a6-83f1b1b3ca91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import torch\n",
        "\n",
        "# the number of entries in our database\n",
        "num_entries = 5000\n",
        "\n",
        "db = torch.rand(num_entries) > 0.5\n",
        "db"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW5YKpBE0Wr8",
        "colab_type": "text"
      },
      "source": [
        "## Project: Generate Parallel Databases\n",
        "\n",
        "Key to the definition of differenital privacy is the ability to ask the question \"When querying a database, if I removed someone from the database, would the output of the query be any different?\". Thus, in order to check this, we must construct what we term \"parallel databases\" which are simply databases with one entry removed. \n",
        "\n",
        "In this first project, I want you to create a list of every parallel database to the one currently contained in the \"db\" variable. Then, I want you to create a function which both:\n",
        "\n",
        "- creates the initial database (db)\n",
        "- creates all parallel databases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5aR-IVM0WsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNAYmw4h0Wsk",
        "colab_type": "code",
        "outputId": "7757f11c-38a0-4f39-a030-bbdabbba55c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "db.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0q2WBprTGKZ",
        "colab_type": "code",
        "outputId": "71c5354d-bdd6-43df-e90e-09da3789cc68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "db"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saYc_cB30WtF",
        "colab_type": "code",
        "outputId": "cd61ed16-d454-43a7-cdfd-260419cb7ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# establish a counter\n",
        "i = 0\n",
        "\n",
        "# define a place to put the subtensors\n",
        "outputs = []\n",
        "\n",
        "\n",
        "# generate the tensors of length 4999 that each are missing one sequential element\n",
        "for row in db:\n",
        "  a = db[:i]\n",
        "  b = db[i+1:]\n",
        "  tensor = torch.cat([a, b])\n",
        "  outputs.insert(i, tensor)\n",
        "\n",
        "  i += 1\n",
        "  \n",
        "print(outputs)\n",
        "print(len(outputs))\n",
        "\n",
        "\n",
        "# validate that each tensor in the list is of length 4999\n",
        "# for j in outputs:\n",
        "#  print(j.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([1, 0, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 0, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 1, 1], dtype=torch.uint8), tensor([1, 1, 0,  ..., 1, 1, 0], dtype=torch.uint8)]\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39PqER5bfxd",
        "colab_type": "text"
      },
      "source": [
        "Instructor's work from the video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYqnR4fX0Wtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1: Generate a function that creates a parallel database where we specify which value in the database you want to remove.\n",
        "\n",
        "def get_parallel_db(db, remove_index):\n",
        "  return torch.cat((\n",
        "      db[:remove_index],\n",
        "      db[remove_index+1:]\n",
        "  ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0eLBNg4dRoa",
        "colab_type": "code",
        "outputId": "5d43b6c0-035d-4c65-fff4-0d8f07205a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_parallel_db(db, 3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEMesO6qdbII",
        "colab_type": "code",
        "outputId": "f286355f-2528-4349-c7fd-530ddaf39069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_parallel_db(db, 3).shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4999])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJT5clam0WvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Create a function which iterates over all values in the database, generating a copy with one element removed at the specified index."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Domck7i1dvVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_parallel_dbs(db):\n",
        "  # Instantiate a list to contain all of the parallel databases.\n",
        "\n",
        "  parallel_dbs = list()\n",
        "  \n",
        "  #  Iterate over the database \n",
        "\n",
        "  for i in range(len(db)):\n",
        "    pdb = get_parallel_db(db, i)\n",
        "    parallel_dbs.append(pdb)\n",
        "    \n",
        "  return parallel_dbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxgU6wW5d8Kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdbs = get_parallel_dbs(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnFP61_pezQu",
        "colab_type": "code",
        "outputId": "7d88dd05-8dc5-4cb4-b24d-2a71b7667299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pdbs"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([1, 0, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 0, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " tensor([1, 1, 0,  ..., 1, 0, 1], dtype=torch.uint8),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vAyMvzKfBNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Consolidate the two preceding functions\n",
        "\n",
        "def create_db_and_parallels(num_entries):\n",
        "  db = torch.randn(num_entries) > 0.5\n",
        "  pdbs = get_parallel_dbs(db)\n",
        "  return db, pdbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhxJSo9Nfxgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK2d4-8pf4KK",
        "colab_type": "code",
        "outputId": "5d5ac043-e6b5-4242-b1af-77d8a59dbcaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "db"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obewZHhqf6Ga",
        "colab_type": "code",
        "outputId": "53d81415-4653-42b8-e4c5-deb3f540ff02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "pdbs"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8),\n",
              " tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        dtype=torch.uint8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqvXAMZa0Wvw",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Towards Evaluating The Differential Privacy of a Function\n",
        "\n",
        "Intuitively, we want to be able to query our database and evaluate whether or not the result of the query is leaking \"private\" information. As mentioned previously, this is about evaluating whether the output of a query changes when we remove someone from the database. Specifically, we want to evaluate the *maximum* amount the query changes when someone is removed (maximum over all possible people who could be removed). So, in order to evaluate how much privacy is leaked, we're going to iterate over each person in the database and measure the difference in the output of the query relative to when we query the entire database. \n",
        "\n",
        "Just for the sake of argument, let's make our first \"database query\" a simple sum. Aka, we're going to count the number of 1s in the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_LD_Or50Wv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99mgpDrP0Wwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db):\n",
        "    return db.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP7aCp3z0Wxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_db_result = query(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLmwHuRe0Wyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sensitivity = 0\n",
        "for pdb in pdbs:\n",
        "    pdb_result = query(pdb)\n",
        "    \n",
        "    db_distance = torch.abs(pdb_result - full_db_result)\n",
        "    \n",
        "    if(db_distance > sensitivity):\n",
        "        sensitivity = db_distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AMLurUy0Wzm",
        "colab_type": "code",
        "outputId": "06626599-7fe3-4f77-dea6-74c2cd927073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sensitivity"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgO3Z9vO-tEK",
        "colab_type": "text"
      },
      "source": [
        "### Create a single function called sensitivity (query, n_entries)\n",
        "* initialize a database of correct size\n",
        "* initialize all parallel databases\n",
        "* run the query over all databases\n",
        "* correctly calculate sensitivity\n",
        "* return the sensitivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sZt52wIAFu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input query function to sensitivity function\n",
        "def query(db):\n",
        "  return db.sum()\n",
        "\n",
        "# Generate a function that creates a parallel database where we specify which value in the database you want to remove.\n",
        "def get_parallel_db(db, remove_index):\n",
        "  return torch.cat((\n",
        "      db[:remove_index],\n",
        "      db[remove_index+1:]\n",
        "  ))\n",
        "\n",
        "# Create a function which iterates over all values in the database, generating a copy with one element removed at the specified index.\n",
        "def get_parallel_dbs(db):\n",
        "  # Instantiate a list to contain all of the parallel databases.\n",
        "\n",
        "  parallel_dbs = list()\n",
        "  \n",
        "  #  Iterate over the database \n",
        "\n",
        "  for i in range(len(db)):\n",
        "    pdb = get_parallel_db(db, i)\n",
        "    parallel_dbs.append(pdb)\n",
        "    \n",
        "  return parallel_dbs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meu9pwswED5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sensitivity function\n",
        "def sensitivity(query, n_entries):\n",
        "  \n",
        "  # initialize a database of correct size\n",
        "  db = torch.rand(n_entries) > 0.5\n",
        "  \n",
        "  # initialize all parallel databases\n",
        "  pdbs = get_parallel_dbs(db)\n",
        "  \n",
        "  # run the query over all the databases\n",
        "  # correctly calculate sensitivity\n",
        "  \n",
        "  full_db_result = query(db)\n",
        "  \n",
        "  sensitivity = 0\n",
        "  for pdb in pdbs:\n",
        "      pdb_result = query(pdb)\n",
        "\n",
        "      db_distance = torch.abs(pdb_result - full_db_result)\n",
        "\n",
        "      if(db_distance > sensitivity):\n",
        "          sensitivity = db_distance\n",
        "  \n",
        "  \n",
        "  # return the sensitivity\n",
        "  return sensitivity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2eBf8g5EWBp",
        "colab_type": "code",
        "outputId": "d5bbfaea-b730-49ac-e530-733b278518ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s = sensitivity(query, 5000)\n",
        "print(s)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy591Pcc0Wzy",
        "colab_type": "text"
      },
      "source": [
        "# Project - Evaluating the Privacy of a Function\n",
        "\n",
        "In the last section, we measured the difference between each parallel db's query result and the query result for the entire database and then calculated the max value (which was 1). This value is called \"sensitivity\", and it corresponds to the function we chose for the query. Namely, the \"sum\" query will always have a sensitivity of exactly 1. However, we can also calculate sensitivity for other functions as well.\n",
        "\n",
        "Let's try to calculate sensitivity for the \"mean\" function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uLc-qDk0Wz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSQSu1xV0W0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sensitivity(query, n_entries=1000):\n",
        "  \n",
        "  db, pdbs = create_db_and_parallels(n_entries)\n",
        "  \n",
        "  full_db_result = query(db)\n",
        "  \n",
        "  max_distance = 0\n",
        "  \n",
        "  for pdb in pdbs:\n",
        "    pdb_result = query(pdb)\n",
        "    \n",
        "    db_distance = torch.abs(pdb_result - full_db_result)\n",
        "    \n",
        "    if(db_distance > max_distance): \n",
        "      max_distance = db_distance\n",
        "      \n",
        "  return max_distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6eXpyeW0W0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db):\n",
        "  return db.float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v18ThHz0W01",
        "colab_type": "code",
        "outputId": "6db66fc7-0130-4dd2-c6d1-cfce8e2613e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sensitivity(query)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0007)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWcxm4z20W1N",
        "colab_type": "code",
        "outputId": "ecead6d5-bf6c-4820-8881-39213f53e678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# average value in the database divided by the number of entries\n",
        "\n",
        "avg = (1 + 0) / 2\n",
        "\n",
        "avg / 1000"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB8N4H430W1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reFuA8qw0W1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1LdfVlk0W1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MoX7PlF0W2B",
        "colab_type": "text"
      },
      "source": [
        "Wow! That sensitivity is WAY lower. Note the intuition here. \"Sensitivity\" is measuring how sensitive the output of the query is to a person being removed from the database. For a simple sum, this is always 1, but for the mean, removing a person is going to change the result of the query by rougly 1 divided by the size of the database (which is much smaller). Thus, \"mean\" is a VASTLY less \"sensitive\" function (query) than SUM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUapGllA0W2E",
        "colab_type": "text"
      },
      "source": [
        "# Project: Calculate L1 Sensitivity For Threshold\n",
        "\n",
        "In this first project, I want you to calculate the sensitivty for the \"threshold\" function. \n",
        "\n",
        "- First compute the sum over the database (i.e. sum(db)) and return whether that sum is greater than a certain threshold.\n",
        "- Then, I want you to create databases of size 10 and threshold of 5 and calculate the sensitivity of the function. \n",
        "- Finally, re-initialize the database 10 times and calculate the sensitivity each time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUohuVBBk4NZ",
        "colab_type": "text"
      },
      "source": [
        "My work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SazAxTCO0W2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgc-yaOR0W2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the query function:\n",
        "#  compute the sum over the database and return whether the sum is greater than or less than a certain threshold.\n",
        "\n",
        "def query(t, db):\n",
        "  # calculate sum of database\n",
        "  db_sum = db.sum()\n",
        "  \n",
        "  # initialize a variable for distance past threshold\n",
        "  above_t = 0\n",
        "  \n",
        "  # update above_t if sum of database is above threshold\n",
        "  if(db_sum > t):\n",
        "    above_t = db_sum - t\n",
        "    \n",
        "  return above_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGK0w_7D0W2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 10 databases of size 10\n",
        "\n",
        "def get_dbs(num_dbs, num_db_entries):\n",
        "  # Instantiate a list to contain all of the databases.\n",
        "\n",
        "  dbs = list()\n",
        "  \n",
        "  #  Iterate over the number of databases (num_dbs) to generate as many dbs of length num_db_entries \n",
        "\n",
        "  for i in range(num_dbs):\n",
        "    db = torch.rand(num_db_entries) > 0.5\n",
        "    dbs.append(db)\n",
        "  \n",
        "  return dbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_n3-y8yoIXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbs = get_dbs(10, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfQwmH3xowAm",
        "colab_type": "code",
        "outputId": "abe47231-8e42-4c8a-a9c6-c3960ba38511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(dbs)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE5qvqu6os1n",
        "colab_type": "code",
        "outputId": "98e3c0ea-0930-4473-8ee2-cacc3963e6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dbs[0].shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j2-ykqR0W2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# query each database with a theshold of 5 (calculate sensitivity)\n",
        "\n",
        "def query_dbs(dbs, query, t):\n",
        "  \n",
        "  qry_out = list()\n",
        "  \n",
        "  for i in range(len(dbs)):\n",
        "    out = int(query(t, dbs[i]))\n",
        "    qry_out.append(out)\n",
        "    \n",
        "  return qry_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t09mK96ilF-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print out the sensitivity of each database\n",
        "\n",
        "result = query_dbs(dbs, query, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3mDh4nQqK4I",
        "colab_type": "code",
        "outputId": "3c57f24d-5788-440b-f600-26a34c39703d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 2, 0, 1, 0, 0, 0, 0, 2, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWa60aFGqrd8",
        "colab_type": "text"
      },
      "source": [
        "Instructor's work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LmPflxGqt0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db, threshold=5):\n",
        "  return (db.sum() > threshold).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EDjB2e33Ggu",
        "colab_type": "code",
        "outputId": "41032e5a-6007-44b9-dc94-e683bd5c56a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# explicitly calculate the sensitivity:\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  sens_f = sensitivity(query, n_entries=10)\n",
        "  print(sens_f)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6_q4Gv10W22",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: A Basic Differencing Attack\n",
        "\n",
        "Sadly none of the functions we've looked at so far are differentially private (despite them having varying levels of sensitivity). The most basic type of attack can be done as follows.\n",
        "\n",
        "Let's say we wanted to figure out a specific person's value in the database. All we would have to do is query for the sum of the entire database and then the sum of the entire database without that person!\n",
        "\n",
        "# Project: Perform a Differencing Attack on Row 10\n",
        "\n",
        "In this project, I want you to construct a database and then demonstrate how you can use two different sum queries to explose the value of the person represented by row 10 in the database (note, you'll need to use a database with at least 10 rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBgzuxzZe4Fg",
        "colab_type": "text"
      },
      "source": [
        "My work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWqC7gel0W27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Duwy2130W3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function that creates a parallel database; specify which value in the database to remove.\n",
        "\n",
        "def get_parallel_db(db, remove_index):\n",
        "  return torch.cat((\n",
        "      db[:remove_index],\n",
        "      db[remove_index+1:]\n",
        "  ))\n",
        "\n",
        "# define the query functions\n",
        "\n",
        "def query_sum(db):\n",
        "  return db.sum()\n",
        "\n",
        "def query_mean(db):\n",
        "  return db.float().mean()\n",
        "\n",
        "def query_threshold(db, threshold=5):\n",
        "  return (db.sum() > threshold).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccPfULmX0W3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# differential attack function\n",
        "\n",
        "def diff_attack(num_entries, remove_index, query):\n",
        "  \n",
        "  # create the base database\n",
        "  db = torch.rand(num_entries) > 0.5\n",
        "  \n",
        "  # generate the comparison data that removes the nth (remove_index) entity from the database. store as pdb\n",
        "  pdb = get_parallel_db(db, remove_index)\n",
        "  \n",
        "  # initialize a list to hold the results\n",
        "  output = list()\n",
        "  \n",
        "  # calculate the sensitivity of the original database, append to output list\n",
        "  db_out = query(db)\n",
        "  output.append(db_out)\n",
        "  \n",
        "  # calculate the sensitivity of the dataset with the element removed, append to output list\n",
        "  pdb_out = query(pdb)\n",
        "  output.append(pdb_out)\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY1mmvbk0W3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of the three query functions to iterate over them.\n",
        "\n",
        "query_list = [query_sum, query_mean, query_threshold]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTHsp3XP0W3h",
        "colab_type": "code",
        "outputId": "1cb6dfe7-d998-4b6c-a202-a96d28337599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# perform differential attack on the list of queries. \n",
        "\n",
        "num_entries = 5000\n",
        "remove_index = 10\n",
        "\n",
        "for query in range(len(query_list)):\n",
        "  print(query_list[query])\n",
        "  output = diff_attack(num_entries, remove_index, query_list[query])\n",
        "  print(output)\n",
        "  print(output[0] - output[1])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function query_sum at 0x7ff2f15dd2f0>\n",
            "[tensor(2457), tensor(2457)]\n",
            "tensor(0)\n",
            "<function query_mean at 0x7ff2efc9e488>\n",
            "[tensor(0.5002), tensor(0.5001)]\n",
            "tensor(9.9957e-05)\n",
            "<function query_threshold at 0x7ff2efc9e400>\n",
            "[tensor(1.), tensor(1.)]\n",
            "tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SCrEYi_pB7y",
        "colab_type": "text"
      },
      "source": [
        "Instructor's work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvEDSk_y0W3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a database and put 100 values in it\n",
        "\n",
        "db, _ = create_db_and_parallels(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgdfcz-c0W3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a parallel database where remove entity at index 10\n",
        "\n",
        "pdb = get_parallel_db(db, remove_index=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POEBRW4T0W4G",
        "colab_type": "code",
        "outputId": "3582e179-f25a-4746-82b9-6277eacc30bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# differencing attack using addition (sum query)\n",
        "sum(db) - sum(pdb)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1, dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpfM7o6BqShP",
        "colab_type": "code",
        "outputId": "c38ab6ec-a1c3-4f66-e2ec-5001aa485078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# differencing attack using mean \n",
        "# if value is nonzero, indicates that missing value is a one.\n",
        "\n",
        "(sum(db).float()/len(db)) - (sum(pdb).float()/len(pdb))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0075)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRbFL5rjqjQ9",
        "colab_type": "code",
        "outputId": "56825fb2-b9af-4fab-d96b-388d595852e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# differencing attack using threshold\n",
        "\n",
        "(sum(db).float() > 49) - (sum(pdb).float() > 49)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0, dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6noC8ll_0W4Q",
        "colab_type": "text"
      },
      "source": [
        "# Project: Local Differential Privacy\n",
        "\n",
        "As you can see, the basic sum query is not differentially private at all! In truth, differential privacy always requires a form of randomness added to the query. Let me show you what I mean.\n",
        "\n",
        "### Randomized Response (Local Differential Privacy)\n",
        "\n",
        "Let's say I have a group of people I wish to survey about a very taboo behavior which I think they will lie about (say, I want to know if they have ever committed a certain kind of crime). I'm not a policeman, I'm just trying to collect statistics to understand the higher level trend in society. So, how do we do this? One technique is to add randomness to each person's response by giving each person the following instructions (assuming I'm asking a simple yes/no question):\n",
        "\n",
        "- Flip a coin 2 times.\n",
        "- If the first coin flip is heads, answer honestly\n",
        "- If the first coin flip is tails, answer according to the second coin flip (heads for yes, tails for no)!\n",
        "\n",
        "Thus, each person is now protected with \"plausible deniability\". If they answer \"Yes\" to the question \"have you committed X crime?\", then it might becasue they actually did, or it might be becasue they are answering according to a random coin flip. Each person has a high degree of protection. Furthermore, we can recover the underlying statistics with some accuracy, as the \"true statistics\" are simply averaged with a 50% probability. Thus, if we collect a bunch of samples and it turns out that 60% of people answer yes, then we know that the TRUE distribution is actually centered around 70%, because 70% averaged wtih 50% (a coin flip) is 60% which is the result we obtained. \n",
        "\n",
        "However, it should be noted that, especially when we only have a few samples, the this comes at the cost of accuracy. This tradeoff exists across all of Differential Privacy. The greater the privacy protection (plausible deniability) the less accurate the results. \n",
        "\n",
        "Let's implement this local DP for our database before!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b2mq-BtSxdL",
        "colab_type": "text"
      },
      "source": [
        "My work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7izgCUuo0W4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbgP62FrYrJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the query functions\n",
        "\n",
        "def query_mean(db):\n",
        "  return db.float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ru0AwFV0W44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# local differential privacy function\n",
        "\n",
        "def local_diff_privacy(num_entries, query):\n",
        "  \n",
        "  bias = 0.5\n",
        "  \n",
        "  # create the base database\n",
        "  db = torch.rand(num_entries) > 0.5\n",
        "  \n",
        "  # initialize a list for the locally private instance.\n",
        "  lpdb_l = list()\n",
        "  rdb0_l = list()\n",
        "  rdb1_l = list()\n",
        "  \n",
        "  # create a for loop that iterates through each entry in the database.\n",
        "  for i in range(len(db)):\n",
        "    \n",
        "    # Flip a coin two times. Let 0 represent tails and 1 represent heads. \n",
        "    c = torch.rand(2) > 0.5\n",
        "    \n",
        "    # If the first coin flip is heads, answer honestly.\n",
        "    # If the first coin flip is tails, answer according to the second coin flip (heads for yes, tails for no)\n",
        "    rdb0_l.append(c[0])\n",
        "    rdb1_l.append(c[1])\n",
        "    \n",
        "    if(c[0] == 1):\n",
        "      lpdb_l.append(db[i])\n",
        "    else:\n",
        "      if(c[1] == 0):\n",
        "        lpdb_l.append(0)\n",
        "      else:\n",
        "        lpdb_l.append(1)\n",
        "  \n",
        "  # convert locally private list to tensor\n",
        "  lpdb = torch.FloatTensor(lpdb_l)\n",
        "  rdb0 = torch.FloatTensor(rdb0_l)\n",
        "  rdb1 = torch.FloatTensor(rdb1_l)\n",
        "  \n",
        "  # initialize a list to hold the results\n",
        "  output = list()\n",
        "  \n",
        "  # calculate the query of the original database, append to output list\n",
        "  # don't have to put .float() here because it's part of the query function's definition.\n",
        "  db_out = query(db)\n",
        "  output.append(db_out)\n",
        "  \n",
        "  # calculate the query of the dataset, adjust for skew, append to output list\n",
        "  lpdb_out = query(lpdb) # augmented database\n",
        "  rdb0_out = query(rdb0) # weighting in favor of original database\n",
        "  rdb1_out = query(rdb1) # random noise (coin flip) database\n",
        "  \n",
        "  # (noise) * query(original result) + (1 - noise) * query(coin flip result) = query(augmented result)\n",
        "  # query(original result) = (1/noise) * (query(augmented result) - ((1-noise)*query(coin flip result)))\n",
        "  \n",
        "  norm_lpdb = (1 / bias) * (lpdb_out.float() - ((1 - bias) * rdb1_out.float()))\n",
        "  output.append(norm_lpdb.float())\n",
        "  \n",
        "  return rdb0_out, rdb1_out, output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsPTahui0W5C",
        "colab_type": "code",
        "outputId": "70519a17-0270-4eaa-a3a9-4ef0ccc87a1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "bias = 0.5\n",
        "bias0_mean, bias1_mean, output = local_diff_privacy(10, query_mean)\n",
        "\n",
        "print(\"Mean of coin flip 1: bias of \" + str(bias) + \" in favor of original database: \" + str(bias0_mean))\n",
        "print(\"Mean of coin flip 2: noise in place of database: \" + str(bias1_mean))\n",
        "print(\"Without Noise: \" + str(output[0]))\n",
        "print(\"With Noise: \" + str(output[1]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of coin flip 1: bias of 0.5 in favor of original database: tensor(0.5000)\n",
            "Mean of coin flip 2: noise in place of database: tensor(0.5000)\n",
            "Without Noise: tensor(0.6000)\n",
            "With Noise: tensor(1.1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmiqvHkP0W5J",
        "colab_type": "code",
        "outputId": "4a0b6271-2e10-4207-c170-07eaa34397c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "bias = 0.5\n",
        "bias0_mean, bias1_mean, output = local_diff_privacy(100, query_mean)\n",
        "\n",
        "print(\"Mean of coin flip 1: bias of \" + str(bias) + \" in favor of original database: \" + str(bias0_mean))\n",
        "print(\"Mean of coin flip 2: noise in place of database: \" + str(bias1_mean))\n",
        "print(\"Without Noise: \" + str(output[0]))\n",
        "print(\"With Noise: \" + str(output[1]))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of coin flip 1: bias of 0.5 in favor of original database: tensor(0.5000)\n",
            "Mean of coin flip 2: noise in place of database: tensor(0.5200)\n",
            "Without Noise: tensor(0.5400)\n",
            "With Noise: tensor(0.5600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WIZoEE80W5T",
        "colab_type": "code",
        "outputId": "675798d7-3039-4e51-ebc9-69dd1c7d6774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "bias = 0.5\n",
        "bias0_mean, bias1_mean, output = local_diff_privacy(1000, query_mean)\n",
        "\n",
        "print(\"Mean of coin flip 1: bias of \" + str(bias) + \" in favor of original database: \" + str(bias0_mean))\n",
        "print(\"Mean of coin flip 2: noise in place of database: \" + str(bias1_mean))\n",
        "print(\"Without Noise: \" + str(output[0]))\n",
        "print(\"With Noise: \" + str(output[1]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of coin flip 1: bias of 0.5 in favor of original database: tensor(0.4950)\n",
            "Mean of coin flip 2: noise in place of database: tensor(0.4880)\n",
            "Without Noise: tensor(0.4980)\n",
            "With Noise: tensor(0.4880)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvkIj2cq0W5c",
        "colab_type": "code",
        "outputId": "a75223e1-d50e-47c4-e034-474d235c7460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "bias = 0.5\n",
        "bias0_mean, bias1_mean, output = local_diff_privacy(10000, query_mean)\n",
        "\n",
        "print(\"Mean of coin flip 1: bias of \" + str(bias) + \" in favor of original database: \" + str(bias0_mean))\n",
        "print(\"Mean of coin flip 2: noise in place of database: \" + str(bias1_mean))\n",
        "print(\"Without Noise: \" + str(output[0]))\n",
        "print(\"With Noise: \" + str(output[1]))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of coin flip 1: bias of 0.5 in favor of original database: tensor(0.4982)\n",
            "Mean of coin flip 2: noise in place of database: tensor(0.5082)\n",
            "Without Noise: tensor(0.5013)\n",
            "With Noise: tensor(0.4990)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19zj37-GdXFL",
        "colab_type": "text"
      },
      "source": [
        "Instructor's work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQm0k1v-0W5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SspqL6Ui0W5t",
        "colab_type": "code",
        "outputId": "cb2769ca-6789-432d-857b-36d293f84028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "true_result = torch.mean(db.float())\n",
        "true_result"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3700)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apv6Z1UP0W50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db):\n",
        "  \n",
        "  true_result = torch.mean(db.float())\n",
        "  \n",
        "  first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "  second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "  \n",
        "  augmented_database = db.float() * first_coin_flip + (1 - first_coin_flip) * second_coin_flip\n",
        "  \n",
        "  # need to de-skew the result\n",
        "  db_result = torch.mean(augmented_database.float()) * 2 - 0.5\n",
        "  \n",
        "  return true_result, db_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbjT_4BJfJNY",
        "colab_type": "code",
        "outputId": "2c1fb184-2169-440d-a8cd-0fe5fc796ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "db, pdbs = create_db_and_parallels(10)\n",
        "true_result, private_result = query(db)\n",
        "print(\"Without Noise: \" + str(true_result))\n",
        "print(\"With Noise: \" + str(private_result))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Noise: tensor(0.3000)\n",
            "With Noise: tensor(0.5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsi1e1xTfXOX",
        "colab_type": "code",
        "outputId": "55a392a3-414d-4bb6-ff1c-a36cec0b0fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "db, pdbs = create_db_and_parallels(100)\n",
        "true_result, private_result = query(db)\n",
        "print(\"Without Noise: \" + str(true_result))\n",
        "print(\"With Noise: \" + str(private_result))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Noise: tensor(0.3100)\n",
            "With Noise: tensor(0.3200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCGsEJ6clApN",
        "colab_type": "code",
        "outputId": "e5e0c6f6-292d-4098-bbdd-ab960bbfe14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "db, pdbs = create_db_and_parallels(1000)\n",
        "true_result, private_result = query(db)\n",
        "print(\"Without Noise: \" + str(true_result))\n",
        "print(\"With Noise: \" + str(private_result))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Noise: tensor(0.2920)\n",
            "With Noise: tensor(0.2480)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZkJoorXlDCa",
        "colab_type": "code",
        "outputId": "1dff49d6-d747-4916-cf71-794889cd06f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "db, pdbs = create_db_and_parallels(10000)\n",
        "true_result, private_result = query(db)\n",
        "print(\"Without Noise: \" + str(true_result))\n",
        "print(\"With Noise: \" + str(private_result))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Noise: tensor(0.3107)\n",
            "With Noise: tensor(0.2980)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdQ373eR0W57",
        "colab_type": "text"
      },
      "source": [
        "# Project: Varying Amounts of Noise\n",
        "\n",
        "In this project, I want you to augment the randomized response query (the one we just wrote) to allow for varying amounts of randomness to be added. Specifically, I want you to bias the coin flip to be higher or lower and then run the same experiment. \n",
        "\n",
        "Note - this one is a bit tricker than you might expect. You need to both adjust the likelihood of the first coin flip AND the de-skewing at the end (where we create the \"augmented_result\" variable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKqkOfjcv10Z",
        "colab_type": "text"
      },
      "source": [
        "My work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKdN8NE30W5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHtW0Vph0W6E",
        "colab_type": "code",
        "outputId": "658cb72c-07a0-4721-82a8-655ce7eb33af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "db_test = torch.rand(10000) > 0.3\n",
        "db_test_mean = db_test.float().mean()\n",
        "db_test_mean"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6976)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdZSypTM0W6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# local differential privacy function with flexible bias\n",
        "\n",
        "def local_diff_privacy_bias(num_entries, query, bias):\n",
        "  \n",
        "  # create the base database\n",
        "  db = torch.rand(num_entries) > 0.5\n",
        "  \n",
        "  # initialize a list for the locally private instance.\n",
        "  augmented_db_list = list()\n",
        "  noise_factor_list = list() # bias toward orig db\n",
        "  noise_value_list = list() # noise\n",
        "  private_db_list = list()\n",
        "  \n",
        "  # create a for loop that iterates through each entry in the database.\n",
        "  for i in range(len(db)):\n",
        "    \n",
        "    # Flip a coin two times. Let 0 represent tails and 1 represent heads. \n",
        "    c0_noise_factor = (torch.rand(1) > (1 - bias)).float()\n",
        "    c1_noise_value = (torch.rand(1) > 0.5).float()\n",
        "    \n",
        "    # Populate noise factor (bias) and noise value (unbiased coin) databases\n",
        "    noise_factor_list.append(c0_noise_factor)\n",
        "    noise_value_list.append(c1_noise_value)\n",
        "    \n",
        "    # If the first coin flip is heads, answer honestly.\n",
        "    # If the first coin flip is tails, answer according to the second coin flip (heads for yes, tails for no)\n",
        "    if(c0_noise_factor == 1):\n",
        "      augmented_db_list.append(db[i])\n",
        "    else:\n",
        "      augmented_db_list.append(c1_noise_value)\n",
        "  \n",
        "  # convert locally private list to tensor\n",
        "  augmented_db = torch.FloatTensor(augmented_db_list)\n",
        "  noise_factor = torch.FloatTensor(noise_factor_list)\n",
        "  noise_value = torch.FloatTensor(noise_value_list)\n",
        "  \n",
        "  # test\n",
        "  # print(\"original database\")\n",
        "  # print(db)\n",
        "  # print(\"bias factor\")\n",
        "  # print(noise_factor)\n",
        "  # print(\"unbiased coin\")\n",
        "  # print(noise_value)\n",
        "  # print(\"augmented db\")\n",
        "  # print(augmented_db)\n",
        "  \n",
        "  \n",
        "  # calculate the query of the original database, append to output list\n",
        "  # don't have to put .float() here because it's part of the query function's definition.\n",
        "  db_query = query(db)\n",
        "  print(\"Query: original database: \" + str(db_query))\n",
        "  \n",
        "  # calculate the query of the dataset, adjust for skew, append to output list\n",
        "  augmented_db_query = query(augmented_db) # augmented database\n",
        "  noise_factor_query = query(noise_factor) # weighting in favor of original database\n",
        "  noise_value_query = query(noise_value) # random noise (coin flip) database\n",
        "  \n",
        "  print(\"Query: augmented database, unadjusted (skewed): \" + str(augmented_db_query))\n",
        "  print(\"Query: bias: \" + str(noise_factor_query))\n",
        "  print(\"Query: noise: \" + str(noise_value_query))\n",
        "  \n",
        "  # impute private database result from the augmented database result, noise bias, and noise values.\n",
        "  private_db_query = (1 / bias) * (augmented_db_query - (1 - bias)*(noise_value_query))\n",
        "  print(\"Query: augmented database, adjusted (unskewed): \" + str(private_db_query))\n",
        "  \n",
        "  # validation\n",
        "  wtd_private_db = noise_factor_query.float() * private_db_query.float()\n",
        "  wtd_noise = (1 - noise_factor_query.float()) * noise_value_query.float()\n",
        "  \n",
        "  print(\"(bias) * (unskewed db) + (1 - bias) * (noise) = (skewed db)\")\n",
        "  print(\"skewed result = \" + str(wtd_private_db + wtd_noise))\n",
        "  \n",
        "  return db_query, augmented_db_query, noise_factor_query, noise_value_query, private_db_query"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_y-vXgwHe3Z",
        "colab_type": "code",
        "outputId": "15591648-5479-45ab-b25b-037bc23a0c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "bias = 0.5\n",
        "db_query, augmented_db_query, noise_factor_query, noise_value_query, private_db_query = local_diff_privacy_bias(1000, query_mean, bias)\n",
        "\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: original database: tensor(0.4970)\n",
            "Query: augmented database, unadjusted (skewed): tensor(0.5040)\n",
            "Query: bias: tensor(0.5100)\n",
            "Query: noise: tensor(0.5040)\n",
            "Query: augmented database, adjusted (unskewed): tensor(0.5040)\n",
            "(bias) * (unskewed db) + (1 - bias) * (noise) = (skewed db)\n",
            "skewed result = tensor(0.5040)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43x1qJ8m0W6V",
        "colab_type": "code",
        "outputId": "727d3d65-2318-4b73-8a0a-a60e3e267cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "bias = 0.1\n",
        "db_query, augmented_db_query, noise_factor_query, noise_value_query, private_db_query = local_diff_privacy_bias(1000, query_mean, bias)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: original database: tensor(0.5110)\n",
            "Query: augmented database, unadjusted (skewed): tensor(0.5030)\n",
            "Query: bias: tensor(0.0920)\n",
            "Query: noise: tensor(0.4980)\n",
            "Query: augmented database, adjusted (unskewed): tensor(0.5480)\n",
            "(bias) * (unskewed db) + (1 - bias) * (noise) = (skewed db)\n",
            "skewed result = tensor(0.5026)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9jKmW2h0W6x",
        "colab_type": "code",
        "outputId": "b8183e3a-6b78-4d45-d15a-02981700f84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "bias = 0.5\n",
        "db_query, augmented_db_query, noise_factor_query, noise_value_query, private_db_query = local_diff_privacy_bias(1000, query_mean, bias)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: original database: tensor(0.5110)\n",
            "Query: augmented database, unadjusted (skewed): tensor(0.5130)\n",
            "Query: bias: tensor(0.5080)\n",
            "Query: noise: tensor(0.4970)\n",
            "Query: augmented database, adjusted (unskewed): tensor(0.5290)\n",
            "(bias) * (unskewed db) + (1 - bias) * (noise) = (skewed db)\n",
            "skewed result = tensor(0.5133)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7tB3pTp0W6-",
        "colab_type": "code",
        "outputId": "c3b09f43-3986-4a68-8c0c-f7878aff7d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "bias = 0.9\n",
        "db_query, augmented_db_query, noise_factor_query, noise_value_query, private_db_query = local_diff_privacy_bias(1000, query_mean, bias)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query: original database: tensor(0.4820)\n",
            "Query: augmented database, unadjusted (skewed): tensor(0.4730)\n",
            "Query: bias: tensor(0.9150)\n",
            "Query: noise: tensor(0.4830)\n",
            "Query: augmented database, adjusted (unskewed): tensor(0.4719)\n",
            "(bias) * (unskewed db) + (1 - bias) * (noise) = (skewed db)\n",
            "skewed result = tensor(0.4728)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJUwdxaKyKa1",
        "colab_type": "text"
      },
      "source": [
        "Instructor's work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAftzkFl0W7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def query(db, noise):\n",
        "  \n",
        "  true_result = torch.mean(db.float())\n",
        "  \n",
        "  first_coin_flip = (torch.rand(len(db)) > noise).float()\n",
        "  second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
        "  \n",
        "  augmented_database = db.float() * first_coin_flip + (1 - first_coin_flip) * second_coin_flip\n",
        "  \n",
        "  # skewed result\n",
        "  sk_result = augmented_database.float().mean()\n",
        "  \n",
        "  private_result = ((sk_result / noise) - 0.5) * noise / (1-noise)\n",
        "  \n",
        "  # need to de-skew the result\n",
        "  # db_result = torch.mean(augmented_database.float()) * 2 - 0.5\n",
        "  \n",
        "  return private_result, true_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzCqEJ7R0W7w",
        "colab_type": "code",
        "outputId": "779e2db5-927a-4a26-b96e-613f7b1d3701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "noise = 0.1\n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "private_result, true_result = query(db, noise)\n",
        "print(\"With Noise: \" + str(private_result))\n",
        "print(\"Without Noise: \" + str(true_result))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise: tensor(0.3667)\n",
            "Without Noise: tensor(0.3800)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxDxe7JY0W8A",
        "colab_type": "code",
        "outputId": "4d8cb5b6-4d30-447f-e036-dae049c7b7d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "noise = 0.2\n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "private_result, true_result = query(db, noise)\n",
        "print(\"With Noise: \" + str(private_result))\n",
        "print(\"Without Noise: \" + str(true_result))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise: tensor(0.4000)\n",
            "Without Noise: tensor(0.3500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dElJuSK0W8K",
        "colab_type": "code",
        "outputId": "bdaab0ed-1227-47fa-c31e-e542a1376f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "noise = 0.4\n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "private_result, true_result = query(db, noise)\n",
        "print(\"With Noise: \" + str(private_result))\n",
        "print(\"Without Noise: \" + str(true_result))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise: tensor(0.3667)\n",
            "Without Noise: tensor(0.3700)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvVpbQB5Rwxg",
        "colab_type": "code",
        "outputId": "d837af29-59c0-48b2-d64f-30e281734dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "noise = 0.8\n",
        "db, pdbs = create_db_and_parallels(100)\n",
        "private_result, true_result = query(db, noise)\n",
        "print(\"With Noise: \" + str(private_result))\n",
        "print(\"Without Noise: \" + str(true_result))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise: tensor(0.3500)\n",
            "Without Noise: tensor(0.3600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anuCRQfORzX6",
        "colab_type": "code",
        "outputId": "0c3deb88-feca-47c2-eb99-33bf8b084be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# convergence when increase size of dataset\n",
        "# thus, the larger the dataset, the more privacy you can add.\n",
        "noise = 0.1\n",
        "db, pdbs = create_db_and_parallels(10000)\n",
        "private_result, true_result = query(db, noise)\n",
        "print(\"With Noise: \" + str(private_result))\n",
        "print(\"Without Noise: \" + str(true_result))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Noise: tensor(0.3108)\n",
            "Without Noise: tensor(0.3103)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20dQeWpq0W8l",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: The Formal Definition of Differential Privacy\n",
        "\n",
        "The previous method of adding noise was called \"Local Differentail Privacy\" because we added noise to each datapoint individually. This is necessary for some situations wherein the data is SO sensitive that individuals do not trust noise to be added later. However, it comes at a very high cost in terms of accuracy. \n",
        "\n",
        "However, alternatively we can add noise AFTER data has been aggregated by a function. This kind of noise can allow for similar levels of protection with a lower affect on accuracy. However, participants must be able to trust that no-one looked at their datapoints _before_ the aggregation took place. In some situations this works out well, in others (such as an individual hand-surveying a group of people), this is less realistic.\n",
        "\n",
        "Nevertheless, global differential privacy is incredibly important because it allows us to perform differential privacy on smaller groups of individuals with lower amounts of noise. Let's revisit our sum functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YTIISU40W8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# db, pdbs = create_db_and_parallels(100)\n",
        "\n",
        "# def query(db):\n",
        "#     return torch.sum(db.float())\n",
        "\n",
        "# def M(db):\n",
        "#    query(db) + noise\n",
        "\n",
        "# query(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3vozRGL0W8y",
        "colab_type": "text"
      },
      "source": [
        "So the idea here is that we want to add noise to the output of our function. We actually have two different kinds of noise we can add - Laplacian Noise or Gaussian Noise. However, before we do so at this point we need to dive into the formal definition of Differential Privacy.\n",
        "\n",
        "![alt text](dp_formula.png \"Title\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3azsdR1P0W81",
        "colab_type": "text"
      },
      "source": [
        "_Image From: \"The Algorithmic Foundations of Differential Privacy\" - Cynthia Dwork and Aaron Roth - https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3vT3Lf30W83",
        "colab_type": "text"
      },
      "source": [
        "This definition does not _create_ differential privacy, instead it is a measure of how much privacy is afforded by a query M. Specifically, it's a comparison between running the query M on a database (x) and a parallel database (y). As you remember, parallel databases are defined to be the same as a full database (x) with one entry/person removed.\n",
        "\n",
        "Thus, this definition says that FOR ALL parallel databases, the maximum distance between a query on database (x) and the same query on database (y) will be e^epsilon, but that occasionally this constraint won't hold with probability delta. Thus, this theorem is called \"epsilon delta\" differential privacy.\n",
        "\n",
        "# Epsilon\n",
        "\n",
        "Let's unpack the intuition of this for a moment. \n",
        "\n",
        "Epsilon Zero: If a query satisfied this inequality where epsilon was set to 0, then that would mean that the query for all parallel databases outputed the exact same value as the full database. As you may remember, when we calculated the \"threshold\" function, often the Sensitivity was 0. In that case, the epsilon also happened to be zero.\n",
        "\n",
        "Epsilon One: If a query satisfied this inequality with epsilon 1, then the maximum distance between all queries would be 1 - or more precisely - the maximum distance between the two random distributions M(x) and M(y) is 1 (because all these queries have some amount of randomness in them, just like we observed in the last section).\n",
        "\n",
        "# Delta\n",
        "\n",
        "Delta is basically the probability that epsilon breaks. Namely, sometimes the epsilon is different for some queries than it is for others. For example, you may remember when we were calculating the sensitivity of threshold, most of the time sensitivity was 0 but sometimes it was 1. Thus, we could calculate this as \"epsilon zero but non-zero delta\" which would say that epsilon is perfect except for some probability of the time when it's arbitrarily higher. Note that this expression doesn't represent the full tradeoff between epsilon and delta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmBp-Wfi0W84",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: How To Add Noise for Global Differential Privacy\n",
        "\n",
        "In this lesson, we're going to learn about how to take a query and add varying amounts of noise so that it satisfies a certain degree of differential privacy. In particular, we're going to leave behind the Local Differential privacy previously discussed and instead opt to focus on Global differential privacy. \n",
        "\n",
        "So, to sum up, this lesson is about adding noise to the output of our query so that it satisfies a certain epsilon-delta differential privacy threshold.\n",
        "\n",
        "There are two kinds of noise we can add - Gaussian Noise or Laplacian Noise. Generally speaking Laplacian is better, but both are still valid. Now to the hard question...\n",
        "\n",
        "### How much noise should we add?\n",
        "\n",
        "The amount of noise necessary to add to the output of a query is a function of four things:\n",
        "\n",
        "- the type of noise (Gaussian/Laplacian)\n",
        "- the sensitivity of the query/function\n",
        "- the desired epsilon ()\n",
        "- the desired delta ()\n",
        "\n",
        "Thus, for each type of noise we're adding, we have different way of calculating how much to add as a function of sensitivity, epsilon, and delta. We're going to focus on Laplacian noise. Laplacian noise is increased/decreased according to a \"scale\" parameter b. We choose \"b\" based on the following formula.\n",
        "\n",
        "b = sensitivity(query) / epsilon\n",
        "\n",
        "In other words, if we set b to be this value, then we know that we will have a privacy leakage of <= epsilon. Furthermore, the nice thing about Laplace is that it guarantees this with delta == 0. There are some tunings where we can have very low epsilon where delta is non-zero, but we'll ignore them for now.\n",
        "\n",
        "### Querying Repeatedly\n",
        "\n",
        "- if we query the database multiple times - we can simply add the epsilons (Even if we change the amount of noise and their epsilons are not the same)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0_XrQs8qcdj",
        "colab_type": "text"
      },
      "source": [
        "My work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRddyzkq0W86",
        "colab_type": "code",
        "outputId": "2c4e80af-3329-47c0-8a24-b3f49b8e8efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# set a number of entries\n",
        "n = 10000\n",
        "\n",
        "# define epsilon, bounded between 0 and 1\n",
        "e = 0.5\n",
        "\n",
        "# create the base database\n",
        "db = torch.rand(n) > 0.5\n",
        "\n",
        "# define the query functions\n",
        "def query_sum(db):\n",
        "  return db.sum()\n",
        "\n",
        "def query_mean(db):\n",
        "  return db.float().mean()\n",
        "\n",
        "# define sensitivities\n",
        "s_sum = 1\n",
        "print(s_sum)\n",
        "\n",
        "s_mean = ((1 + 0) / 2) / n\n",
        "print(s_mean)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "5e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPXFP8-E2FLs",
        "colab_type": "code",
        "outputId": "db91a205-675f-46fe-cf3d-705424244464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# define scale parameter beta for each query method:\n",
        "b_sum = s_sum / e\n",
        "b_mean = s_mean / e\n",
        "\n",
        "print(b_sum)\n",
        "print(b_mean)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n",
            "0.0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVXgj9pk428_",
        "colab_type": "code",
        "outputId": "61cfa90c-61a2-453a-a0da-16669790f888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# https://discuss.pytorch.org/t/gpytorch-runtimeerror-expected-backend-cpu-and-dtype-double-but-got-backend-cpu-and-dtype-float/44309/2\n",
        "\n",
        "lpl = np.random.laplace(0, 1, n)\n",
        "noise = torch.tensor(lpl * b_sum)\n",
        "print(noise)\n",
        "print(noise.shape)\n",
        "print(db.shape)\n",
        "print(noise.double() + db.double())"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.7420,  3.0316,  0.8927,  ..., -0.9474,  4.7084, -1.8309],\n",
            "       dtype=torch.float64)\n",
            "torch.Size([10000])\n",
            "torch.Size([10000])\n",
            "tensor([-1.7420,  4.0316,  1.8927,  ..., -0.9474,  4.7084, -0.8309],\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l7TY1SY3VPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def M(query, e, s):\n",
        "  # create the base database\n",
        "  db = torch.rand(n) > 0.5\n",
        "  \n",
        "  # calculate the noise, using beta as the spread paramater on the Laplacian distribution\n",
        "  b = s / e\n",
        "  lpl = np.random.laplace(0, b, 1)\n",
        "  noise = torch.tensor(lpl)\n",
        "  \n",
        "  # calculate the original result of the query\n",
        "  q = query(db)\n",
        "  \n",
        "  # calulate the noise-enhanced result of the query\n",
        "  m = query(db) + noise\n",
        "  \n",
        "  return q, m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_jAotQz6VvI",
        "colab_type": "code",
        "outputId": "fc720f0f-9978-48bb-e6b2-238c2a06c1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "q_sum, m_sum = M(query_sum, e=0.5, s=1)\n",
        "print(q_sum)\n",
        "print(m_sum)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5014)\n",
            "tensor([5012.7787], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM_jNtUp-1_G",
        "colab_type": "code",
        "outputId": "239a7ace-68c4-48d7-e0e1-8bac5f8af974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "s_mean = ((1 + 0) / 2) / n\n",
        "q_mean, m_mean = M(query_mean, e=0.5, s=s_mean)\n",
        "print(q_mean)\n",
        "print(m_mean)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.4963)\n",
            "tensor([0.4962], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5sqkZ1OoVL7",
        "colab_type": "text"
      },
      "source": [
        "Instructor's work in next section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOuacS94oX-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhTSI5pB0W9A",
        "colab_type": "text"
      },
      "source": [
        "# Project: Create a Differentially Private Query\n",
        "\n",
        "In this project, I want you to take what you learned in the previous lesson and create a query function which sums over the database and adds just the right amount of noise such that it satisfies an epsilon constraint. Write a query for both \"sum\" and for \"mean\". Ensure that you use the correct sensitivity measures for both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAhZQqBF0W9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try this project here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjreUCdJo6rP",
        "colab_type": "text"
      },
      "source": [
        "Instructor's work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6968xZOn0W9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb5hWgAb0W9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pLy4IgS0W9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db, pdbs = create_db_and_parallels(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge_UJDti0W9i",
        "colab_type": "code",
        "outputId": "57ffa299-d2b3-4c89-a30f-a4f9b34a6b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "db"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
              "        0, 0, 0, 0], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT213R_G0W9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sum_query(db):\n",
        "  return db.sum()\n",
        "\n",
        "def mean_query(db):\n",
        "  return torch.mean(db.float())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub7xjHYa0W9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def laplacian_mechanism(db, query, sensitivity):\n",
        "  beta = sensitivity / epsilon\n",
        "  noise = torch.tensor(np.random.laplace(0, beta, 1))\n",
        "  return query(db) + noise\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKZXqFNO0W9z",
        "colab_type": "code",
        "outputId": "b731ef92-dc68-4566-f351-df260fb740a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "laplacian_mechanism(db, sum_query, 1)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([23.6449], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itUPTguH0W93",
        "colab_type": "code",
        "outputId": "c69c34d7-7133-4790-b763-735d2743affb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum_query(db)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb6jdDkguyPN",
        "colab_type": "code",
        "outputId": "4f2719e3-918e-4b48-930d-b8f5ccf1cbfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "laplacian_mechanism(db, mean_query, 1/100)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2101], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEkOLUCwu3Uh",
        "colab_type": "code",
        "outputId": "151feffd-8acd-4abc-dc7e-645e9a5e8106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean_query(db)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM3KVtf20W9_",
        "colab_type": "text"
      },
      "source": [
        "# Lesson: Differential Privacy for Deep Learning\n",
        "\n",
        "So in the last lessons you may have been wondering - what does all of this have to do with Deep Learning? Well, these same techniques we were just studying form the core primitives for how Differential Privacy provides guarantees in the context of Deep Learning. \n",
        "\n",
        "Previously, we defined perfect privacy as \"a query to a database returns the same value even if we remove any person from the database\", and used this intuition in the description of epsilon/delta. In the context of deep learning we have a similar standard.\n",
        "\n",
        "Training a model on a dataset should return the same model even if we remove any person from the dataset.\n",
        "\n",
        "Thus, we've replaced \"querying a database\" with \"training a model on a dataset\". In essence, the training process is a kind of query. However, one should note that this adds two points of complexity which database queries did not have:\n",
        "\n",
        "    1. do we always know where \"people\" are referenced in the dataset?\n",
        "    2. neural models rarely never train to the same output model, even on identical data\n",
        "\n",
        "The answer to (1) is to treat each training example as a single, separate person. Strictly speaking, this is often overly zealous as some training examples have no relevance to people and others may have multiple/partial (consider an image with multiple people contained within it). Thus, localizing exactly where \"people\" are referenced, and thus how much your model would change if people were removed, is challenging.\n",
        "\n",
        "The answer to (2) is also an open problem - but several interesitng proposals have been made. We're going to focus on one of the most popular proposals, PATE.\n",
        "\n",
        "## An Example Scenario: A Health Neural Network\n",
        "\n",
        "First we're going to consider a scenario - you work for a hospital and you have a large collection of images about your patients. However, you don't know what's in them. You would like to use these images to develop a neural network which can automatically classify them, however since your images aren't labeled, they aren't sufficient to train a classifier. \n",
        "\n",
        "However, being a cunning strategist, you realize that you can reach out to 10 partner hospitals which DO have annotated data. It is your hope to train your new classifier on their datasets so that you can automatically label your own. While these hospitals are interested in helping, they have privacy concerns regarding information about their patients. Thus, you will use the following technique to train a classifier which protects the privacy of patients in the other hospitals.\n",
        "\n",
        "- 1) You'll ask each of the 10 hospitals to train a model on their own datasets (All of which have the same kinds of labels)\n",
        "- 2) You'll then use each of the 10 partner models to predict on your local dataset, generating 10 labels for each of your datapoints\n",
        "- 3) Then, for each local data point (now with 10 labels), you will perform a DP query to generate the final true label. This query is a \"max\" function, where \"max\" is the most frequent label across the 10 labels. We will need to add laplacian noise to make this Differentially Private to a certain epsilon/delta constraint.\n",
        "- 4) Finally, we will retrain a new model on our local dataset which now has labels. This will be our final \"DP\" model.\n",
        "\n",
        "So, let's walk through these steps. I will assume you're already familiar with how to train/predict a deep neural network, so we'll skip steps 1 and 2 and work with example data. We'll focus instead on step 3, namely how to perform the DP query for each example using toy data.\n",
        "\n",
        "So, let's say we have 10,000 training examples, and we've got 10 labels for each example (from our 10 \"teacher models\" which were trained directly on private data). Each label is chosen from a set of 10 possible labels (categories) for each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCsUPx4N0W-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yd7hurJ0W-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_teachers = 10 # we're working with 10 partner hospitals\n",
        "num_examples = 10000 # the size of OUR dataset\n",
        "num_labels = 10 # number of lablels for our classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FOUJE070W-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = (np.random.rand(num_teachers, num_examples) * num_labels).astype(int).transpose(1,0) # fake predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hnCeYRM0W-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_labels = list()\n",
        "for an_image in preds:\n",
        "\n",
        "    label_counts = np.bincount(an_image, minlength=num_labels)\n",
        "\n",
        "    epsilon = 0.1\n",
        "    beta = 1 / epsilon\n",
        "\n",
        "    for i in range(len(label_counts)):\n",
        "        label_counts[i] += np.random.laplace(0, beta, 1)\n",
        "\n",
        "    new_label = np.argmax(label_counts)\n",
        "    \n",
        "    new_labels.append(new_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt3ae5Vc0W-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbwOj6K_0W-v",
        "colab_type": "text"
      },
      "source": [
        "# PATE Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiC5LMSy0W-w",
        "colab_type": "code",
        "outputId": "627ce43e-78a4-48a1-ba06-a6a49a5f8c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels = np.array([9, 9, 3, 6, 9, 9, 9, 9, 8, 2])\n",
        "counts = np.bincount(labels, minlength=10)\n",
        "query_result = np.argmax(counts)\n",
        "query_result"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsf9dECr0W-3",
        "colab_type": "code",
        "outputId": "45a4904a-f1d9-4567-d2f2-d94af0997073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from syft.frameworks.torch.differential_privacy import pate"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0704 22:37:17.986018 140683261495168 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0704 22:37:18.000128 140683261495168 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln96irF-0W_A",
        "colab_type": "code",
        "outputId": "3020b2ef-bfde-4dc0-d006-249d4f69a1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_teachers, num_examples, num_labels = (100, 100, 10)\n",
        "preds = (np.random.rand(num_teachers, num_examples) * num_labels).astype(int) #fake preds\n",
        "indices = (np.random.rand(num_examples) * num_labels).astype(int) # true answers\n",
        "\n",
        "preds[:,0:10] *= 0\n",
        "\n",
        "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5)\n",
        "\n",
        "assert data_dep_eps < data_ind_eps\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: May not have used enough values of l. Increase 'moments' variable and run again.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiJQZP-J0W_L",
        "colab_type": "code",
        "outputId": "f72d2694-66f3-4052-f30c-7705e0a40029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5)\n",
        "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
        "print(\"Data Dependent Epsilon:\", data_dep_eps)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: May not have used enough values of l. Increase 'moments' variable and run again.\n",
            "Data Independent Epsilon: 11.756462732485115\n",
            "Data Dependent Epsilon: 1.52655213289881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzxddNaf0W_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds[:,0:50] *= 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZWPrS6s0W_a",
        "colab_type": "code",
        "outputId": "c5e8ecbe-2a06-4d0f-f028-b99cf2a8e23a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5, moments=20)\n",
        "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
        "print(\"Data Dependent Epsilon:\", data_dep_eps)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Independent Epsilon: 11.756462732485115\n",
            "Data Dependent Epsilon: 0.9029013677789843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN5MX-Ab0W_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hyaZCoM0W_q",
        "colab_type": "text"
      },
      "source": [
        "# Where to Go From Here\n",
        "\n",
        "\n",
        "Read:\n",
        "    - Algorithmic Foundations of Differential Privacy: https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf\n",
        "    - Deep Learning with Differential Privacy: https://arxiv.org/pdf/1607.00133.pdf\n",
        "    - The Ethical Algorithm: https://www.amazon.com/Ethical-Algorithm-Science-Socially-Design/dp/0190948205\n",
        "   \n",
        "Topics:\n",
        "    - The Exponential Mechanism\n",
        "    - The Moment's Accountant\n",
        "    - Differentially Private Stochastic Gradient Descent\n",
        "\n",
        "Advice:\n",
        "    - For deployments - stick with public frameworks!\n",
        "    - Join the Differential Privacy Community\n",
        "    - Don't get ahead of yourself - DP is still in the early days"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQZMeTaO0W_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu4jnJGS0W_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6dabM3U0W_1",
        "colab_type": "text"
      },
      "source": [
        "# Section Project:\n",
        "\n",
        "For the final project for this section, you're going to train a DP model using this PATE method on the MNIST dataset, provided below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "822qKcqx0W_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.datasets as datasets\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8U06kkO0XAB",
        "colab_type": "code",
        "outputId": "614cdbd7-bc9a-46cb-cca0-a6edbaa8d133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_data = mnist_trainset.train_data\n",
        "train_targets = mnist_trainset.train_labels"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-labZcH0XAJ",
        "colab_type": "code",
        "outputId": "9dca1019-8b57-4ed0-ea09-36f39b533a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test_data = mnist_trainset.test_data\n",
        "test_targets = mnist_trainset.test_labels"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0yrFEpOwHVk",
        "colab_type": "text"
      },
      "source": [
        "My work. \n",
        "\n",
        "Assumptions:\n",
        "*   train_data = private databases that must be kept differentially private.\n",
        "*   test_data = public dataset that does not need to be kept differentially private.\n",
        "\n",
        "Process:\n",
        "* split train_data into partitions.\n",
        "* train feature models on those partitions.\n",
        "* use those results to annotate test_data for the purpose of training a model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynGtPAGU8i5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install PyTorch dependencies\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define helper functions\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZQeoOMZ0XAW",
        "colab_type": "code",
        "outputId": "5e5d3c10-f380-4b43-9fd9-1cbf44d665a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Get info on the properties of training (private) and testing (public) datasets\n",
        "\n",
        "print(\"train_data shape: \", train_data.shape)\n",
        "print(\"train_targets shape: \", train_targets.shape)\n",
        "print(\"test_data shape: \", test_data.shape)\n",
        "print(\"test_targets shape: \", test_targets.shape)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data shape:  torch.Size([60000, 28, 28])\n",
            "train_targets shape:  torch.Size([60000])\n",
            "test_data shape:  torch.Size([60000, 28, 28])\n",
            "test_targets shape:  torch.Size([60000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2kQU0gO6FYj",
        "colab_type": "code",
        "outputId": "6a25a999-793a-442f-8021-07b8ab1bdf49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "\n",
        "\n",
        "mnist_trainset = torchvision.datasets.MNIST('/data/mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the testing data\n",
        "mnist_testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=10000, shuffle=False)\n",
        "\n",
        "# Metrics for tensor properties\n",
        "train_data = mnist_trainset.train_data\n",
        "train_targets = mnist_trainset.train_labels\n",
        "test_data = mnist_testset.test_data\n",
        "test_targets = mnist_testset.test_labels\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3y6LjXS_CMa",
        "colab_type": "code",
        "outputId": "5a0bbb48-4e27-41ca-af60-f298dabc4c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Return properties of the trainloader and test loader\n",
        "\n",
        "print(\"train loader: \", trainloader.dataset.data.shape)\n",
        "print(\"test loader: \", testloader.dataset.data.shape)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loader:  torch.Size([60000, 28, 28])\n",
            "test loader:  torch.Size([10000, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3z7Ukt8RNG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Partition the trainloader to mimic six private datasets\n",
        "\n",
        "split0_size = ((5/6) * len(mnist_trainset))\n",
        "priv0_size = len(mnist_trainset) - split0_size\n",
        "\n",
        "split0_dataset, priv0_dataset = torch.utils.data.random_split(mnist_trainset, [int(split0_size), int(priv0_size)])\n",
        "\n",
        "split1_size = (4/5) * len(split0_dataset)\n",
        "priv1_size = len(split0_dataset) - split1_size\n",
        "\n",
        "split1_dataset, priv1_dataset = torch.utils.data.random_split(split0_dataset, [int(split1_size), int(priv1_size)])\n",
        "\n",
        "split2_size = (3/4) * len(split1_dataset)\n",
        "priv2_size = len(split1_dataset) - split2_size\n",
        "\n",
        "split2_dataset, priv2_dataset = torch.utils.data.random_split(split1_dataset, [int(split2_size), int(priv2_size)])\n",
        "\n",
        "split3_size = (2/3) * len(split2_dataset)\n",
        "priv3_size = len(split2_dataset) - split3_size\n",
        "\n",
        "split3_dataset, priv3_dataset = torch.utils.data.random_split(split2_dataset, [int(split3_size), int(priv3_size)])\n",
        "\n",
        "split4_size = (1/2) * len(split3_dataset)\n",
        "priv4_size = len(split3_dataset) - split4_size\n",
        "\n",
        "priv4_dataset, priv5_dataset = torch.utils.data.random_split(split3_dataset, [int(split4_size), int(priv4_size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-awikxrxbQcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split each private dataset into a training set and a testing set\n",
        "ptrain_size = 0.9 * len(priv0_dataset)\n",
        "ptest_size = len(priv0_dataset) - ptrain_size\n",
        "\n",
        "priv0_train, priv0_test = torch.utils.data.random_split(priv0_dataset, [int(ptrain_size), int(ptest_size)])\n",
        "priv1_train, priv1_test = torch.utils.data.random_split(priv1_dataset, [int(ptrain_size), int(ptest_size)])\n",
        "priv2_train, priv2_test = torch.utils.data.random_split(priv2_dataset, [int(ptrain_size), int(ptest_size)])\n",
        "priv3_train, priv3_test = torch.utils.data.random_split(priv3_dataset, [int(ptrain_size), int(ptest_size)])\n",
        "priv4_train, priv4_test = torch.utils.data.random_split(priv4_dataset, [int(ptrain_size), int(ptest_size)])\n",
        "priv5_train, priv5_test = torch.utils.data.random_split(priv5_dataset, [int(ptrain_size), int(ptest_size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbokfaNJUPOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c22ca2da-e8be-4594-8344-09f2a1cbaf95"
      },
      "source": [
        "# Generate loaders for each of the datasets\n",
        "batch = 64\n",
        "\n",
        "p0_trainloader = torch.utils.data.DataLoader(priv0_train, batch_size=batch, shuffle=True)\n",
        "p0_testloader = torch.utils.data.DataLoader(priv0_test, batch_size=batch, shuffle=True)\n",
        "\n",
        "p1_trainloader = torch.utils.data.DataLoader(priv1_train, batch_size=batch, shuffle=True)\n",
        "p1_testloader = torch.utils.data.DataLoader(priv1_test, batch_size=batch, shuffle=True)\n",
        "\n",
        "p2_trainloader = torch.utils.data.DataLoader(priv2_train, batch_size=batch, shuffle=True)\n",
        "p2_testloader = torch.utils.data.DataLoader(priv2_test, batch_size=batch, shuffle=True)\n",
        "\n",
        "p3_trainloader = torch.utils.data.DataLoader(priv3_train, batch_size=batch, shuffle=True)\n",
        "p3_testloader = torch.utils.data.DataLoader(priv3_test, batch_size=batch, shuffle=True)\n",
        "\n",
        "p4_trainloader = torch.utils.data.DataLoader(priv4_train, batch_size=batch, shuffle=True)\n",
        "p4_testloader = torch.utils.data.DataLoader(priv4_test, batch_size=batch, shuffle=True)\n",
        "\n",
        "p5_trainloader = torch.utils.data.DataLoader(priv5_train, batch_size=batch, shuffle=True)\n",
        "p5_testloader = torch.utils.data.DataLoader(priv5_test, batch_size=batch, shuffle=True)\n",
        "\n",
        "print(\"Private Loader 0: \", p0_trainloader)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Private Loader 0:  <torch.utils.data.dataloader.DataLoader object at 0x7ff2c6926f28>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzUr4VKNzMWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the classification model to be used on each of the private loaders.\n",
        "# Theoretically could be six different models. Training the same model on each dataset here for expediency.\n",
        "# See Prior work. Exercise Part 5 of CNNs.\n",
        "\n",
        "## TODO: Define your model with dropout added\n",
        "\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "        # add dropout module with 0.2 drop probability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        # update to include dropout\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        \n",
        "        # no dropout on output layer\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyjehnlUKX-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to train the model on each of the data loaders for a specified number of epochs, number of steps, and optimizer learning rate.\n",
        "\n",
        "def TrainModel(trainloader, testloader, lr, epochs, steps):\n",
        "  \n",
        "  model = Classifier()\n",
        "  criterion = nn.NLLLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "  epochs = 30\n",
        "  steps = 0\n",
        "  \n",
        "  train_losses, test_losses, test_accuracy = [], [], []\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in trainloader:\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          log_ps = model(images)\n",
        "          loss = criterion(log_ps, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "\n",
        "      else:\n",
        "          ## TODO: Implement the validation pass and print out the validation accuracy\n",
        "          # turn off gradients\n",
        "          test_loss = 0\n",
        "          accuracy = 0\n",
        "\n",
        "          # turn off gradients\n",
        "          with torch.no_grad():\n",
        "\n",
        "            # set model to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # run validation pass\n",
        "            for images, labels in testloader:\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              log_ps = model(images)\n",
        "              test_loss = test_loss + criterion(log_ps, labels)\n",
        "\n",
        "              # Get the class probabilities\n",
        "              ps = torch.exp(log_ps)\n",
        "\n",
        "              # Use top-k to identify most likely classes\n",
        "              top_p, top_class = ps.topk(1, dim=1)\n",
        "\n",
        "              # compare to true labels\n",
        "              equals = top_class == labels.view(*top_class.shape)\n",
        "              accuracy = accuracy + torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "          # set model back to training mode\n",
        "          model.train()\n",
        "\n",
        "          train_losses.append(running_loss/len(trainloader))\n",
        "          test_losses.append(test_loss/len(testloader))\n",
        "          test_accuracy.append(accuracy/len(testloader))\n",
        "\n",
        "          # print(f'Accuracy: {accuracy.item()*100}%')\n",
        "\n",
        "          #print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "          #  \"Training loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "          #  \"Testing loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "          #  \"Test Accuracy: {:.3f}.. \".format(accuracy/len(testloader))\n",
        "          #  )\n",
        "  \n",
        "  plt.plot(train_losses, label='Training Loss')\n",
        "  plt.plot(test_losses, label='Validation Loss')\n",
        "  plt.plot(test_accuracy, label='Test Accuracy')\n",
        "  plt.legend(frameon=False)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJyF0HdT39k2",
        "colab_type": "code",
        "outputId": "3fffea3d-9857-4ba1-af07-6ce34c080e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model_0 = TrainModel(trainloader=p0_trainloader, testloader=p0_testloader, lr=0.003, epochs=30, steps=0)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU4UrxVcNDCZ",
        "colab_type": "code",
        "outputId": "67040462-adb7-4e75-982e-e3a2045124c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model_1 = TrainModel(trainloader=p1_trainloader, testloader=p1_testloader, lr=0.003, epochs=30, steps=0)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3AGG5A4wJHeAIbkDDAUEUsve/yIneAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfbVdAkzCs8B",
        "colab_type": "code",
        "outputId": "a5727afb-6006-4773-bd06-82943a960829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model_2 = TrainModel(trainloader=p2_trainloader, testloader=p2_testloader, lr=0.003, epochs=30, steps=0)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCOGDJNyFEMIHSbgLIYQP+v9L8TO3sqEGCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pqL0_1R88He",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "fe215129-14c5-4c88-e844-ec0abca0e43b"
      },
      "source": [
        "model_3 = TrainModel(trainloader=p3_trainloader, testloader=p3_testloader, lr=0.003, epochs=30, steps=0)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI0d6fEwXnlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "84547326-19fb-4049-be78-bd86b0655683"
      },
      "source": [
        "model_4 = TrainModel(trainloader=p4_trainloader, testloader=p4_testloader, lr=0.003, epochs=30, steps=0)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lOr_7v3f07b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "2f42b00f-e714-4119-93e5-7e4bfbb77105"
      },
      "source": [
        "model_5 = TrainModel(trainloader=p5_trainloader, testloader=p5_testloader, lr=0.003, epochs=30, steps=0)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCgzPr4Zwwip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Return top p, k results from test set for each trained model.\n",
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "def pred(testloader, model):\n",
        "  # model to evaluation mode\n",
        "  model.eval()\n",
        "  \n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "      images, labels = data\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  \n",
        "  print('Accuracy of the network on the public database: %d %%' % (100 * correct / total))\n",
        "  \n",
        "  return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqIZhiR70fYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54f4df16-56fc-454b-ee22-063a985aa716"
      },
      "source": [
        "pred_0 = pred(testloader, model_0)\n",
        "print(pred_0.shape)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the public database: 94 %\n",
            "torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19b0n6FQ1lgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "27648299-4fbe-4618-e042-402b8f8d2c20"
      },
      "source": [
        "pred_1 = pred(testloader, model_1)\n",
        "print(pred_1.shape)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the public database: 95 %\n",
            "torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnlMxnjA1rmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3afe7b30-4ca4-451c-e9cf-31d62b879390"
      },
      "source": [
        "pred_2 = pred(testloader, model_2)\n",
        "print(pred_2.shape)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the public database: 94 %\n",
            "torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNfsWEAT1wn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e38a4da9-974d-4a52-bbfc-b37049c72eaf"
      },
      "source": [
        "pred_3 = pred(testloader, model_3)\n",
        "print(pred_3.shape)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the public database: 94 %\n",
            "torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxLPgSY4127R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fef54a8f-a36d-409b-a87f-60eaeb607088"
      },
      "source": [
        "pred_4 = pred(testloader, model_4)\n",
        "print(pred_4.shape)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the public database: 94 %\n",
            "torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiGlUveW18Dc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b605af61-1631-4d89-e536-3f891f2718f2"
      },
      "source": [
        "pred_5 = pred(testloader, model_5)\n",
        "print(pred_5.shape)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the public database: 95 %\n",
            "torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqUgcVs97GmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8a9d5589-4793-401f-a156-bb45c18332ed"
      },
      "source": [
        "# Aggregate predictons into one array of arrays. convert to a tensor of arrays.\n",
        "preds_list = []\n",
        "preds_to_append = [pred_0, pred_1, pred_2, pred_3, pred_4, pred_5]\n",
        "\n",
        "for i in range(len(preds_to_append)):\n",
        "  preds_list.append(preds_to_append[i].tolist())\n",
        "\n",
        "preds_arr = np.array(preds_list)\n",
        "preds = torch.tensor(preds_arr)\n",
        "print(preds)\n"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7, 2, 1,  ..., 4, 5, 6],\n",
            "        [7, 2, 1,  ..., 4, 5, 6],\n",
            "        [7, 2, 1,  ..., 4, 5, 6],\n",
            "        [7, 2, 1,  ..., 4, 5, 6],\n",
            "        [7, 2, 1,  ..., 4, 5, 6],\n",
            "        [7, 2, 1,  ..., 4, 5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO0SObRd8tc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fbe955fb-d71d-4e0e-d61d-b32ca1a19a65"
      },
      "source": [
        "# All predictions from one teacher\n",
        "print(\"All predictions from teacher 0: \", preds[0])\n",
        "\n",
        "# All predictions for the first image across \n",
        "print(\"All predictions for the first image across: \", preds[:, 0])"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All predictions from teacher 0:  tensor([7, 2, 1,  ..., 4, 5, 6])\n",
            "All predictions for the first image across:  tensor([7, 7, 7, 7, 7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDsDCh8t-XBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55bd254e-09c1-45d4-9b9f-85a5088178e8"
      },
      "source": [
        "# Analysis before adding random noise\n",
        "\n",
        "num_labels = 10 # images of handwritten digits 0 to 9\n",
        "\n",
        "# pull the predictions for a single image\n",
        "an_image = preds[:, 0]\n",
        "\n",
        "# count the nuber of times the models return each integer\n",
        "label_counts = np.bincount(an_image, minlength=num_labels)\n",
        "print(\"counts of labels: \", label_counts)\n",
        "\n",
        "# return the index of the max value\n",
        "max_index = np.argmax(label_counts)\n",
        "print(\"index of the max value: \", max_index)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts of labels:  [0 0 0 0 0 0 0 6 0 0]\n",
            "index of the max value:  7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwCrh4acOGv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e32a2eb3-2050-4165-c697-7b5c4149bd4f"
      },
      "source": [
        "# Analysis before adding random noise\n",
        "# Iterate through all the labels\n",
        "\n",
        "true_labels = list()\n",
        "pred = np.array(preds).transpose()\n",
        "\n",
        "for an_image in pred:\n",
        "  \n",
        "  label_counts = np.bincount(an_image, minlength = num_labels)\n",
        "    \n",
        "  max_index = np.argmax(label_counts)\n",
        "  \n",
        "  true_labels.append(max_index)\n",
        "  \n",
        "len(true_labels)\n",
        "\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "print(true_labels)\n",
        "print(test_targets)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 ... 4 5 6]\n",
            "tensor([7, 2, 1,  ..., 4, 5, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSxOoTTDA1_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4bb0dad0-ab16-4fe9-c640-1c1ed84c3497"
      },
      "source": [
        "# Analysis after adding random noise\n",
        "\n",
        "epsilon = 0.1\n",
        "sensitivity = 5\n",
        "beta = 10 / epsilon\n",
        "\n",
        "for i in range(len(label_counts)):\n",
        "  label_counts[i] += np.random.laplace(0, beta, 1)\n",
        "  \n",
        "print(\"label counts with laplacian noise: \", label_counts)\n",
        "\n",
        "# Calculate arg_max on on the labels with the noise added\n",
        "\n",
        "new_label = np.argmax(label_counts)\n",
        "\n",
        "print(\"label with noise added: \", new_label)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label counts with laplacian noise:  [ -22   12 -173  -37  -67 -154  239  123   25  -88]\n",
            "label with noise added:  6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVdBxdyqBYtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a9c8436-d961-48d4-bd14-28118206df3a"
      },
      "source": [
        "# Iterate through all the labels\n",
        "\n",
        "new_labels = list()\n",
        "\n",
        "for an_image in pred:\n",
        "  \n",
        "  label_counts = np.bincount(an_image, minlength = 10)\n",
        "  \n",
        "  epsilon = 0.1\n",
        "  sensitivity = 10\n",
        "  beta = sensitivity / epsilon\n",
        "  \n",
        "  for i in range(len(label_counts)):\n",
        "    label_counts[i] += np.random.laplace(0, beta, 1)\n",
        "    \n",
        "  new_label = np.argmax(label_counts)\n",
        "  \n",
        "  new_labels.append(new_label)\n",
        "  \n",
        "len(new_labels)\n",
        "\n",
        "new_labels = np.array(new_labels)\n",
        "\n",
        "print(new_labels)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 6 ... 1 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMMkwaeqBzld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c411626c-6cff-4c91-e57c-8f0bdb02e42f"
      },
      "source": [
        "print(true_labels)\n",
        "print(new_labels)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 ... 4 5 6]\n",
            "[0 1 6 ... 1 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTxGqCE9Ne2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "010011f9-dd8f-49f6-d72c-232735c8a49e"
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages/syft-0.1.21a1-py3.6.egg (0.1.21a1)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.0.3)\n",
            "Requirement already satisfied: flask_socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages/Flask_SocketIO-4.1.0-py3.6.egg (from syft) (4.1.0)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: tf_encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.6)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: websocket_client>=0.56.0 in /usr/local/lib/python3.6/dist-packages/websocket_client-0.56.0-py3.6.egg (from syft) (0.56.0)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (7.0)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages/python_socketio-4.2.0-py3.6.egg (from flask_socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages/python_engineio-3.8.2.post1-py3.6.egg (from python-socketio>=2.1.0->flask_socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->syft) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pBAeIUm0Nox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d005fad-6746-4393-941a-917565a485cc"
      },
      "source": [
        "\"\"\"\"Performs PATE analysis on predictions from teachers and combined predictions for student.\n",
        "\n",
        "    Args:\n",
        "        teacher_preds: a numpy array of dim (num_teachers x num_examples). Each value corresponds to the\n",
        "            index of the label which a teacher gave for a specific example\n",
        "        indices: a numpy array of dim (num_examples) of aggregated examples which were aggregated using\n",
        "            the noisy max mechanism.\n",
        "        noise_eps: the epsilon level used to create the indices\n",
        "        delta: the desired level of delta\n",
        "        moments: the number of moments to track (see the paper)\n",
        "        beta: a smoothing parameter (see the paper)\n",
        "    Returns:\n",
        "        tuple: first value is the data dependent epsilon, then the data independent epsilon\n",
        "    \"\"\""
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Performs PATE analysis on predictions from teachers and combined predictions for student.\\n\\n    Args:\\n        teacher_preds: a numpy array of dim (num_teachers x num_examples). Each value corresponds to the\\n            index of the label which a teacher gave for a specific example\\n        indices: a numpy array of dim (num_examples) of aggregated examples which were aggregated using\\n            the noisy max mechanism.\\n        noise_eps: the epsilon level used to create the indices\\n        delta: the desired level of delta\\n        moments: the number of moments to track (see the paper)\\n        beta: a smoothing parameter (see the paper)\\n    Returns:\\n        tuple: first value is the data dependent epsilon, then the data independent epsilon\\n    '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mImIRnI4rSup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "131fd33b-3140-4458-f892-64881e97938c"
      },
      "source": [
        "num_teachers, num_examples, num_labels = (len(preds), len(preds[0]), 10)\n",
        "preds_arr = preds.numpy() # fake preds\n",
        "indices = new_labels.astype(int) # true answers\n",
        "\n",
        "print(\"number of teachers: \", num_teachers)\n",
        "print(\"number of examples: \", num_examples)\n",
        "print(\"number of labels: \", num_labels)\n",
        "print(\"shape of preds array: \", preds.shape)\n",
        "print(\"shape of indices array: \", indices.shape)\n",
        "print(indices)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of teachers:  6\n",
            "number of examples:  10000\n",
            "number of labels:  10\n",
            "shape of preds array:  torch.Size([6, 10000])\n",
            "shape of indices array:  (10000,)\n",
            "[0 1 6 ... 1 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTpP5pJMqANO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1501db72-800c-4f3d-bec4-3d99397980df"
      },
      "source": [
        "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=pred.transpose(), indices=indices, noise_eps=0.1, delta=1e-5)\n",
        "\n",
        "print(\"Data dependent epsilon: \", data_dep_eps) \n",
        "print(\"Data independent epsilon: \", data_ind_eps) \n",
        "print(data_dep_eps < data_ind_eps)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data dependent epsilon:  411.51292546502725\n",
            "Data independent epsilon:  411.5129254649703\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}